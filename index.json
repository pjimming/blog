[{"categories":[],"content":"通过封装 VChart 组件，实现简单易用的图表。达到代码复用，提高研发效率。 最近有一个需求，需要实现一个图表，图表的数据是动态的，需要根据后端返回的数据进行实时更新。 在调研了 ECharts 后，发现 ECharts 的使用门槛较高，需要对 ECharts 的 API 有一定的了解。同时关注到了 VChart，VChart 的使用门槛较低，只需要对 VChart 的 API 有一定的了解即可。同时对 VChart 的文档进行了调研，发现 VChart 的文档非常详细，可以满足我们的需求。 当然，并不是说 VChart 就完美无缺，VChart 的文档虽然详细，但是对于一些特殊的场景，VChart 的文档并没有给出详细的说明。比如，如何实现动态数据更新，如何实现图表的交互等。因此需要我们对 VChart 进行二次封装，以满足我们的需求。 ","date":"2025-02-28","objectID":"/2025-02-28/vchart/:0:0","tags":[],"title":"Vue封装VChart组件，实现简单易用的图表","uri":"/2025-02-28/vchart/"},{"categories":[],"content":"前置知识 快速上手 VChart ","date":"2025-02-28","objectID":"/2025-02-28/vchart/:1:0","tags":[],"title":"Vue封装VChart组件，实现简单易用的图表","uri":"/2025-02-28/vchart/"},{"categories":[],"content":"VChart 封装 components/VChart.vue \u003cscript setup\u003e import { onMounted, defineProps, watch } from \"vue\"; import VChart from \"@visactor/vchart\"; import { useAppStore } from \"@/store\"; const appStore = useAppStore(); // 组件接收的 props const props = defineProps({ // 图表的配置 spec: { type: Object, default: () =\u003e ({}), }, width: { type: [String, Number], default: \"100%\" }, // 图表宽度 height: { type: [String, Number], default: \"400px\" }, // 图表高度 }); const chartContainer = ref(null); // 绑定 VChart 实例 let chart; function createOrUpdateChart() { console.log(\"createOrUpdateChart\", chartContainer.value); if (chartContainer.value) { if (!chart) { console.log(\"📌 创建新图表实例\", props.spec); chart = new VChart(props.spec, { dom: chartContainer.value, }); } else { console.log(\"🔄 更新图表\", props.spec); chart.updateSpec(props.spec); } chart.setCurrentTheme(appStore.isDark ? \"dark\" : \"light\"); chart.renderSync(); } } onMounted(() =\u003e { createOrUpdateChart(); }); onUpdated(() =\u003e { createOrUpdateChart(); }); onBeforeUnmount(() =\u003e { if (chart) { chart.release(); } }); // 可选，明暗模式切换 watch( () =\u003e appStore.isDark, () =\u003e { createOrUpdateChart(); } ); \u003c/script\u003e \u003ctemplate\u003e \u003cdiv ref=\"chartContainer\" :style=\"{ width: props.width, height: props.height }\" \u003e\u003c/div\u003e \u003c/template\u003e 根据代码可知，我们只需要关注 spec 的配置即可，其他的都是自动处理的。 ","date":"2025-02-28","objectID":"/2025-02-28/vchart/:2:0","tags":[],"title":"Vue封装VChart组件，实现简单易用的图表","uri":"/2025-02-28/vchart/"},{"categories":[],"content":"使用 \u003ctemplate\u003e \u003cdiv class=\"mt-12 flex\"\u003e \u003cVChart :spec=\"spec\" /\u003e \u003c/div\u003e \u003c/template\u003e \u003cscript setup\u003e import VChart from '@/components/VChart.vue' import api from '../api' const spec = ref({ type: 'bar', data: [ { id: 'barData', values: [ { month: 'Monday', sales: 22 }, { month: 'Tuesday', sales: 13 }, { month: 'Wednesday', sales: 25 }, { month: 'Thursday', sales: 29 }, { month: 'Friday', sales: 38 } ] } ], xField: 'month', yField: 'sales' };) api.getData().then({ data } =\u003e { spec.value = { ...spec.value, data: { values: data.freeServerCountBySuit }, } }); \u003c/script\u003e ","date":"2025-02-28","objectID":"/2025-02-28/vchart/:3:0","tags":[],"title":"Vue封装VChart组件，实现简单易用的图表","uri":"/2025-02-28/vchart/"},{"categories":["docker"],"content":"使用 DevContainer 打造一个轻量级算法竞赛环境，无需担忧环境变更即可轻松写题 ","date":"2025-01-26","objectID":"/2025-01-26/acm-dev-container/:0:0","tags":["docker","devcontainer","vscode","acm"],"title":"使用Dev Container打造轻量级算法竞赛环境","uri":"/2025-01-26/acm-dev-container/"},{"categories":["docker"],"content":"什么是 Dev Container Dev Container 是一种基于容器化技术的开发环境配置方式，由 VS Code 扩展支持。它允许你为一个项目定义一个完全隔离的开发环境，从而确保开发者的工具链、依赖和配置在任何机器上都一致。 ","date":"2025-01-26","objectID":"/2025-01-26/acm-dev-container/:1:0","tags":["docker","devcontainer","vscode","acm"],"title":"使用Dev Container打造轻量级算法竞赛环境","uri":"/2025-01-26/acm-dev-container/"},{"categories":["docker"],"content":"Dev Container 的核心概念 开发环境即代码： 通过配置文件（通常是 .devcontainer/devcontainer.json 和 Dockerfile），你可以将开发环境定义为代码的一部分，版本化并与团队共享。 所有开发者拉取项目后，都可以在几分钟内启动一个相同的开发环境。 基于容器： 使用 Docker 容器作为运行环境，将代码和依赖隔离在独立的环境中，而不会污染宿主系统。 容器可以基于通用的镜像（如 ubuntu, node, python）或自定义的镜像。 集成 VS Code： VS Code 可以连接到容器内部，通过 Remote - Containers 插件使开发体验无缝。 开发者几乎感觉不到自己是在容器中工作，因为所有操作（如调试、终端、文件操作）都与本地开发一致。 ","date":"2025-01-26","objectID":"/2025-01-26/acm-dev-container/:1:1","tags":["docker","devcontainer","vscode","acm"],"title":"使用Dev Container打造轻量级算法竞赛环境","uri":"/2025-01-26/acm-dev-container/"},{"categories":["docker"],"content":"前置环境 Vs Code Docker Dev Container ","date":"2025-01-26","objectID":"/2025-01-26/acm-dev-container/:2:0","tags":["docker","devcontainer","vscode","acm"],"title":"使用Dev Container打造轻量级算法竞赛环境","uri":"/2025-01-26/acm-dev-container/"},{"categories":["docker"],"content":"使用 Dev Container 目录结构如下所示： . ├── .clang-format // C++格式化配置 ├── .devcontainer // devcontainer主要目录 │ ├── Dockerfile │ ├── devcontainer.json // 描述 Dev Container 的核心配置，比如基础镜像、安装扩展、转发端口、环境变量等 │ └── setup.sh ├── .vscode // vscode相关配置 │ ├── cpp.code-snippets // 代码块模版 │ └── settings.json // 自定义设置 └── code // 代码文件，懂得都懂 ├── atcoder └── codeforces 拉取仓库： git clone git@github.com:pjimming/acm-dev-container.git code acm-dev-container 打开这个目录后，点击左下角的链接 UI（箭头所指） 点击蓝色小块 选择 Reopen in Container 选择在容器里重新打开 Docker 会根据 Dockerfile 自动拉取镜像，构建容器，配置所需要的环境 # 使用基于 GCC 的镜像作为基础镜像 FROM gcc:latest # 更新系统并安装常用开发工具 RUN apt-get update -y \u0026\u0026 \\ apt-get upgrade -y \u0026\u0026 \\ apt-get install -y \\ build-essential \\ g++ \\ gdb \\ cmake \\ git \\ vim \\ wget \\ curl \\ unzip \\ zsh \u0026\u0026 \\ apt-get clean # 安装 Oh My Zsh RUN sh -c \"$(wget https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh -O -)\" --unattended \u0026\u0026 \\ chsh -s /bin/zsh \u0026\u0026 \\ echo \"export TERM=xterm-256color\" \u003e\u003e ~/.zshrc # 安装 Zsh 插件：zsh-autosuggestions 和 zsh-syntax-highlighting RUN git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions \u0026\u0026 \\ git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting \u0026\u0026 \\ sed -i 's/plugins=(git)/plugins=(git zsh-autosuggestions zsh-syntax-highlighting)/g' ~/.zshrc # 设置默认工作目录 WORKDIR /workspace # 设置环境变量，使用 C++20 编译 ENV CXXFLAGS=\"-std=c++20 -D_GLIBCXX_DEBUG\" # 安装 C++ 工具：Clang Tidy、Clang Format（可选） RUN apt-get install -y clang-tidy clang-format # 设置默认终端为 Zsh CMD [\"/bin/zsh\"] 等待启动完成后，就是一个可以愉快写题的环境了。 ABC390_A ","date":"2025-01-26","objectID":"/2025-01-26/acm-dev-container/:3:0","tags":["docker","devcontainer","vscode","acm"],"title":"使用Dev Container打造轻量级算法竞赛环境","uri":"/2025-01-26/acm-dev-container/"},{"categories":["计算机网络"],"content":"简单介绍一下四层接入中的 DR 模式 ","date":"2025-01-09","objectID":"/2025-01-09/dpvs-ipip-dr/:0:0","tags":["计算机网络","dpvs"],"title":"通过IPIP网络隧道实现DPVS的DR模式","uri":"/2025-01-09/dpvs-ipip-dr/"},{"categories":["计算机网络"],"content":"基础知识 ","date":"2025-01-09","objectID":"/2025-01-09/dpvs-ipip-dr/:1:0","tags":["计算机网络","dpvs"],"title":"通过IPIP网络隧道实现DPVS的DR模式","uri":"/2025-01-09/dpvs-ipip-dr/"},{"categories":["计算机网络"],"content":"1. IPIP 隧道简介 IPIP 隧道是一种简单的点对点隧道协议，通过在原始 IP 数据包上再封装一层 IP 头，将数据包通过隧道传递。它常用于跨地域传输数据，尤其是在负载均衡场景中。 ","date":"2025-01-09","objectID":"/2025-01-09/dpvs-ipip-dr/:1:1","tags":["计算机网络","dpvs"],"title":"通过IPIP网络隧道实现DPVS的DR模式","uri":"/2025-01-09/dpvs-ipip-dr/"},{"categories":["计算机网络"],"content":"2. DR 模式简介 Direct Routing 模式是负载均衡的一种方式，它允许请求流量通过负载均衡器到达后端服务器，但响应流量直接从后端服务器返回给客户端，而不经过负载均衡器。这种模式可以降低负载均衡器的流量压力。 ","date":"2025-01-09","objectID":"/2025-01-09/dpvs-ipip-dr/:1:2","tags":["计算机网络","dpvs"],"title":"通过IPIP网络隧道实现DPVS的DR模式","uri":"/2025-01-09/dpvs-ipip-dr/"},{"categories":["计算机网络"],"content":"3. DPVS 简介 DPVS 基于 DPDK（Data Plane Development Kit）的四层负载均衡器，特点是高性能、低延迟、丰富功能等优势。它特别适合高并发、高吞吐的场景，且对已有的 LVS 配置具有良好的兼容性，同时对于数据包在用户态进行处理，无需通过内核封装。 ","date":"2025-01-09","objectID":"/2025-01-09/dpvs-ipip-dr/:1:3","tags":["计算机网络","dpvs"],"title":"通过IPIP网络隧道实现DPVS的DR模式","uri":"/2025-01-09/dpvs-ipip-dr/"},{"categories":["计算机网络"],"content":"链路图解 DR模式链路图解 客户端发送一个请求，目的 IP 是 DPVS 集群监听的 VIP DPVS 集群收到了这个请求，将这个请求数据包封装成一个 ipip 数据包（源 IP: LB_IP, 目的 IP: RS_IP, 协议: 4；其中协议：4 表示一个 ipip 数据包），通过负载均衡算法，将这个 ipip 数据包发送给与 dpvs 打通 ipip 隧道的 rs 服务器 rs 服务器收到 dpvs 传来的 ipip 数据包，解封后得到原本的数据包，处理请求后，根据源 IP 地址，直接发送 response 到对于的 ip，不需要通过 dpvs 发送，减缓集群压力 ","date":"2025-01-09","objectID":"/2025-01-09/dpvs-ipip-dr/:2:0","tags":["计算机网络","dpvs"],"title":"通过IPIP网络隧道实现DPVS的DR模式","uri":"/2025-01-09/dpvs-ipip-dr/"},{"categories":["计算机网络"],"content":"代理服务器是介于客户端与服务器之间，充当中间人的角色，可以有效提高系统的安全性、性能和可拓展性。 ","date":"2024-09-02","objectID":"/2024-09-02/proxy/:0:0","tags":["正向代理","反向代理","计算机网络"],"title":"谈谈正向代理与反向代理","uri":"/2024-09-02/proxy/"},{"categories":["计算机网络"],"content":"正向代理 ","date":"2024-09-02","objectID":"/2024-09-02/proxy/:1:0","tags":["正向代理","反向代理","计算机网络"],"title":"谈谈正向代理与反向代理","uri":"/2024-09-02/proxy/"},{"categories":["计算机网络"],"content":"概念 正向代理位于客户端与服务器中间的代理服务器。 客户端将请求发送给正向代理，然后由代理服务器将请求转发给目标服务器。服务器处理请求之后，将结果传回代理服务器，然后代理服务器将结果转发给客户端。 正向代理 ","date":"2024-09-02","objectID":"/2024-09-02/proxy/:1:1","tags":["正向代理","反向代理","计算机网络"],"title":"谈谈正向代理与反向代理","uri":"/2024-09-02/proxy/"},{"categories":["计算机网络"],"content":"特点 隐藏客户端身份：正向代理可以隐藏客户端的真实地址，保护客户端的隐私 访问控制：正向代理可以根据一定的规则去限制或允许客户端的访问请求，实现访问控制的功能 缓存加速：正向代理可以缓存经常访问的页面，提高访问速度，减轻服务器压力 ","date":"2024-09-02","objectID":"/2024-09-02/proxy/:1:2","tags":["正向代理","反向代理","计算机网络"],"title":"谈谈正向代理与反向代理","uri":"/2024-09-02/proxy/"},{"categories":["计算机网络"],"content":"使用场景 突破网络限制：在某些地区或网络环境下，用户可能无法直接访问某些网站或服务。此时，可以通过设置正向代理来突破这些限制，实现访问 网络安全：通过正向代理，企业可以监控和管理员工的网络访问行为，隐藏客户端真实 IP，防止敏感数据泄露 内容过滤：学校、图书馆等公共场所可以通过正向代理过滤不良内容，保护用户免受不良信息的侵害。 提高访问速度：代理服务器设置硬盘缓冲区，可以将部分高频请求的响应数据保存到缓冲区中，以提高访问速度。 ","date":"2024-09-02","objectID":"/2024-09-02/proxy/:1:3","tags":["正向代理","反向代理","计算机网络"],"title":"谈谈正向代理与反向代理","uri":"/2024-09-02/proxy/"},{"categories":["计算机网络"],"content":"反向代理 ","date":"2024-09-02","objectID":"/2024-09-02/proxy/:2:0","tags":["正向代理","反向代理","计算机网络"],"title":"谈谈正向代理与反向代理","uri":"/2024-09-02/proxy/"},{"categories":["计算机网络"],"content":"概念 客户端将请求发送给反向代理，然后由代理服务器根据一定的规则将请求转发给后端服务器。后端服务器将响应返回给代理服务器，再由代理服务器将响应转发给客户端。反向代理对客户端是透明的，客户端无需知道实际服务器的地址，只需将反向代理当作目标服务器一样发送请求就可以了。 反向代理 ","date":"2024-09-02","objectID":"/2024-09-02/proxy/:2:1","tags":["正向代理","反向代理","计算机网络"],"title":"谈谈正向代理与反向代理","uri":"/2024-09-02/proxy/"},{"categories":["计算机网络"],"content":"特点 负载均衡：反向代理可以根据后端服务器的负载情况，将请求分发到不同的服务器上，实现负载均衡，提高系统的整体性能。 安全性增强：反向代理可以隐藏后端服务器的真实地址和端口，防止直接攻击（如 DoS/DDoS）。同时，还可以实现 SSL 加密、访问控制等安全功能。 缓存优化：反向代理可以缓存静态资源，减少后端服务器的负载，提高响应速度。 ","date":"2024-09-02","objectID":"/2024-09-02/proxy/:2:2","tags":["正向代理","反向代理","计算机网络"],"title":"谈谈正向代理与反向代理","uri":"/2024-09-02/proxy/"},{"categories":["计算机网络"],"content":"使用场景 Web 应用：在 Web 应用中，反向代理常用于实现负载均衡、安全访问控制以及缓存优化等功能。 API 网关：API 网关通常采用反向代理的方式，对外部请求进行统一管理和调度，实现 API 的安全、高效访问。 CDN 加速：内容分发网络（CDN）通过在全球范围内部署反向代理服务器，实现内容的就近访问和加速传输。 ","date":"2024-09-02","objectID":"/2024-09-02/proxy/:2:3","tags":["正向代理","反向代理","计算机网络"],"title":"谈谈正向代理与反向代理","uri":"/2024-09-02/proxy/"},{"categories":["计算机网络"],"content":"正反向代理的比较 ","date":"2024-09-02","objectID":"/2024-09-02/proxy/:3:0","tags":["正向代理","反向代理","计算机网络"],"title":"谈谈正向代理与反向代理","uri":"/2024-09-02/proxy/"},{"categories":["计算机网络"],"content":"相同点 位置和功能： 正向代理和反向代理都位于客户端和真实服务器之间，它们的主要功能都是将客户端的请求转发给服务器，然后再将服务器的响应转发给客户端。 提高访问速度： 两者都能通过缓存机制提高访问速度。当客户端请求某个资源时，如果代理服务器已经缓存了该资源，就可以直接从缓存中提供，而无需再次从原始服务器获取，从而节省了时间和带宽。 ","date":"2024-09-02","objectID":"/2024-09-02/proxy/:3:1","tags":["正向代理","反向代理","计算机网络"],"title":"谈谈正向代理与反向代理","uri":"/2024-09-02/proxy/"},{"categories":["计算机网络"],"content":"不同点 代理对象： 正向代理是为客户端提供代理服务，即服务器不知道真正的客户端是谁。而反向代理则是为服务器提供代理服务，即客户端不知道真正的服务器是谁。 架设位置： 正向代理通常是由客户端架设的，而反向代理则是由服务器架设的。 用途和目的： 正向代理的主要用途是为在防火墙内的局域网客户端提供访问 Internet 的途径，侧重于解决访问限制问题。而反向代理的主要用途是将防火墙后面的服务器提供给 Internet 用户访问，其目的在于实现负载均衡、安全防护等。 服务对象： 在正向代理中，服务器不知道真正的用户是谁；而在反向代理中，用户不知道真正的服务器是谁。 ","date":"2024-09-02","objectID":"/2024-09-02/proxy/:3:2","tags":["正向代理","反向代理","计算机网络"],"title":"谈谈正向代理与反向代理","uri":"/2024-09-02/proxy/"},{"categories":["计算机网络"],"content":"四层和七层中反代的区别 四层中根据用户的 IP+PORT 来做 hash 七层中根据 Http 协议中的属性来做 hash（如 Header、Cookies） ","date":"2024-09-02","objectID":"/2024-09-02/proxy/:3:3","tags":["正向代理","反向代理","计算机网络"],"title":"谈谈正向代理与反向代理","uri":"/2024-09-02/proxy/"},{"categories":["计算机网络"],"content":"总结 正向代理主要关注客户端的访问需求和安全性，而反向代理则更注重后端服务器的负载均衡、安全性和性能优化。 ","date":"2024-09-02","objectID":"/2024-09-02/proxy/:4:0","tags":["正向代理","反向代理","计算机网络"],"title":"谈谈正向代理与反向代理","uri":"/2024-09-02/proxy/"},{"categories":["blog"],"content":"纪念我热烈灿烂的青春 ","date":"2024-06-28","objectID":"/2024-06-28/summary/:0:0","tags":["blog","zust"],"title":"总结一下我的本科四年","uri":"/2024-06-28/summary/"},{"categories":["blog"],"content":"年级总结 先总结一下每个年级自认为最重要的事情吧。 大一：转专业到计算机，抹平专业差距 大二：进入浙科大程序设计竞赛集训队，拿了点比赛的奖项，减少学历差距 大三：面试拿到了七牛云的实习 offer，并且有了一段 10 个月的实习经历，补齐了项目、实习经历 大四：校招进入北京快手，是一个好的职业起点 结果来看的确还行，但是距离我入学时给自己定的 50w 年薪还差了点。 尽管大环境有点不如人意，还是希望再接再厉，争取两年后达到年薪 50 万的目标。 ","date":"2024-06-28","objectID":"/2024-06-28/summary/:1:0","tags":["blog","zust"],"title":"总结一下我的本科四年","uri":"/2024-06-28/summary/"},{"categories":["blog"],"content":"旅行方面 大学前一坤年因为疫情的原因，并没有出去旅游。从大四的国庆开始，开启了我的大学旅行生活。 在这一年里，去了南京、宁波、合肥、哈尔滨、横店、兰州、西宁、海北藏族自治州，张掖、嘉峪关、瓜州、敦煌、海西蒙古族藏族自治州、大柴旦、格尔木、可可西里、茶卡、海南藏族自治州、海东市。 去南京的走过翠绿的梧桐大道，等待音乐台的鸽子飞起，也进过富丽堂皇的牛首山佛顶宫，也曾夜泊秦淮夫子庙，登过南京的老城墙，观赏过三博之一的南博。 去宁波和高中同学惊险攀岩，去合肥中科大打了第一场 icpc 线下赛，去哈尔滨感受了一下北国风光，也第一次坐了飞机。 去西北走过祁连山、昆仑山、当金山，踏足柴达木盆地和青藏高原，也骑过马、骑过骆驼、追过鼠兔、撵过羊。看过雪山、草原、沙漠与星空，见过沙漠下暴雨，也见过六月飞雪，见到了初中地理上的丹霞与雅丹地貌。更收获了一段珍贵的友谊和全长 4300 千米的自驾环线。 ","date":"2024-06-28","objectID":"/2024-06-28/summary/:2:0","tags":["blog","zust"],"title":"总结一下我的本科四年","uri":"/2024-06-28/summary/"},{"categories":["blog"],"content":"经济方面 ","date":"2024-06-28","objectID":"/2024-06-28/summary/:3:0","tags":["blog","zust"],"title":"总结一下我的本科四年","uri":"/2024-06-28/summary/"},{"categories":["blog"],"content":"奖学金 大学里总计获得奖学金如下： 省政府奖学金 $\\times 1$ 优秀学生二等奖学金 $\\times 2$ 创新创业三等奖学金 $\\times 2$ 信息学院科技创新奖学金 $3707$￥ 优良学风奖 $\\times 1$ 奖学金共计：16107.0 ￥ ","date":"2024-06-28","objectID":"/2024-06-28/summary/:3:1","tags":["blog","zust"],"title":"总结一下我的本科四年","uri":"/2024-06-28/summary/"},{"categories":["blog"],"content":"实习所得 实习公司如下： 鸿泉物联：2610.8 ￥ 七牛云：62400.0 ￥ 实习共计：65010.8 ￥ ","date":"2024-06-28","objectID":"/2024-06-28/summary/:3:2","tags":["blog","zust"],"title":"总结一下我的本科四年","uri":"/2024-06-28/summary/"},{"categories":["blog"],"content":"投资理财 截止目前（2024-06-28），基金获利 211.47 ￥，投入成本 6000 ￥左右。 其中 S\u0026P500 获利 523.96 ￥，而军工、医疗、白酒相关的 A 股基金亏损 312.49 ￥。 远离 A 股，享受幸福人生 ","date":"2024-06-28","objectID":"/2024-06-28/summary/:3:3","tags":["blog","zust"],"title":"总结一下我的本科四年","uri":"/2024-06-28/summary/"},{"categories":["blog"],"content":"其他 通过闲鱼半个月赚了 6000 ￥左右，以及其他兼职、校内补贴共 1000 ￥左右。 共计 7000 ￥ ","date":"2024-06-28","objectID":"/2024-06-28/summary/:3:4","tags":["blog","zust"],"title":"总结一下我的本科四年","uri":"/2024-06-28/summary/"},{"categories":["blog"],"content":"总结 大学里通过奖学金、实习、兼职、创业、投资理财共计获得 88329.27 ￥。 相对来说，在大学的后半段，大三下以及大四期间，我实现了大学生的财富自由。 通过自己赚来的钱，给自己置备了一部新手机 iPhone 15 Pro Max，一瓶 500ml 大吉岭茶香水，旅行所需的全部资金、平常的生活开销、北京的租房资金，以及给妈妈买了一个金戒指作为母亲节礼物。 遗憾的是没有达到 6 位数的收入，希望工作之后能减少一些不必要的支出，尽快达到人生理想！ ","date":"2024-06-28","objectID":"/2024-06-28/summary/:3:5","tags":["blog","zust"],"title":"总结一下我的本科四年","uri":"/2024-06-28/summary/"},{"categories":["blog"],"content":"荣誉\u0026奖项 ","date":"2024-06-28","objectID":"/2024-06-28/summary/:4:0","tags":["blog","zust"],"title":"总结一下我的本科四年","uri":"/2024-06-28/summary/"},{"categories":["blog"],"content":"荣誉认证 🏆 浙江科技大学优秀毕业生 2024 🏆 工业互联网平台开发工程师中级 2023 ","date":"2024-06-28","objectID":"/2024-06-28/summary/:4:1","tags":["blog","zust"],"title":"总结一下我的本科四年","uri":"/2024-06-28/summary/"},{"categories":["blog"],"content":"评奖评优 🏆 浙江科技大学优良学风奖学金 2022-2023 🏆 浙江科技大学创新创业奖学金三等奖 2022-2023 🏆 浙江省政府奖学金 2021-2022 🏆 浙江科技大学创新创业奖学金三等奖 2021-2022 🏆 浙江科技大学优秀学生二等奖学金 2021-2022 🏆 浙江科技大学三好学生 2021-2022 🏆 浙江科技大学优秀学生二等奖学金 2020-2021 🏆 浙江科技大学三好学生 2020-2021 ","date":"2024-06-28","objectID":"/2024-06-28/summary/:4:2","tags":["blog","zust"],"title":"总结一下我的本科四年","uri":"/2024-06-28/summary/"},{"categories":["blog"],"content":"竞赛奖项 🥈 CCCC - 第八届中国高校计算机大赛 GPLT 全国总决赛 - 银奖 2024 🥇 CCCC - 第八届中国高校计算机大赛 GPLT 全国总决赛 - 金奖 2023 🥈 第十四届蓝桥杯软件和信息技术专业人才大赛 C/C++ 组（国赛）- 银奖 2023 🥇 第十四届蓝桥杯软件和信息技术专业人才大赛 C/C++ 组（省赛）- 金奖 2023 🥈 RAICOM - 机器人开发者大赛 CAIP 编程设计（省赛）- 银奖 2023 🥈 ICPC - 第十九届浙江省大学生程序设计竞赛 - 银奖 2022 🥈 CCCC - 第七届中国高校计算机大赛 GPLT 全国总决赛 - 银奖 2022 🥈 第十三届蓝桥杯软件和信息技术专业人才大赛 C/C++ 组（省赛）- 银奖 2022 🥉 RoboCom - 机器人开发者大赛 CAIP 编程设计（国赛）- 铜奖 2022 🥈 RoboCom - 机器人开发者大赛 CAIP 编程设计（省赛）- 银奖 2022 ","date":"2024-06-28","objectID":"/2024-06-28/summary/:4:3","tags":["blog","zust"],"title":"总结一下我的本科四年","uri":"/2024-06-28/summary/"},{"categories":["blog"],"content":"感谢的人 首先需要感谢我的父母一直以来给我的支持与鼓励，以及家族内长辈们的关心与帮助。 感谢妞妞，陪伴了我 9 年。 感谢浙科大林志洁老师，虽然在训练上没怎么帮助，但是每次比赛的资金由林老师支付，感恩 🙏。 感谢我的室友（李想，汤晨铳，王家栋）给我带来了三年良好的宿舍氛围与快乐。 感谢我的同学们，网友们，谢谢你们陪伴了我的青春。 感谢浙科大 ACM 实验室的同仁，尤其是方行同学和方毓乔同学，志同道合的队友 🤝，我们都有美好的未来。 感谢杭州七牛云的 mentor 们（捷哥、雨哥、宝哥），我在七牛云过的很充实、很开心。 感谢北京快手的 leader 旭哥、mentor 京哥，在绝望时给了我留在这个行业的希望。 感谢方行同学，胡向东同学陪伴了我 11 天的毕业西北自驾旅行。 感谢一段 be 的感情，让我成长了很多。 最后感谢我自己，没有放弃那个高考考砸的小男孩，没有选择浑浑噩噩的度过一生。 ","date":"2024-06-28","objectID":"/2024-06-28/summary/:5:0","tags":["blog","zust"],"title":"总结一下我的本科四年","uri":"/2024-06-28/summary/"},{"categories":["blog"],"content":"展望未来 现在我是 22 周岁。 希望自己在 24 岁可以提一台自己的小车，预算 30 万。 在 27 岁踏入年薪百万的行列，正所谓业立家成。 在 27~30 岁的区间和喜欢的人结婚，我们一定志同道合。 未来可能会继续深造，读研读博。但是目前最重要的还是做好自己的本职工作，保障快手的网络流量可用性。 当然也考虑创业，如果天时地利人和的话。 也不能一直闷着头搞技术，和人打交道也是必会的技能，尽可能向上社交。 少熬夜，多锻炼，勤阅读。 北京，我来了。 潘江明 二〇二四年六月二十八日 凌晨 记于 杭州临安家中 ","date":"2024-06-28","objectID":"/2024-06-28/summary/:6:0","tags":["blog","zust"],"title":"总结一下我的本科四年","uri":"/2024-06-28/summary/"},{"categories":["mysql"],"content":"《MySQL 实战 45 讲》第 18 章至第 26 章的笔记 ","date":"2024-05-17","objectID":"/2024-05-17/mysql45-3/:0:0","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——实践篇（二）","uri":"/2024-05-17/mysql45-3/"},{"categories":["mysql"],"content":"18 ｜ 为什么这些 SQL 语句逻辑相同，性能却差异巨大 条件字段函数操作：在语句中使用了函数，不走索引。 隐式数据转换：类型不一致，索引失效。 隐式字符集转换：编码格式不同，会导致索引失效。 ","date":"2024-05-17","objectID":"/2024-05-17/mysql45-3/:1:0","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——实践篇（二）","uri":"/2024-05-17/mysql45-3/"},{"categories":["mysql"],"content":"19 ｜ 为什么我只差一行的语句，也执行这么慢 长时间不返回 等 MDL 锁 等 flush 等行锁 查询慢 其他事务阻塞查询 ","date":"2024-05-17","objectID":"/2024-05-17/mysql45-3/:2:0","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——实践篇（二）","uri":"/2024-05-17/mysql45-3/"},{"categories":["mysql"],"content":"《MySQL 实战 45 讲》第 9 章至第 17 章的笔记 ","date":"2024-05-06","objectID":"/2024-05-06/mysql45-2/:0:0","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——实践篇（一）","uri":"/2024-05-06/mysql45-2/"},{"categories":["mysql"],"content":"09 | 普通索引和唯一索引，应该怎么选择？ ","date":"2024-05-06","objectID":"/2024-05-06/mysql45-2/:1:0","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——实践篇（一）","uri":"/2024-05-06/mysql45-2/"},{"categories":["mysql"],"content":"Change Buffer 当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。 将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。 如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用 buffer pool 的，所以这种方式还能够避免占用内存，提高内存利用率。 同时 change buffer 用的是 buffer pool 里的内容，因此不能无限增大。可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。 ","date":"2024-05-06","objectID":"/2024-05-06/mysql45-2/:1:1","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——实践篇（一）","uri":"/2024-05-06/mysql45-2/"},{"categories":["mysql"],"content":"唯一索引不需要使用 Change Buffer 对于唯一索引，每次更新需要判断是否违反唯一性约束。因此需要将磁盘的内容读入到内存中，直接在内存中更新显然效率更高，就不需要使用 change buffer 了。 因此只有普通索引才可以使用 change buffer。 ","date":"2024-05-06","objectID":"/2024-05-06/mysql45-2/:1:2","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——实践篇（一）","uri":"/2024-05-06/mysql45-2/"},{"categories":["mysql"],"content":"数据不在内存中时，两个索引的新增操作表现 对于唯一索引来说，需要将数据页读入到内存中，判断是否违反了唯一性约束，插入值，语句结束。 对于普通索引来说，在 change buffer 中记录一条数据，语句结束。 将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。 ","date":"2024-05-06","objectID":"/2024-05-06/mysql45-2/:1:3","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——实践篇（一）","uri":"/2024-05-06/mysql45-2/"},{"categories":["mysql"],"content":"change buffer 的使用场景 change buffer 的作用就是将记录的变更操作缓存起来，因此缓存的记录越多，收益越大。 对于写多读少的业务，比如账单类、日志类的系统，change buffer 可以提供非常好的效果。 对于写入之后需要马上查询的业务，写入 change buffer 后会立即触发 merge 操作，随机访问的 IO 操作不会减少，还会增加 change buffer 的维护代价，因此会起到反作用。 ","date":"2024-05-06","objectID":"/2024-05-06/mysql45-2/:1:4","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——实践篇（一）","uri":"/2024-05-06/mysql45-2/"},{"categories":["mysql"],"content":"redo log 和 change buffer redo log 主要节省随机写磁盘的 IO 消耗（转为顺序写）；change buffer 主要节省随机读磁盘的 IO 消耗。 带change buffer的更新过程 ","date":"2024-05-06","objectID":"/2024-05-06/mysql45-2/:1:5","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——实践篇（一）","uri":"/2024-05-06/mysql45-2/"},{"categories":["mysql"],"content":"异常重启是否会丢失 change buffer 和数据 不会。事务在 commit 时，会把 change buffer 的操作记录到 redo log 中，因此在崩溃的时候，change buffer 也会找到原来的数据。 ","date":"2024-05-06","objectID":"/2024-05-06/mysql45-2/:1:6","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——实践篇（一）","uri":"/2024-05-06/mysql45-2/"},{"categories":["mysql"],"content":"10 | MySQL 为什么有时候会选错索引？ ","date":"2024-05-06","objectID":"/2024-05-06/mysql45-2/:2:0","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——实践篇（一）","uri":"/2024-05-06/mysql45-2/"},{"categories":["mysql"],"content":"优化器的逻辑 优化器选择索引的标准有：扫描行数、是否使用临时表、是否排序等。 如何判断扫描行数？根据索引的“区分度”去统计大概的扫描行数，区分度称为基数（cardinality），基数越大，区分度越好。 MySQL 提供采样统计来得到索引的基数。由于采样统计，可能就会出现基数不正确的情况。同样优化器也需要考虑回表的代价。 对于使用错误索引，可以参考以下方式： 使用force index来强行指定索引。 通过修改语句来引导优化器。 通过增加或者删除索引来绕过问题。 ","date":"2024-05-06","objectID":"/2024-05-06/mysql45-2/:2:1","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——实践篇（一）","uri":"/2024-05-06/mysql45-2/"},{"categories":["mysql"],"content":"11 | 怎么给字符串字段加索引？ 直接创建完整索引，但是比较占用空间。 创建前缀索引，节省空间。但是会增加查询扫描次数，并不能使用覆盖索引。 倒序存储，再创建前缀索引，绕过字符串本身前缀区分度不够的问题。 创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，不支持范围扫描。 ","date":"2024-05-06","objectID":"/2024-05-06/mysql45-2/:3:0","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——实践篇（一）","uri":"/2024-05-06/mysql45-2/"},{"categories":["mysql"],"content":"12 | 为什么我的 MySQL 会“抖”一下？ 一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显边长。 日志写满，更新全部被堵住，写性能跌为 0。 ","date":"2024-05-06","objectID":"/2024-05-06/mysql45-2/:4:0","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——实践篇（一）","uri":"/2024-05-06/mysql45-2/"},{"categories":["mysql"],"content":"13 | 为什么表数据删掉一半，表文件大小不变？ 如果使用 delete 是无法收缩表占用空间的。删除的数据只会标注上可复用的标记。需要使用 alter table 命令重建表。同时 Online DDL 的方式可以考虑在业务低峰期使用。 锁表DDL流程 Online DDL流程 alter table t engine = InnoDB（也就是 recreate）； analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了 MDL 读锁； optimize table t 等于 recreate+analyze。 ","date":"2024-05-06","objectID":"/2024-05-06/mysql45-2/:5:0","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——实践篇（一）","uri":"/2024-05-06/mysql45-2/"},{"categories":["mysql"],"content":"14 | count(*)这么慢，我该怎么办？ InnoDB 获取表记录数量时，会选择扫描行数少的索引，把所有匹配的记录扫描出来。 可以使用额外的存储记录总数，推荐用上 InnoDB 的事务进行计数。 效率排序：$count(字段)\u003ccount(pk)\u003ccount(1)\\approx count(*)$ ","date":"2024-05-06","objectID":"/2024-05-06/mysql45-2/:6:0","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——实践篇（一）","uri":"/2024-05-06/mysql45-2/"},{"categories":["mysql"],"content":"15 | 答疑文章（一）：日志和索引相关问题 ","date":"2024-05-06","objectID":"/2024-05-06/mysql45-2/:7:0","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——实践篇（一）","uri":"/2024-05-06/mysql45-2/"},{"categories":["mysql"],"content":"如何判断 binlog 是否完整 statement 格式的 binlog，最后会有 commit row 格式的 binlog，最后会有 XID event 同时引入 binlog-checksum 验证内容的正确性。 ","date":"2024-05-06","objectID":"/2024-05-06/mysql45-2/:7:1","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——实践篇（一）","uri":"/2024-05-06/mysql45-2/"},{"categories":["mysql"],"content":"redo log 和 binlog 如何关联 它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log： 如果碰到既有 prepare、又有 commit 的 redo log，就直接提交； 如果碰到只有 prepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。 ","date":"2024-05-06","objectID":"/2024-05-06/mysql45-2/:7:2","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——实践篇（一）","uri":"/2024-05-06/mysql45-2/"},{"categories":["mysql"],"content":"最终数据落盘，来自 redo log 还是 buffer pool redo log 并没有记录数据页的完整数据，所以它并没有能力自己去更新磁盘数据页 如果是正常运行的实例的话，数据页被修改以后，跟磁盘的数据页不一致，称为脏页。最终数据落盘，就是把内存中的数据页写盘。这个过程，甚至与 redo log 毫无关系。 在崩溃恢复场景中，InnoDB 如果判断到一个数据页可能在崩溃恢复的时候丢失了更新，就会将它读到内存，然后让 redo log 更新内存内容。更新完成后，内存页变成脏页，就回到了第一种情况的状态。 ","date":"2024-05-06","objectID":"/2024-05-06/mysql45-2/:7:3","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——实践篇（一）","uri":"/2024-05-06/mysql45-2/"},{"categories":["mysql"],"content":"16 | “order by”是怎么工作的？ 全字段排序：如果 sort_buffer_size 满足需要排序的内容大小，则进行全字段排序。 rowid 排序：如果不能满足内存排序大小，使用 rowid 排序，但是需要再回到原表去取数据。 覆盖索引排序：根据查询选择特定的索引，由于索引具有有序性，所以不需要进行排序，直接取出数据即可。 ","date":"2024-05-06","objectID":"/2024-05-06/mysql45-2/:8:0","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——实践篇（一）","uri":"/2024-05-06/mysql45-2/"},{"categories":["mysql"],"content":"17 | 如何正确地显示随机消息？ 主要思想就是减少数据库的扫描行数。例如先随机出一个 id，找到第一个小于等于该 id 的数据，这样子通过索引只需要扫描一行。还有通过limit Y,1需要扫描 Y+1 行。 ","date":"2024-05-06","objectID":"/2024-05-06/mysql45-2/:9:0","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——实践篇（一）","uri":"/2024-05-06/mysql45-2/"},{"categories":["mysql"],"content":"关于 MySQL 基础架构、日志系统、事务、索引和锁的相关概念 ","date":"2024-05-04","objectID":"/2024-05-04/mysql45-1/:0:0","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——基础篇","uri":"/2024-05-04/mysql45-1/"},{"categories":["mysql"],"content":"01 | 基础架构：一条 SQL 查询语句是如何执行的？ MySQL 的逻辑架构可分为 Server 层和存储引擎层。 Server 层包括了连接器、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。 而存储引擎层负责数据的存储和提取。其架构模式为插件式，支持 InnoDB、MyISAM、Memory 等多个存储引擎。 MySQL架构图 ","date":"2024-05-04","objectID":"/2024-05-04/mysql45-1/:1:0","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——基础篇","uri":"/2024-05-04/mysql45-1/"},{"categories":["mysql"],"content":"连接器 主要工作负责与客户端连接。通过认证之后根据权限表得到拥有的权限，之后的操作权限判定都会依靠此时获取的权限信息。 对于长连接内存占用太大的问题，原因是 MySQL 在执行过程中临时使用的内存是管理在连接对象里的。这些资源会在连接断开的时候才释放。解决方案： 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。 如果使用 MySQL 5.7 或以上版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。 ","date":"2024-05-04","objectID":"/2024-05-04/mysql45-1/:1:1","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——基础篇","uri":"/2024-05-04/mysql45-1/"},{"categories":["mysql"],"content":"分析器 工作是对 SQL 语句做一个“词法分析”，识别字符串。识别完成之后做“语法分析”，根据语法规则判断是否符合 MySQL 语法。 ","date":"2024-05-04","objectID":"/2024-05-04/mysql45-1/:1:2","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——基础篇","uri":"/2024-05-04/mysql45-1/"},{"categories":["mysql"],"content":"优化器 经过分析器的处理，已经知道了要做什么操作。在执行之前，需要对操作进行优化。优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序 ","date":"2024-05-04","objectID":"/2024-05-04/mysql45-1/:1:3","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——基础篇","uri":"/2024-05-04/mysql45-1/"},{"categories":["mysql"],"content":"执行器 MySQL 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。执行步骤如下： 判断是否拥有权限，若没有，则返回权限错误。 根据表的引擎去调用引擎提供的接口。 ","date":"2024-05-04","objectID":"/2024-05-04/mysql45-1/:1:4","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——基础篇","uri":"/2024-05-04/mysql45-1/"},{"categories":["mysql"],"content":"02 | 日志系统：一条 SQL 更新语句是如何执行的？ MySQL 重要的日志模块有 redo log 和 binlog。 redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。 sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。 ","date":"2024-05-04","objectID":"/2024-05-04/mysql45-1/:2:0","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——基础篇","uri":"/2024-05-04/mysql45-1/"},{"categories":["mysql"],"content":"redo log 该日志模块的关键点在于 WAL（Write Ahead Logging），即先写日志，再写磁盘。避免了更新时找到对应日志记录，修改相关数据，最后再写入磁盘所花费的 I/O 代价。InnoDB 会在合适的时候将 redo log 上的记录更新到磁盘中。 redo log示意图 write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。 write pos 和 checkpoint 之间的是 redo log 上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示 redo log 满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。 有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 crash-safe。 ","date":"2024-05-04","objectID":"/2024-05-04/mysql45-1/:2:1","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——基础篇","uri":"/2024-05-04/mysql45-1/"},{"categories":["mysql"],"content":"binlog redo log 是 InnoDB 自带的日志系统，而 Server 层的日志模块是 binlog。 它们之间的区别如下： redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。 redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。 redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 执行器和 InnoDB 引擎在执行update T set c=c+1 where ID=2;语句时的内部流程。 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。 update 语句的执行流程图，图中浅色框表示是在 InnoDB 内部执行的，深色框表示是在执行器中执行的。 update语句执行流程 ","date":"2024-05-04","objectID":"/2024-05-04/mysql45-1/:2:2","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——基础篇","uri":"/2024-05-04/mysql45-1/"},{"categories":["mysql"],"content":"两阶段提交 上图可以注意到，在 redo log 中，存在 prepare 和 commit 两个阶段。两阶段提交就是让 redo log 和 binlog 这两个状态保持逻辑上的一致。 ","date":"2024-05-04","objectID":"/2024-05-04/mysql45-1/:2:3","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——基础篇","uri":"/2024-05-04/mysql45-1/"},{"categories":["mysql"],"content":"03 | 事务隔离：为什么你改了我还看不见？ 事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在 MySQL 中，事务支持是在引擎层实现的。 ","date":"2024-05-04","objectID":"/2024-05-04/mysql45-1/:3:0","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——基础篇","uri":"/2024-05-04/mysql45-1/"},{"categories":["mysql"],"content":"隔离性与隔离级别 读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。 读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。 可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。 串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。 在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。 ","date":"2024-05-04","objectID":"/2024-05-04/mysql45-1/:3:1","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——基础篇","uri":"/2024-05-04/mysql45-1/"},{"categories":["mysql"],"content":"事务隔离的实现 undo log示意图 对于每个事务的视图，想要获取视图的值，就得将当前值依次执行图中所有的回滚操作得到。 当系统里没有比这个 undo log 更早的 read-view 的时候，会将这个 undo log 删除。 ","date":"2024-05-04","objectID":"/2024-05-04/mysql45-1/:3:2","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——基础篇","uri":"/2024-05-04/mysql45-1/"},{"categories":["mysql"],"content":"事务的启动方式 显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。 set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。 建议使用 set autocommit=1, 通过显式语句的方式来启动事务。 在 autocommit 为 1 的情况下，用 begin 显式启动的事务，如果执行 commit 则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行 begin 语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。 ","date":"2024-05-04","objectID":"/2024-05-04/mysql45-1/:3:3","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——基础篇","uri":"/2024-05-04/mysql45-1/"},{"categories":["mysql"],"content":"如何避免长事务对业务的影响？ 从应用开发端来看： 确认是否使用了 set autocommit=0。这个确认工作可以在测试环境中开展，把 MySQL 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 1。 确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 begin/commit 框起来。我见过有些是业务并没有这个需要，但是也把好几个 select 语句放到了事务中。这种只读事务可以去掉。 业务连接数据库的时候，根据业务本身的预估，通过 SET MAX_EXECUTION_TIME 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。 从数据库端来看： 监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 / 或者 kill； Percona 的 pt-kill 这个工具不错，推荐使用； 在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题； 如果使用的是 MySQL 5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。 ","date":"2024-05-04","objectID":"/2024-05-04/mysql45-1/:3:4","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——基础篇","uri":"/2024-05-04/mysql45-1/"},{"categories":["mysql"],"content":"04\u002605 | 深入浅出索引 索引的作用是用于加快数据的查询操作。 ","date":"2024-05-04","objectID":"/2024-05-04/mysql45-1/:4:0","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——基础篇","uri":"/2024-05-04/mysql45-1/"},{"categories":["mysql"],"content":"索引的常见模型 哈希表：只适用于等值查询的场景 有序数组：等值查询和范围查询场景中的性能都非常优秀 树：维护和查询的操作都是 log(n) 其中，InnoDB 的存储引擎使用 B+Tree 作为底层数据结构。 ","date":"2024-05-04","objectID":"/2024-05-04/mysql45-1/:4:1","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——基础篇","uri":"/2024-05-04/mysql45-1/"},{"categories":["mysql"],"content":"覆盖索引 如果执行的语句是 select ID from T where k between 3 and 5，这时只需要查 ID 的值，而 ID 的值已经在 k 索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖索引。 覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。 ","date":"2024-05-04","objectID":"/2024-05-04/mysql45-1/:4:2","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——基础篇","uri":"/2024-05-04/mysql45-1/"},{"categories":["mysql"],"content":"06 | 全局锁和表锁 ：给表加个字段怎么有这么多阻碍？ 根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类。 数据库锁设计的初衷是处理并发问题。作为多用户共享的资源，当出现并发访问的时候，数据库需要合理地控制资源的访问规则。而锁就是用来实现这些访问规则的重要数据结构。 ","date":"2024-05-04","objectID":"/2024-05-04/mysql45-1/:5:0","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——基础篇","uri":"/2024-05-04/mysql45-1/"},{"categories":["mysql"],"content":"全局锁 全局锁主要用在逻辑备份过程中。对于全部是 InnoDB 引擎的库，建议你选择使用 –-single-transaction 参数，对应用会更友好。但 --single-transaction 方法只适用于所有的表使用事务引擎的库。 MySQL 提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。 ","date":"2024-05-04","objectID":"/2024-05-04/mysql45-1/:5:1","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——基础篇","uri":"/2024-05-04/mysql45-1/"},{"categories":["mysql"],"content":"表级锁 MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL）。 表锁的语法是 lock tables … read/write。可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。InnoDB 支持行锁，因此表锁的使用场景不多。 另一类表级的锁是 MDL（metadata lock）。MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。 ","date":"2024-05-04","objectID":"/2024-05-04/mysql45-1/:5:2","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——基础篇","uri":"/2024-05-04/mysql45-1/"},{"categories":["mysql"],"content":"如何安全地给小表加字段？ 主要思想是避免长事务，一个方法是在alter table语句中加入等待时间。或者 kill 长事务。 ","date":"2024-05-04","objectID":"/2024-05-04/mysql45-1/:5:3","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——基础篇","uri":"/2024-05-04/mysql45-1/"},{"categories":["mysql"],"content":"07 | 行锁功过：怎么减少行锁对性能的影响？ 如果事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。 ","date":"2024-05-04","objectID":"/2024-05-04/mysql45-1/:6:0","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——基础篇","uri":"/2024-05-04/mysql45-1/"},{"categories":["mysql"],"content":"死锁与死锁检测 当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。 死锁出现的情况 当出现死锁以后，有两种策略： 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。 怎么解决由这种热点行更新导致的性能问题呢？ 一个方法是关闭死锁检测。另一个方法是控制并发度（最好在服务端进行控制） ","date":"2024-05-04","objectID":"/2024-05-04/mysql45-1/:6:1","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——基础篇","uri":"/2024-05-04/mysql45-1/"},{"categories":["mysql"],"content":"08 | 事务到底是隔离的还是不隔离的？ ","date":"2024-05-04","objectID":"/2024-05-04/mysql45-1/:7:0","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——基础篇","uri":"/2024-05-04/mysql45-1/"},{"categories":["mysql"],"content":"“快照”在 MVCC 里是怎么工作的？ InnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。 而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。 也就是说，数据表中的一行记录，其实可能有多个版本 (row)，每个版本有自己的 row trx_id。 记录行多个事务更新状态图 在实现上， InnoDB 为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务 ID。“活跃”指的就是，启动了但还没提交。 数组里面事务 ID 的最小值记为低水位，当前系统里面已经创建过的事务 ID 的最大值加 1 记为高水位。 这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。 数据版本可见性规则 这样，对于当前事务的启动瞬间来说，一个数据版本的 row trx_id，有以下几种可能： 如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的； 如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的； 如果落在黄色部分，那就包括两种情况： 若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见； 若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。 因此，在一个事务视图的数据版本中，有三种情况： 版本未提交，不可见； 版本已提交，但是是在视图创建后提交的，不可见； 版本已提交，而且是在视图创建前提交的，可见。 ","date":"2024-05-04","objectID":"/2024-05-04/mysql45-1/:7:1","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——基础篇","uri":"/2024-05-04/mysql45-1/"},{"categories":["mysql"],"content":"更新逻辑 更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。当然在加锁操作的情况下，select 操作也会用到当前读。 ","date":"2024-05-04","objectID":"/2024-05-04/mysql45-1/:7:2","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——基础篇","uri":"/2024-05-04/mysql45-1/"},{"categories":["mysql"],"content":"事务的可重复读的能力是怎么实现的？ 可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。 而读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是： 在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图； 在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。 ","date":"2024-05-04","objectID":"/2024-05-04/mysql45-1/:7:3","tags":["mysql","mysql实战45讲"],"title":"《MySQL实战45讲》阅读笔记——基础篇","uri":"/2024-05-04/mysql45-1/"},{"categories":["blog"],"content":"记录本科毕设的需求、进度 目前进度 数据库 数据库设计 prompt_option: prompt 选项表 resource: 资源表 role: 角色表 role_resource_rel: 角色-资源关联表 sys_param: 系统参数表 user_basic: 用户表 api_log: API 日志表 资源初始化 后端服务 API 登录/注册/登出 PhotoMaker 权限模块 角色管理：增删改查 用户管理：增删改查 资源树管理：增删改查 Prompt 管理：增删改查 系统参数管理：增删改查 API 日志模块：增查 中间件 JWT 认证 业务限流器 缓存限流次数 API 日志记录 字段脱敏 优化 对 DB 封装一层 Redis 缓存 前端页面 身份认证功能：登录/注册/登出 首页业务页面：魔力照相机 系统管理页面 角色管理页面 资源管理页面 用户管理页面 Prompt 管理页面 系统参数管理页面 监控视图页面 服务器监控面板 Go 进程监控面板 Redis 监控面板 MySQL 监控面板 WEB API 监控面板 API 日志查询页面 测试 登录/注册/登出 业务模块 后台管理模块 权限模块 用户模块 角色模块 Prompt 模块 系统参数模块 监控模块 服务器监控面板 Go 进程监控面板 Redis 监控面板 MySQL 监控面板 WEB API 监控面板 日志模块 运维相关 流水线发布（前端） 流水线发布（后端） Nginx 部署 MySQL 部署 Redis 部署 监控组件部署 Prometheus 部署 node_exporter 部署 mysqld_exporter 部署 redis_exporter 部署 Grafana 部署 服务器 Dashboard Go 进程 Dashboard Redis Dashboard MySQL Dashboard WEB API Dashboard SSL/TLS 证书 日志 Prompt 设置 ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:0:0","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"数据库设计 单体服务，采用 mysql 作为底层数据库，使用 redis 做缓存数据库。 ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:1:0","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"权限模块 通过 RBAC 模型的方式，基于角色控制资源权限，表字段设计如下： 用户表 字段名 类型 NULL Key Default Extra id bigint unsigned NO PRI null auto_increment created_at datetime YES null updated_at datetime YES null deleted_at datetime YES null username varchar(50) NO UNI null password_hash varchar(255) NO null role_id bigint unsigned NO MUL 0 last_login datetime YES null is_enable tinyint(1) YES null biz_count bigint unsigned YES 0 建表语句： CREATE TABLE `user_basic` ( `id` bigint unsigned NOT NULL AUTO_INCREMENT COMMENT '序号', `created_at` datetime DEFAULT NULL COMMENT '创建时间', `updated_at` datetime DEFAULT NULL COMMENT '更新时间', `deleted_at` datetime DEFAULT NULL COMMENT '删除时间', `username` varchar(50) NOT NULL COMMENT '用户名', `password_hash` varchar(255) NOT NULL COMMENT '加密过后的密码', `role_id` bigint unsigned NOT NULL DEFAULT '0' COMMENT '所属角色', `last_login` datetime DEFAULT NULL COMMENT '最后登录时间', `is_enable` tinyint(1) DEFAULT NULL COMMENT '是否启用:1-启用;0-禁用', `biz_count` bigint unsigned DEFAULT '0' COMMENT '使用业务接口次数', PRIMARY KEY (`id`), UNIQUE KEY `username` (`username`), KEY `fk_user_role` (`role_id`), CONSTRAINT `fk_user_role` FOREIGN KEY (`role_id`) REFERENCES `role` (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=16 DEFAULT CHARSET=utf8mb3 COMMENT='用户表'; 资源表 字段名 类型 Null Key Default Extra id bigint unsigned NO PRI null auto_increment created_at datetime YES null updated_at datetime YES null deleted_at datetime YES null name varchar(255) NO code varchar(255) NO type varchar(255) NO parent_id bigint unsigned NO 0 order int NO 0 icon varchar(512) NO component varchar(512) NO path varchar(512) NO is_show tinyint(1) NO 0 is_enable tinyint(1) NO 0 建表语句： CREATE TABLE `resource` ( `id` bigint unsigned NOT NULL AUTO_INCREMENT COMMENT '序号', `created_at` datetime DEFAULT NULL COMMENT '创建时间', `updated_at` datetime DEFAULT NULL COMMENT '更新时间', `deleted_at` datetime DEFAULT NULL COMMENT '删除时间', `name` varchar(255) NOT NULL DEFAULT '' COMMENT '名称', `code` varchar(255) NOT NULL DEFAULT '' COMMENT '编码', `type` varchar(255) NOT NULL DEFAULT '' COMMENT '类型', `parent_id` bigint unsigned NOT NULL DEFAULT '0' COMMENT '父节点id', `order` int NOT NULL DEFAULT '0' COMMENT '排序', `icon` varchar(512) NOT NULL DEFAULT '' COMMENT '菜单图标', `component` varchar(512) NOT NULL DEFAULT '' COMMENT '组件路径', `path` varchar(512) NOT NULL DEFAULT '' COMMENT '路由地址', `is_show` tinyint(1) NOT NULL DEFAULT '0' COMMENT '是否显示', `is_enable` tinyint(1) NOT NULL DEFAULT '0' COMMENT '是否启用', PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=22 DEFAULT CHARSET=utf8mb3 COMMENT='资源表'; 角色-资源关联表 字段名 类型 Null Key Default Extra id bigint unsigned NO PRI null auto_increment created_at datetime YES null updated_at datetime YES null deleted_at datetime YES null role_id bigint unsigned NO MUL 0 resource_id bigint unsigned NO MUL 0 建表语句： CREATE TABLE `role_resource_rel` ( `id` bigint unsigned NOT NULL AUTO_INCREMENT COMMENT '序号', `created_at` datetime DEFAULT NULL COMMENT '创建时间', `updated_at` datetime DEFAULT NULL COMMENT '更新时间', `deleted_at` datetime DEFAULT NULL COMMENT '删除时间', `role_id` bigint unsigned NOT NULL DEFAULT '0' COMMENT '角色id', `resource_id` bigint unsigned NOT NULL DEFAULT '0' COMMENT '资源id', PRIMARY KEY (`id`), KEY `fk_role` (`role_id`), KEY `fk_resource` (`resource_id`), CONSTRAINT `fk_resource` FOREIGN KEY (`resource_id`) REFERENCES `resource` (`id`), CONSTRAINT `fk_role` FOREIGN KEY (`role_id`) REFERENCES `role` (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=17 DEFAULT CHARSET=utf8mb3 COMMENT='角色-资源表'; 角色表 字段名 类型 Null Key Default Extra id bigint unsigned NO PRI null auto_increment created_at datetime YES null updated_at datetime YES null deleted_at datetime YES null code varchar(255) NO UNI name varchar(255) NO UNI is_enable tinyint(1) NO 0 建表语句： CREATE TABLE `role` ( `id` bigint unsigned NOT NULL AUTO_INCREMENT COMMENT '序号', `created_at` datetime DEFAULT NULL COMMENT '创建时间', `updated_at` datetime DEFAULT NULL COMMENT '更新时间', `deleted_at` datetime DEFAULT NULL COMMENT '删除时间', `code` varchar(255) NOT NULL DEFAULT '' COMMENT '角色编码', `name` ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:1:1","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"业务模块 需要给用户提供一个下拉选项，并且对应 prompt 中英文。 造型选项表 Field Type Null Key Default Extra id bigint unsigned NO PRI null auto_increment created_at datetime YES null updated_at datetime YES null deleted_at datetime YES null name varchar(255) NO UNI prompt text YES null negative_prompt text YES null desc varchar(255) NO 建表语句： CREATE TABLE `prompt_option` ( `id` bigint unsigned NOT NULL AUTO_INCREMENT COMMENT '序号', `created_at` datetime DEFAULT NULL COMMENT '创建时间', `updated_at` datetime DEFAULT NULL COMMENT '更新时间', `deleted_at` datetime DEFAULT NULL COMMENT '删除时间', `name` varchar(255) NOT NULL DEFAULT '' COMMENT '选项名', `prompt` text COMMENT 'prompt', `negative_prompt` text COMMENT '负面prompt', `desc` varchar(255) NOT NULL DEFAULT '' COMMENT '描述', PRIMARY KEY (`id`), UNIQUE KEY `name` (`name`) ) ENGINE=InnoDB AUTO_INCREMENT=5 DEFAULT CHARSET=utf8mb3 COMMENT='prompt选项表'; ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:1:2","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"系统模块 系统参数表 字段名 字段类型 Null Key Default Extra id bigint unsigned NO PRI null auto_increment created_at datetime YES null updated_at datetime YES null deleted_at datetime YES null key varchar(255) NO UNI null value text YES null desc varchar(255) NO 建表语句： CREATE TABLE `sys_param` ( `id` bigint unsigned NOT NULL AUTO_INCREMENT COMMENT '序号', `created_at` datetime DEFAULT NULL COMMENT '创建时间', `updated_at` datetime DEFAULT NULL COMMENT '更新时间', `deleted_at` datetime DEFAULT NULL COMMENT '删除时间', `key` varchar(255) NOT NULL COMMENT '键', `value` text COMMENT '值', `desc` varchar(255) NOT NULL DEFAULT '' COMMENT '描述', PRIMARY KEY (`id`), UNIQUE KEY `key` (`key`) ) ENGINE=InnoDB AUTO_INCREMENT=13 DEFAULT CHARSET=utf8mb3 COMMENT='系统参数表'; ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:1:3","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"日志模块 字段名 字段类型 Null Key Default Extra id bigint unsigned NO PRI null auto_increment created_at datetime YES null method varchar(64) NO null api_path text NO null req_header mediumtext YES null req_body mediumtext YES null status varchar(64) NO null operator varchar(255) NO null remote_ip varchar(255) YES null remote_city varchar(255) YES null response longtext YES null cost_time bigint unsigned NO null 建表语句： CREATE TABLE `api_log` ( `id` bigint unsigned NOT NULL AUTO_INCREMENT COMMENT '序号', `created_at` datetime DEFAULT NULL COMMENT '创建时间', `method` varchar(64) NOT NULL COMMENT 'http方法', `api_path` text NOT NULL COMMENT 'api路径', `req_header` mediumtext COMMENT '请求头', `req_body` mediumtext COMMENT '请求body', `status` varchar(64) NOT NULL COMMENT '状态', `operator` varchar(255) NOT NULL COMMENT '操作人', `remote_ip` varchar(255) DEFAULT NULL COMMENT '操作ip', `remote_city` varchar(255) DEFAULT NULL COMMENT '操作地点', `response` longtext COMMENT '返回结果', `cost_time` bigint unsigned NOT NULL COMMENT '请求耗时，单位：ms', PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=85 DEFAULT CHARSET=utf8mb3 COMMENT='API日志表'; ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:1:4","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"数据初始化 insert into magic_camera.resource (id, created_at, updated_at, deleted_at, name, code, type, parent_id, order, icon, component, path, is_show, is_enable) values (1, '2024-04-06 07:04:23', '2024-04-06 07:13:28', null, '资源管理', 'Resource_Mgt', 'MENU', 2, 1, 'i-fe:list', '/src/views/sys/resource/index.vue', '/pms/resource', 1, 1), (2, '2024-04-06 07:04:53', '2024-04-06 07:04:53', null, '系统管理', 'SysMgt', 'MENU', 0, 2, 'i-fe:grid', '', '', 1, 1), (3, '2024-04-06 07:05:00', '2024-04-06 07:13:28', null, '角色管理', 'RoleMgt', 'MENU', 2, 2, 'i-fe:user-check', '/src/views/sys/role/index.vue', '/pms/role', 1, 1), (4, '2024-04-06 07:05:00', '2024-04-06 07:13:28', null, '用户管理', 'UserMgt', 'MENU', 2, 3, 'i-fe:user', '/src/views/sys/user/index.vue', '/pms/user', 1, 1), (5, '2024-04-06 07:05:01', '2024-04-06 07:13:28', null, '分配用户', 'RoleUser', 'MENU', 3, 1, 'i-fe:user-plus', '/src/views/sys/role/role-user.vue', '/pms/role/user/:roleId', 1, 1), (8, '2024-04-06 07:05:01', '2024-04-06 07:05:01', null, '个人资料', 'UserProfile', 'MENU', 0, 99, 'i-fe:user', '/src/views/profile/index.vue', '/profile', 0, 1); ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:1:5","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"AI 模型需求 ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:2:0","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"PhotoMaker 使用 PhotoMaker 作为 AI Work，底层用到了 Stable Diffusion 和 LoRA 微调。 ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:2:1","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"AI 部署 模型算法部署在了 Replicate 上，通过 http 接口的方式暴露给后端使用。 ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:2:2","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"接口列表 ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:0","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"1. “分页查询 API 日志” route definition Url: /api/v1/api-log Method: GET Request: GetApiLogReq Response: GetApiLogResp request definition type GetApiLogReq struct { Page int `form:\"page,default=1\"` Size int `form:\"size,default=10\"` Method string `form:\"method,optional\"` APIPath string `form:\"apiPath,optional\"` Status string `form:\"status,optional\"` Operator string `form:\"operator,optional\"` RemoteIP string `form:\"remoteIp,optional\"` RemoteCity string `form:\"remoteCity,optional\"` } response definition type GetApiLogResp struct { Items []*ApiLog `json:\"items\"` Total int64 `json:\"total\"` } ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:1","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"2. “用户登录” route definition Url: /api/v1/user/login Method: POST Request: UserLoginReq Response: UserLoginResp request definition type UserLoginReq struct { Username string `json:\"username\"` Password string `json:\"password\"` Captcha string `json:\"captcha\"` CaptchaId string `json:\"captchaId\"` } response definition type UserLoginResp struct { Token string `json:\"token\"` } ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:2","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"3. “用户注册” route definition Url: /api/v1/user/register Method: POST Request: UserRegisterReq Response: UserRegisterResp request definition type UserRegisterReq struct { Username string `json:\"username\"` Password string `json:\"password\"` Captcha string `json:\"captcha\"` CaptchaId string `json:\"captchaId\"` } response definition type UserRegisterResp struct { Token string `json:\"token\"` } ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:3","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"4. “用户登出” route definition Url: /api/v1/user/logout Method: POST Request: - Response: - request definition response definition ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:4","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"5. “获取四位验证码” route definition Url: /api/v1/captcha Method: GET Request: - Response: GetCaptchaResp request definition response definition type GetCaptchaResp struct { CaptchaId string `json:\"captcha_id\"` B64s string `json:\"b64s\"` } ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:5","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"6. “获取 tmp 目录下文件” route definition Url: /api/v1/file/:dir/:filename Method: GET Request: GetFileReq Response: - request definition type GetFileReq struct { Dir string `path:\"dir\"` Filename string `path:\"filename\"` } response definition ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:6","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"7. “探活 ping” route definition Url: /ping Method: GET Request: - Response: - request definition response definition ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:7","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"8. “生成照片” route definition Url: /api/v1/generate/photo Method: POST Request: GeneratePhotoReq Response: GeneratePhotoResp request definition type GeneratePhotoReq struct { Images []string `form:\"-\"` Style string `form:\"style\"` Gender string `form:\"gender\"` PromptId uint64 `form:\"promptId\"` Version string `form:\"version\"` } response definition type GeneratePhotoResp struct { Output string `json:\"output\"` Images []string `json:\"images\"` Style string `json:\"style\"` Gender string `json:\"gender\"` PromptId uint64 `json:\"promptId\"` Version string `json:\"version\"` } ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:8","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"9. “获取角色权限树” route definition Url: /api/v1/role/permissions/tree Method: GET Request: - Response: GetResourceTreeResp request definition response definition type GetResourceTreeResp struct { Resource []*Resource `json:\"resource\"` } ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:9","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"10. “分页查询 Prompt Option” route definition Url: /api/v1/prompt-option Method: GET Request: GetPromptOptionReq Response: GetPromptOptionResp request definition type GetPromptOptionReq struct { Page int `form:\"page,default=1\"` Size int `form:\"size,default=10\"` Name string `form:\"name,optional\"` Prompt string `form:\"prompt,optional\"` NegativePrompt string `form:\"negativePrompt,optional\"` // 负面prompt Desc string `form:\"desc,optional\"` } response definition type GetPromptOptionResp struct { Items []*PromptOption `json:\"items\"` Total int64 `json:\"total\"` } ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:10","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"11. “新增 Prompt Option” route definition Url: /api/v1/prompt-option Method: POST Request: AddPromptOptionReq Response: AddPromptOptionResp request definition type AddPromptOptionReq struct { Name string `json:\"name\"` // 选项名 Prompt string `json:\"prompt\"` // prompt NegativePrompt string `json:\"negativePrompt\"` // 负面prompt Desc string `json:\"desc,optional\"` // 描述 } response definition type AddPromptOptionResp struct { ID uint64 `json:\"id\"` } ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:11","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"12. “修改 Prompt Option” route definition Url: /api/v1/prompt-option/:id Method: PUT Request: UpdatePromptOptionReq Response: - request definition type UpdatePromptOptionReq struct { ID uint64 `path:\"id\"` // 序号 Name string `json:\"name\"` // 选项名 Prompt string `json:\"prompt\"` // prompt NegativePrompt string `json:\"negativePrompt\"` // 负面prompt Desc string `json:\"desc,optional\"` // 描述 } response definition ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:12","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"13. “删除 Prompt Option” route definition Url: /api/v1/prompt-option/:id Method: DELETE Request: DeletePromptOptionReq Response: - request definition type DeletePromptOptionReq struct { ID uint64 `path:\"id\"` } response definition ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:13","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"14. “获取全部 Prompt Option” route definition Url: /api/v1/prompt-option/all Method: GET Request: GetPromptOptionReq Response: GetPromptOptionResp request definition type GetPromptOptionReq struct { Page int `form:\"page,default=1\"` Size int `form:\"size,default=10\"` Name string `form:\"name,optional\"` Prompt string `form:\"prompt,optional\"` NegativePrompt string `form:\"negativePrompt,optional\"` // 负面prompt Desc string `form:\"desc,optional\"` } response definition type GetPromptOptionResp struct { Items []*PromptOption `json:\"items\"` Total int64 `json:\"total\"` } ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:14","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"15. “新增资源” route definition Url: /api/v1/resource Method: POST Request: AddResourceReq Response: AddResourceResp request definition type AddResourceReq struct { Name string `json:\"name\"` Code string `json:\"code\"` Type string `json:\"type,optional\"` ParentID int `json:\"parentId,optional\"` Path string `json:\"path,optional\"` Icon string `json:\"icon,optional\"` Component string `json:\"component,optional\"` IsShow bool `json:\"isShow,optional\"` IsEnable bool `json:\"isEnable,optional\"` Order int `json:\"order\"` } response definition type AddResourceResp struct { ID uint64 `json:\"id\"` } ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:15","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"16. “修改资源” route definition Url: /api/v1/resource/:id Method: PUT Request: SaveResourceReq Response: SaveResourceResp request definition type SaveResourceReq struct { ID uint64 `path:\"id\"` Name string `json:\"name\"` Code string `json:\"code\"` Type string `json:\"type,optional\"` ParentID int `json:\"parentId,optional\"` Path string `json:\"path,optional\"` Icon string `json:\"icon,optional\"` Component string `json:\"component,optional\"` IsShow bool `json:\"isShow,optional\"` IsEnable bool `json:\"isEnable,optional\"` Order int `json:\"order\"` } response definition type SaveResourceResp struct { ID uint64 `json:\"id\"` } ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:16","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"17. “删除资源” route definition Url: /api/v1/resource/:id Method: DELETE Request: DeleteResourceReq Response: DeleteResourceResp request definition type DeleteResourceReq struct { ID uint64 `path:\"id\"` } response definition type DeleteResourceResp struct { DelectCount int `json:\"deleteCount\"` } ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:17","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"18. “获取菜单资源树” route definition Url: /api/v1/resource/menu/tree Method: GET Request: - Response: GetResourceTreeResp request definition response definition type GetResourceTreeResp struct { Resource []*Resource `json:\"resource\"` } ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:18","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"19. “给用户分配角色” route definition Url: /api/v1/assign/roles Method: PUT Request: AssignRolesReq Response: - request definition type AssignRolesReq struct { ID uint64 `json:\"id\"` RoleId uint64 `json:\"roleId\"` Username string `json:\"username\"` } response definition ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:19","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"20. “新增角色” route definition Url: /api/v1/role Method: POST Request: AddRoleReq Response: AddRoleResp request definition type AddRoleReq struct { Code string `json:\"code\"` Name string `json:\"name\"` IsEnable bool `json:\"isEnable\"` ResourceIds []uint64 `json:\"resourceIds\"` } response definition type AddRoleResp struct { ID uint64 `json:\"id\"` } ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:20","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"21. “更新角色” route definition Url: /api/v1/role/:id Method: PUT Request: UpdateRoleReq Response: - request definition type UpdateRoleReq struct { ID uint64 `path:\"id\"` Code string `json:\"code\"` Name string `json:\"name\"` IsEnable bool `json:\"isEnable\"` ResourceIds []uint64 `json:\"resourceIds\"` } response definition ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:21","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"22. “删除角色” route definition Url: /api/v1/role/:id Method: DELETE Request: DeleteRoleReq Response: - request definition type DeleteRoleReq struct { ID uint64 `path:\"id\"` } response definition ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:22","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"23. “查询角色” route definition Url: /api/v1/role/all Method: GET Request: GetRoleAllReq Response: GetRoleAllResp request definition type GetRoleAllReq struct { Code string `form:\"code,optional\"` Name string `form:\"name,optional\"` IsEnable bool `form:\"isEnable,default=false\"` } response definition type GetRoleAllResp struct { Items []*Role `json:\"items\"` } ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:23","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"24. “分页查询角色” route definition Url: /api/v1/role/page Method: GET Request: GetRolePageReq Response: GetRolePageResp request definition type GetRolePageReq struct { Page int `form:\"page,default=1\"` Size int `form:\"size,default=10\"` Code string `form:\"code,optional\"` Name string `form:\"name,optional\"` } response definition type GetRolePageResp struct { Items []*Role `json:\"items\"` Total int64 `json:\"total\"` } ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:24","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"25. “分页查询系统参数” route definition Url: /api/v1/sys-param Method: GET Request: GetSysParamReq Response: GetSysParamResp request definition type GetSysParamReq struct { Page int `form:\"page,default=1\"` Size int `form:\"size,default=10\"` Key string `form:\"key,optional\"` Value string `form:\"value,optional\"` Desc string `form:\"desc,optional\"` } response definition type GetSysParamResp struct { Items []*SysParam `json:\"items\"` Total int64 `json:\"total\"` } ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:25","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"26. “新增系统参数” route definition Url: /api/v1/sys-param Method: POST Request: AddSysParamReq Response: AddSysParamResp request definition type AddSysParamReq struct { Key string `json:\"key\"` // 键 Value string `json:\"value\"` // 值 Desc string `json:\"desc,optional\"` // 描述 } response definition type AddSysParamResp struct { ID uint64 `json:\"id\"` } ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:26","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"27. “修改系统参数” route definition Url: /api/v1/sys-param/:id Method: PUT Request: UpdateSysParamReq Response: - request definition type UpdateSysParamReq struct { ID uint64 `path:\"id\"` // 序号 Key string `json:\"key\"` // 键 Value string `json:\"value\"` // 值 Desc string `json:\"desc,optional\"` // 描述 } response definition ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:27","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"28. “删除系统参数” route definition Url: /api/v1/sys-param/:id Method: DELETE Request: DeleteSysParamReq Response: - request definition type DeleteSysParamReq struct { ID uint64 `path:\"id\"` } response definition ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:28","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"29. “获取单个系统参数” route definition Url: /api/v1/sys-param/single Method: GET Request: GetSysParamReq Response: SysParam request definition type GetSysParamReq struct { Page int `form:\"page,default=1\"` Size int `form:\"size,default=10\"` Key string `form:\"key,optional\"` Value string `form:\"value,optional\"` Desc string `form:\"desc,optional\"` } response definition type SysParam struct { ID uint64 `json:\"id\"` // 序号 CreatedAt int64 `json:\"createdAt\"` // 创建时间 UpdatedAt int64 `json:\"updatedAt\"` // 更新时间 Key string `json:\"key\"` // 键 Value string `json:\"value\"` // 值 Desc string `json:\"desc\"` // 描述 } ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:29","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"30. “分页查询用户” route definition Url: /api/v1/user Method: GET Request: GetUserPageReq Response: GetUserPageResp request definition type GetUserPageReq struct { Page int `form:\"page,default=1\"` Size int `form:\"size,default=10\"` Username string `form:\"username,optional\"` // 用户名 } response definition type GetUserPageResp struct { Items []*User `json:\"items\"` Total int64 `json:\"total\"` } ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:30","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"31. “更新角色” route definition Url: /api/v1/user/:id Method: PUT Request: UpdateUserReq Response: - request definition type UpdateUserReq struct { ID uint64 `path:\"id\"` // 序号 IsEnable bool `json:\"isEnable\"` // 是否启用:0-禁用;1-启用 } response definition ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:31","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"32. “获取全部角色” route definition Url: /api/v1/user/all Method: GET Request: - Response: GetUserPageResp request definition response definition type GetUserPageResp struct { Items []*User `json:\"items\"` Total int64 `json:\"total\"` } ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:32","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"33. “获取用户详情” route definition Url: /api/v1/user/detail Method: GET Request: - Response: GetUserDetailResp request definition response definition type GetUserDetailResp struct { ID uint64 `json:\"id\"` // 序号 CreatedAt int64 `json:\"createdAt\"` // 创建时间 UpdatedAt int64 `json:\"updatedAt\"` // 更新时间 Username string `json:\"username\"` // 账号 LastLogin int64 `json:\"lastLogin\"` // 最后登录时间 IsEnable bool `json:\"isEnable\"` // 是否启用:0-禁用;1-启用 Role *Role `json:\"role\"` // 角色 } ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:33","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"34. “用户修改密码” route definition Url: /api/v1/user/password/change Method: POST Request: ChangeUserPasswordReq Response: - request definition type ChangeUserPasswordReq struct { OldPassword string `json:\"oldPassword\"` NewPassword string `json:\"newPassword\"` } response definition ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:34","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"35. “重置密码” route definition Url: /api/v1/user/password/reset/:id Method: PUT Request: ResetUserPasswordReq Response: - request definition type ResetUserPasswordReq struct { ID uint64 `path:\"id\"` Password string `json:\"password\"` } response definition ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:3:35","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"运维需求 ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:4:0","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"MySQL 服务部署 使用 docker 部署，具体见 docker compose 文件 ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:4:1","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"Redis 服务部署 使用 docker 部署，具体见 docker compose 文件 ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:4:2","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"Nginx 服务部署 使用 docker 部署，具体见 docker compose 文件 /usr/local/nginx/nginx.conf文件 user nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; # 注意要添加这一行 include /etc/nginx/conf.d/*.conf; } /usr/local/nginx/conf.d/default.conf文件 server{ listen 80; server_name localhost docker.xieboke.net; charset utf-8; client_max_body_size 32m; location / { # 此处一定要改成nginx容器中的目录地址，宿主机上的地址容器访问不到 # 命令必须用 root, 不能用 alias root /usr/share/nginx/html; try_files $uri $uri/ /index.html; index index.html index.htm; } location /file/ { proxy_pass http://[your_ip]:[your_port]/api/v1/file/; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } location ^~ /api/ { proxy_pass http://[your_ip]:[your_port]/api/v1/; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"upgrade\"; proxy_set_header X-Forwarded-Proto $scheme; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:4:3","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"Docker Compose 新建 docker-compose.yaml 文件，写入下列内容： version: \"3.7\" services: mysql: image: mysql:latest restart: always environment: MYSQL_ROOT_PASSWORD: your_mysql_password # 需要修改 MYSQL_DATABASE: your_database # 需要修改 ports: - \"3306:3306\" volumes: - mysql_data:/var/lib/mysql redis: image: redis:latest restart: always command: [ \"redis-server\", \"--requirepass\", your_redis_password, # 需要修改 \"--maxmemory\", \"512mb\", \"--maxmemory-policy\", \"allkeys-lru\", ] ports: - \"6379:6379\" nginx: image: nginx:latest ports: - \"80:80\" - \"443:443\" volumes: - /usr/local/nginx/html:/usr/share/nginx/html - /usr/local/nginx/www:/var/www - /usr/local/nginx/logs:/var/log/nginx - /usr/local/nginx/nginx.conf/:/etc/nginx/nginx.conf - /usr/local/nginx/etc/cert:/etc/nginx/cert - /usr/local/nginx/conf.d:/etc/nginx/conf.d restart: always environment: - NGINX_PORT=80 - TZ=Asia/Shanghai privileged: true volumes: mysql_data: 执行命令： docker compose up -d ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:4:4","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"前端部署 通过自写脚本，完成自动化发布流程： 打包 src 压缩 dist 目录成 dist.tar.gz 把压缩包上传到服务器 服务器解压缩目录到/usr/local/nginx/html 删除dist.tar.gz文件 deploy: @pnpm run build @tar -czvf dist.tar.gz -C dist . @scp dist.tar.gz server:/home/ubuntu @ssh server \"sudo tar -xzvf /home/ubuntu/dist.tar.gz -C /usr/local/nginx/html\" @rm dist.tar.gz ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:4:5","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"后端部署 通过 ansible 进行自动化部署 inventory文件： [web_servers] user@ip # 自行修改 ansible.yaml文件： --- - name: Deploy and restart service hosts: user@ip # 自行修改 become: yes tasks: - name: Stop remote service systemd: name: magic-camera.service state: stopped ignore_errors: yes - name: Copy compiled binary to remote server ansible.builtin.copy: src: ../target/magic-camera-amd64-linux dest: /usr/local/bin/magic-camera-backend/magic-camera mode: \"0755\" # 设置文件权限为可执行 - name: Copy config file to remote server ansible.builtin.copy: src: ../app/etc/config-product.yaml dest: /usr/local/bin/magic-camera-backend/config.yaml mode: \"0644\" - name: Start remote service systemd: name: magic-camera.service state: started - name: Get service status command: \"systemctl status magic-camera.service\" register: status_output - debug: msg: \"Service status: {{ status_output }}\" Makefile文件： TARGET_DIR=\"target\" BINARY_NAME=\"magic-camera\" MAIN_GO=app/app.go dep: @go mod download check: @go fmt ./... @go vet ./... build: dep check @mkdir -p ${TARGET_DIR} @GOARCH=arm64 GOOS=darwin go build -o ${TARGET_DIR}/${BINARY_NAME}-arm64-darwin ${MAIN_GO} @GOARCH=amd64 GOOS=darwin go build -o ${TARGET_DIR}/${BINARY_NAME}-amd64-darwin ${MAIN_GO} @GOARCH=amd64 GOOS=linux go build -o ${TARGET_DIR}/${BINARY_NAME}-amd64-linux ${MAIN_GO} @GOARCH=amd64 GOOS=windows go build -o ${TARGET_DIR}/${BINARY_NAME}-amd64-windows ${MAIN_GO} deploy: build @ansible-playbook -i ansible/inventory ansible/ansible.yaml ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:4:6","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"Prometheus 部署 下载 Prometheus 文件，并且放置到各个文件夹下 wget https://github.com/prometheus/prometheus/releases/download/v2.45.4/prometheus-2.45.4.linux-amd64.tar.gz tar -xvf prometheus-2.45.4.linux-amd64.tar.gz cd prometheus-2.45.4.linux-amd64.tar.gz sudo cp prometheus promtool /usr/local/bin sudo cp -r prometheus.yml consoles console_libraries /etc/prometheus 创建 Prometheus 服务 新建文件/etc/systemd/system/prometheus.service [Unit] Description=Prometheus Wants=network-online.target After=network-online.target [Service] User=root Group=root Type=simple Restart=always ExecStart=/usr/local/bin/prometheus \\ --config.file /etc/prometheus/prometheus.yml \\ --storage.tsdb.path /var/lib/prometheus/ \\ --web.console.templates=/etc/prometheus/consoles \\ --web.console.libraries=/etc/prometheus/console_libraries [Install] WantedBy=multi-user.target 启动服务 sudo systemctl daemon-reload sudo systemctl start prometheus sudo systemctl status prometheus 出现下列 active 信息即可，Prometheus 服务运行在:9090端口 ● prometheus.service - Prometheus Loaded: loaded (/etc/systemd/system/prometheus.service; disabled; vendor preset: enabled) Active: active (running) since Sun 2024-04-14 20:15:00 CST; 4 days ago Main PID: 3218298 (prometheus) Tasks: 9 (limit: 2247) Memory: 129.0M CGroup: /system.slice/prometheus.service └─3218298 /usr/local/bin/prometheus --config.file /etc/prometheus/prometheus.yml --storage.tsdb.path /var/\u003e Prometheus 配置文件：/etc/prometheus/prometheus.yml # my global config global: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s). # Alertmanager configuration alerting: alertmanagers: - static_configs: - targets: # - alertmanager:9093 # Load rules once and periodically evaluate them according to the global 'evaluation_interval'. rule_files: # - \"first_rules.yml\" # - \"second_rules.yml\" # A scrape configuration containing exactly one endpoint to scrape: # Here it's Prometheus itself. scrape_configs: # The job name is added as a label `job=\u003cjob_name\u003e` to any timeseries scraped from this config. - job_name: \"prometheus\" # metrics_path defaults to '/metrics' # scheme defaults to 'http'. static_configs: - targets: [\"localhost:9090\"] - job_name: \"node_exporter\" static_configs: - targets: [\"localhost:9100\"] - job_name: \"mysqld_exporter\" static_configs: - targets: [\"localhost:9104\"] - job_name: \"magic_camera\" static_configs: - targets: [\"localhost:6470\"] - job_name: \"redis_exporter\" static_configs: - targets: [\"localhost:9121\"] ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:4:7","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"部署 Node Exporter 下载 node_exporter 文件，并且放置到各个文件夹下 wget wget https://github.com/prometheus/node_exporter/releases/download/v1.7.0/node_exporter-1.7.0.linux-amd64.tar.gz tar -xvf node_exporter-1.7.0.linux-amd64.tar.gz cd node_exporter-1.7.0.linux-amd64.tar.gz sudo cp node_exporter /usr/local/bin 创建 node_exporter 服务 新建文件/etc/systemd/system/node_exporter.service [Unit] Description=Node Exporter Wants=network-online.target After=network-online.target [Service] User=root Group=root Type=simple Restart=always ExecStart=/usr/local/bin/node_exporter [Install] WantedBy=multi-user.target 启动服务 sudo systemctl daemon-reload sudo systemctl start node_exporter sudo systemctl status node_exporter 出现下列 active 信息即可，node_exporter 服务运行在:9100端口 ● node_exporter.service - Node Exporter Loaded: loaded (/etc/systemd/system/node_exporter.service; disabled; vendor preset: enabled) Active: active (running) since Sun 2024-04-14 19:36:13 CST; 4 days ago Main PID: 3207091 (node_exporter) Tasks: 4 (limit: 2247) Memory: 14.4M CGroup: /system.slice/node_exporter.service └─3207091 /usr/local/bin/node_exporter ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:4:8","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"部署 MySQLd Exporter 下载 mysqld_exporter 文件，并且放置到各个文件夹下 wget https://github.com/prometheus/mysqld_exporter/releases/download/v0.15.1/mysqld_exporter-0.15.1.linux-amd64.tar.gz tar -xvf mysqld_exporter-0.15.1.linux-amd64.tar.gz cd mysqld_exporter-0.15.1.linux-amd64.tar.gz sudo cp mysqld_exporter /usr/local/bin mysqld_exporter 配置文件：/etc/prometheus/mysqld_exporter/my.cnf [client] user=root password=your_mysql_password host=127.0.0.1 创建 mysqld_exporter 服务 新建文件/etc/systemd/system/mysqld_exporter.service [Unit] Description=mysqld_exporter Wants=network-online.target After=network-online.target [Service] Type=simple User=root Group=root Environment=DATA_SOURCE_NAME=your_mysql_user:your_mysql_password@(127.0.0.1:3306)/ ExecStart=/usr/local/bin/mysqld_exporter --config.my-cnf=/etc/prometheus/mysqld_exporter/my.cnf Restart=always [Install] WantedBy=multi-user.targe 启动服务 sudo systemctl daemon-reload sudo systemctl start mysqld_exporter sudo systemctl status mysqld_exporter 出现下列 active 信息即可，mysqld_exporter 服务运行在:9104端口 ● mysqld_exporter.service - mysqld_exporter Loaded: loaded (/etc/systemd/system/mysqld_exporter.service; disabled; vendor preset: enabled) Active: active (running) since Mon 2024-04-15 14:48:22 CST; 4 days ago Main PID: 3504637 (mysqld_exporter) Tasks: 6 (limit: 2247) Memory: 12.3M CGroup: /system.slice/mysqld_exporter.service └─3504637 /usr/local/bin/mysqld_exporter --config.my-cnf=/etc/prometheus/mysqld_exporter/my.cnf ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:4:9","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"部署 Redis Exporter 下载 redis_exporter 文件，并且放置到各个文件夹下 wget https://github.com/oliver006/redis_exporter/releases/download/v1.58.0/redis_exporter-v1.58.0.linux-amd64.tar.gz tar -xvf redis_exporter-v1.58.0.linux-amd64.tar.gz cd redis_exporter-v1.58.0.linux-amd64.tar.gz sudo cp redis_exporter /usr/local/bin 创建 redis_exporter 服务 新建文件/etc/systemd/system/redis_exporter.service [Unit] Description=Redis Exporter Wants=network-online.target After=network-online.target [Service] User=root Group=root Type=simple Restart=always ExecStart=/usr/local/bin/redis_exporter \\ --redis.password=your_redis_password [Install] WantedBy=multi-user.target 启动服务 sudo systemctl daemon-reload sudo systemctl start redis_exporter sudo systemctl status redis_exporter 出现下列 active 信息即可，redis_exporter 服务运行在:9121端口 ● redis_exporter.service - Redis Exporter Loaded: loaded (/etc/systemd/system/redis_exporter.service; disabled; vendor preset: enabled) Active: active (running) since Sun 2024-04-14 20:13:14 CST; 4 days ago Main PID: 3217820 (redis_exporter) Tasks: 9 (limit: 2247) Memory: 13.6M CGroup: /system.slice/redis_exporter.service └─3217820 /usr/local/bin/redis_exporter --redis.password=your_redis_password ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:4:10","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"部署 Grafana sudo apt-get install -y adduser libfontconfig1 musl wget https://dl.grafana.com/enterprise/release/grafana-enterprise_10.4.2_amd64.deb sudo dpkg -i grafana-enterprise_10.4.2_amd64.deb sudo systemctl status grafana-server.service 检测服务，服务运行在 :3000 端口： ● grafana-server.service - Grafana instance Loaded: loaded (/lib/systemd/system/grafana-server.service; enabled; vendor preset: enabled) Active: active (running) since Mon 2024-04-15 00:38:00 CST; 4 days ago Docs: http://docs.grafana.org Main PID: 3286698 (grafana) Tasks: 19 (limit: 2247) Memory: 109.8M CGroup: /system.slice/grafana-server.service └─3286698 /usr/share/grafana/bin/grafana server --config=/etc/grafana/grafana.ini --pidfile=/run/grafana/g\u003e ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:4:11","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"遇到的问题 ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:5:0","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"图片上传前后端交互 前端代码 \u003cscript\u003e async function submitForm() { const { value } = formValue const { imgList, version, promptId, style, gender } = value ... const formData = new FormData() imgList.forEach(({ file }) =\u003e formData.append('images', file)) ... try { const { data } = await api.generatePhoto(formData) } ... } \u003c/script\u003e 后端代码 处理图片上传： fileDir := path.Join(\"tmp\", \"image\") if _, err := os.Stat(fileDir); os.IsNotExist(err) { _ = os.MkdirAll(fileDir, os.ModePerm) } for _, fileHeader := range r.MultipartForm.File[\"images\"] { file, _ := fileHeader.Open() filename := fmt.Sprintf(\"%d%s\", time.Now().UnixMicro(), path.Ext(fileHeader.Filename)) filePath := path.Join(fileDir, filename) dst, _ := os.Create(filePath) _, _ = io.Copy(dst, file) req.Images = append(req.Images, filename) _ = file.Close() _ = dst.Close() } // 异步删除 go func(images []string) { for _, item := range images { if err = os.Remove(path.Join(fileDir, item)); err != nil { logx.Error(err) } } }(req.Images) 文件（图片）服务器 func GetFileHandler(svcCtx *svc.ServiceContext) http.HandlerFunc { return func(w http.ResponseWriter, r *http.Request) { var req types.GetFileReq if err := httpx.Parse(r, \u0026req); err != nil { httpresp.HttpError(w, r, errors.BadRequest(errors.DefaultBadRequestID, err.Error())) return } filename := path.Join(\"tmp\", req.Dir, req.Filename) if _, err := os.Stat(filename); err != nil { if os.IsNotExist(err) { _, _ = w.Write([]byte(\"file not exist\")) httpx.Ok(w) return } else { httpresp.HttpError(w, r, errors.NotFound(errors.DefaultNotFoundID, err.Error())) } } http.ServeFile(w, r, filename) } } ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:5:1","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"数据库软删除与唯一索引冲突 暂无解决方案 ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:5:2","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"前端 json 展示 使用 vue-json-viewer 包 \u003ctemplate\u003e \u003cn-form ref=\"modalFormRef\" label-placement=\"top\" label-align=\"left\" :model=\"modalForm\" \u003e \u003cn-form-item label=\"请求头\" path=\"reqHeader\"\u003e \u003cJsonViewer :value=\"JSON.parse(modalForm.reqHeader)\" copyable sort boxed expanded :theme=\"appStore.isDark ? 'jv-dark' : 'jv-light'\" /\u003e \u003c!-- \u003cn-input v-model:value=\"modalForm.reqHeader\" /\u003e --\u003e \u003c/n-form-item\u003e \u003cn-form-item label=\"请求体\" path=\"reqBody\"\u003e \u003cJsonViewer :value=\"JSON.parse(modalForm.reqBody)\" copyable boxed sort :theme=\"appStore.isDark ? 'jv-dark' : 'jv-light'\" /\u003e \u003c!-- \u003cn-input v-model:value=\"modalForm.reqBody\" /\u003e --\u003e \u003c/n-form-item\u003e \u003cn-form-item label=\"返回结果\" path=\"response\"\u003e \u003cJsonViewer :value=\"JSON.parse(modalForm.response)\" copyable boxed sort expanded :theme=\"appStore.isDark ? 'jv-dark' : 'jv-light'\" /\u003e \u003c!-- \u003cn-input v-model:value=\"modalForm.response\" /\u003e --\u003e \u003c/n-form-item\u003e \u003c/n-form\u003e \u003c/template\u003e \u003cscript\u003e import JsonViewer from \"vue-json-viewer\"; import \"vue-json-viewer/style.css\"; import \"vue3-json-viewer/dist/index.css\"; \u003c/script\u003e ","date":"2024-04-05","objectID":"/2024-04-05/graduation-design/:5:3","tags":["blog","毕业设计"],"title":"【毕业季】本科毕设《Magic Camera》需求清单","uri":"/2024-04-05/graduation-design/"},{"categories":["blog"],"content":"纪念第一段真正意义上的实习，爱来自七牛。当然，这次不想讨论工作上的内容，只想聊聊我遇到的同事。 ","date":"2024-04-01","objectID":"/2024-04-01/qiniu/:0:0","tags":["七牛云","blog","工作"],"title":"【纪念向】我在杭州七牛云的323天","uri":"/2024-04-01/qiniu/"},{"categories":["blog"],"content":"初识七牛 对于 Golang 我是情有独钟的，所以对于技术栈使用 Golang 的公司，我也会特别留意一下。 因此，七牛云进入了我的视线，虽然没有一眼万年，但是也和七牛一起走过了一段旅途。 ","date":"2024-04-01","objectID":"/2024-04-01/qiniu/:1:0","tags":["七牛云","blog","工作"],"title":"【纪念向】我在杭州七牛云的323天","uri":"/2024-04-01/qiniu/"},{"categories":["blog"],"content":"初入七牛 小插曲：面试的过程有点曲折，好在有捷哥的帮助下，我还是在 2023-04-27 这天，有惊无险的 12 小时速通七牛。 ","date":"2024-04-01","objectID":"/2024-04-01/qiniu/:2:0","tags":["七牛云","blog","工作"],"title":"【纪念向】我在杭州七牛云的323天","uri":"/2024-04-01/qiniu/"},{"categories":["blog"],"content":"很赞的同事 我该如何向你诉说我的同事有多赞呢？这是一个很难的问题。我忧虑我贫瘠的文笔写不出他们的优秀，所以我只能与你讲讲我与他们的故事。 ","date":"2024-04-01","objectID":"/2024-04-01/qiniu/:3:0","tags":["七牛云","blog","工作"],"title":"【纪念向】我在杭州七牛云的323天","uri":"/2024-04-01/qiniu/"},{"categories":["blog"],"content":"把我带进七牛的捷哥 一直很感谢的人是捷哥，没有捷哥就没有我在七牛云所经历的一切，也没有我后续的成长。 捷哥本科毕业于浙江工商大学，我觉得是一所很好的大学。可惜和捷哥共事的时间并不长，来了之后没多久捷哥就跳槽去了其他的地方。不过很幸运的是，我和捷哥有联系方式，并且在 23 年暑假里，和 mentor 们一起在杭州九米羊肉炉馆聚餐相聚。那晚捷哥请客，吃到了最好吃的羊肉，也聊了很多对未来的考虑。 不论怎么说，捷哥是我人生中的一个贵人，我真的很幸运。 ","date":"2024-04-01","objectID":"/2024-04-01/qiniu/:3:1","tags":["七牛云","blog","工作"],"title":"【纪念向】我在杭州七牛云的323天","uri":"/2024-04-01/qiniu/"},{"categories":["blog"],"content":"让我快速成长的雨哥 由于捷哥跳槽后，我的 mentor 就变成了雨哥。雨哥毕业于河南的一个三本，非常励志，同时也是一个虔诚的基督教徒，救济世人的理念一直是他的潜意识。希望别人好是没错的，可能有时候用力过猛就适得其反了。当然这是一个小插曲，就不再公开处刑了 hahaha。 雨哥的工作经历很丰富，并且对开发规范，代码设计上有很高的要求。这是我快速成长的原因之一，在短时间内掌握了企业开发需要的技能，快速适应开发节奏。很巧的是雨哥住的离我学校很近，有时候会一起下班，交流交流生活、思想上的事情，不仅仅是导师关系，更是同事、朋友。很幸运的遇到了一个技术大神。（唯一美中不足的是到离职了还没吃上雨哥家的甜品蛋糕 🎂） ","date":"2024-04-01","objectID":"/2024-04-01/qiniu/:3:2","tags":["七牛云","blog","工作"],"title":"【纪念向】我在杭州七牛云的323天","uri":"/2024-04-01/qiniu/"},{"categories":["blog"],"content":"有很多梗的宝哥 宝哥真的！！有好多梗啊哈哈哈哈哈哈。宝哥研究生毕业于北京邮电大学，七牛果然卧虎藏龙。更让我震惊的是宝哥“开车”也很牛逼，只能说和宝哥做朋友非常好玩。当然宝哥对于工作的要求也是很高的，与宝哥一起合作的项目中，也可以见识到宝哥的代码功力非常深厚，各种设计模式手拿把掐，果然是北邮战神。 ","date":"2024-04-01","objectID":"/2024-04-01/qiniu/:3:3","tags":["七牛云","blog","工作"],"title":"【纪念向】我在杭州七牛云的323天","uri":"/2024-04-01/qiniu/"},{"categories":["blog"],"content":"同一天入职的晨薇 晨薇是与我同一天入职的杭州电子科技大学本硕。 她负责创新业务部的前端，是一个很优秀的人，也是很好的一个人，她每次都能很好的帮助我、解答我的疑问。有这么好的小伙伴，还有什么不满足的 😊。 晨薇后续去了上海华为，祝福她前程似锦 🎉！！ ","date":"2024-04-01","objectID":"/2024-04-01/qiniu/:3:4","tags":["七牛云","blog","工作"],"title":"【纪念向】我在杭州七牛云的323天","uri":"/2024-04-01/qiniu/"},{"categories":["blog"],"content":"高中同学：黄磊 高中同学，黄磊。 本科就读于香港中文大学深圳校区，做了大概三个月的同事，期间和应明轩一起组成临安中学兄弟篮球，在各个野球场乱杀，立于不败之地。 后续前往香港中文大学本部读研，希望他 25 秋招有个好 offer 吧！！ ","date":"2024-04-01","objectID":"/2024-04-01/qiniu/:3:5","tags":["七牛云","blog","工作"],"title":"【纪念向】我在杭州七牛云的323天","uri":"/2024-04-01/qiniu/"},{"categories":["blog"],"content":"大学本科同学：林心悦 本科同学林心悦，与我在同一个二级学院：信息与电子工程学院，不过专业是软件工程。 同一个部门，负责基础架构的前端。共事了很长一段时间，可惜没有 HC。希望有个好前程吧！ ","date":"2024-04-01","objectID":"/2024-04-01/qiniu/:3:6","tags":["七牛云","blog","工作"],"title":"【纪念向】我在杭州七牛云的323天","uri":"/2024-04-01/qiniu/"},{"categories":["blog"],"content":"人美心善的保洁阿姨 阿姨真的很热情，每天到公司都会和阿姨说一声早上好，并且我的需求，阿姨每次都是有求必应。阿姨真的好好啊，离开七牛有点舍不得阿姨哈哈哈哈哈。 ","date":"2024-04-01","objectID":"/2024-04-01/qiniu/:3:7","tags":["七牛云","blog","工作"],"title":"【纪念向】我在杭州七牛云的323天","uri":"/2024-04-01/qiniu/"},{"categories":["blog"],"content":"杭州七牛云的 SRE 们 杭州的 SRE 同学也挺好的，挺不错的团队氛围。劲哥、华师兄、昱丞、异峰、罗震、云飞、斌哥。期间 leader 杰哥来杭州了几次，部门一起聚了几次餐，真的好好吃啊。 ","date":"2024-04-01","objectID":"/2024-04-01/qiniu/:3:8","tags":["七牛云","blog","工作"],"title":"【纪念向】我在杭州七牛云的323天","uri":"/2024-04-01/qiniu/"},{"categories":["blog"],"content":"图集 杭州七牛云 入职配备的MacBook Pro 2017 离职那天的工位 企业微信截图 夕阳下的环球中心 ","date":"2024-04-01","objectID":"/2024-04-01/qiniu/:4:0","tags":["七牛云","blog","工作"],"title":"【纪念向】我在杭州七牛云的323天","uri":"/2024-04-01/qiniu/"},{"categories":["blog"],"content":"去向-北京快手 所以我为什么离职了呢？ 因为我要成为老铁啦！！！ 来了，老铁！ 潘江明 二〇二四年四月一日 凌晨 王磊烈士牺牲 23 周年祭 记于 浙江科技大学 ","date":"2024-04-01","objectID":"/2024-04-01/qiniu/:5:0","tags":["七牛云","blog","工作"],"title":"【纪念向】我在杭州七牛云的323天","uri":"/2024-04-01/qiniu/"},{"categories":["redis"],"content":"使用 Golang+Redis 实现一些经典业务案例，如签到功能、分布式锁、限流器、消息队列、计数器、排行榜、订阅发布等 前言 该文章中涉及到的代码：https://github.com/pjimming/blog-code/tree/main/go-redis-example ","date":"2024-03-26","objectID":"/2024-03-26/example-golang/:0:0","tags":["redis","golang","实战"],"title":"『实战』使用Golang实现Redis经典应用案例","uri":"/2024-03-26/example-golang/"},{"categories":["redis"],"content":"00-预先准备 项目文件架构： (base) ➜ go-redis-example git:(main) tree . . ├── Makefile ├── README.md ├── common │ ├── concurrent_event_log.go │ └── coucurrent_routine.go ├── example │ ├── ex01_checkin.go │ ├── ex02_setnx.go │ ├── ex03_limiter.go │ ├── ex04_message.go │ ├── ex05_hash_count.go │ ├── ex06_ranking.go │ ├── ex07_pubsub.go │ ├── redis_client.go │ └── redis_client_test.go ├── go.mod ├── go.sum └── main.go 3 directories, 16 files ","date":"2024-03-26","objectID":"/2024-03-26/example-golang/:1:0","tags":["redis","golang","实战"],"title":"『实战』使用Golang实现Redis经典应用案例","uri":"/2024-03-26/example-golang/"},{"categories":["redis"],"content":"下载 Go 第三方包依赖 go get github.com/redis/go-redis/v9 go get github.com/stretchr/testify ","date":"2024-03-26","objectID":"/2024-03-26/example-golang/:1:1","tags":["redis","golang","实战"],"title":"『实战』使用Golang实现Redis经典应用案例","uri":"/2024-03-26/example-golang/"},{"categories":["redis"],"content":"初始化 Redis 连接 确保有一个 Redis 环境，若本地没有，请自行使用搜索引擎进行安装 编写以下代码，初始化 Redis 连接 // example/redis_client.go package example import ( \"context\" \"github.com/redis/go-redis/v9\" ) var RedisCli *redis.Client func init() { RedisCli = redis.NewClient(\u0026redis.Options{ Addr: \"127.0.0.1:6379\", // Your Redis Address Password: \"123456\", // Your Redis Password }) if err := RedisCli.Ping(context.Background()).Err(); err != nil { panic(err) } } 编写测试代码，测试连接是否成功 // example/redis_client_test.go package example import ( \"context\" \"testing\" \"github.com/stretchr/testify/assert\" ) func TestNewRedis(t *testing.T) { ast := assert.New(t) ast.NotNil(RedisCli) ast.Nil(RedisCli.Ping(context.Background()).Err()) } 执行命令：go test ./example -run=\"^TestNewRedis\" 得到如下结果表示测试通过，Redis 连接初始化成功： (base) ➜ go-redis-example git:(main) ✗ go test ./example -run=\"^TestNewRedis\" ok go-redis-example/example 0.287s ","date":"2024-03-26","objectID":"/2024-03-26/example-golang/:1:2","tags":["redis","golang","实战"],"title":"『实战』使用Golang实现Redis经典应用案例","uri":"/2024-03-26/example-golang/"},{"categories":["redis"],"content":"通用方法 在 common 文件夹下新建两个文件，分别是 concurrent_event_log.go 和 concurrent_routine.go common/concurrent_event_log.go: 日志收集及打印工具 package common import ( \"context\" \"fmt\" \"sort\" \"time\" ) type ConcurrentEventLogger struct { eventLogs []EventLog } // EventLog 搜集日志的结构 type EventLog struct { EventTime time.Time Log string } func NewConcurrentEventLog(ctx context.Context, logsLength int) *ConcurrentEventLogger { if logsLength \u003c= 0 { logsLength = 32 } logContainer := make([]EventLog, 0, logsLength) return \u0026ConcurrentEventLogger{eventLogs: logContainer} } // Append 追加日志 func (ceLog *ConcurrentEventLogger) Append(mLog EventLog) { ceLog.eventLogs = append(ceLog.eventLogs, mLog) } // PrintLogs 日志按时间正序输出 func (ceLog *ConcurrentEventLogger) PrintLogs() { sort.Slice(ceLog.eventLogs, func(i, j int) bool { return ceLog.eventLogs[i].EventTime.Before(ceLog.eventLogs[j].EventTime) }) for i := range ceLog.eventLogs { fmt.Println(ceLog.eventLogs[i].Log) } } // LogFormat 包含通用日志前缀 [2022-11-27T12:36:00.213454+08:00] routine[5] func LogFormat(routine int, format string, a ...any) string { tpl := \"[%s] routine[%d] \" + format sr := []any{ time.Now().Format(time.RFC3339Nano), routine, } sr = append(sr, a...) return fmt.Sprintf(tpl, sr...) } common/concurrent_routine.go: 并发执行器 package common import ( \"context\" \"sync\" ) // ConcurrentRoutine 并发执行器对象定义 type ConcurrentRoutine struct { routineNums int // 定义并发协程的数量 concurrentEventLogger *ConcurrentEventLogger // 并发日志搜集器 } // CInstParams 定义传入callBack的参数 type CInstParams struct { Routine int // 协程编号 ConcurrentEventLogger *ConcurrentEventLogger CustomParams interface{} // 用户自定义参数 } type callBack func(ctx context.Context, params CInstParams) // 定义一个用户自定义执行函数 // NewConcurrentRoutine 初始化一个并发执行器 func NewConcurrentRoutine( routineNums int, concurrentEventLog *ConcurrentEventLogger, ) *ConcurrentRoutine { return \u0026ConcurrentRoutine{ routineNums: routineNums, concurrentEventLogger: concurrentEventLog, } } // Run 并发执行用户自定义函数 workFun func (cInst *ConcurrentRoutine) Run(ctx context.Context, customParams interface{}, workFun callBack) { wg := \u0026sync.WaitGroup{} for i := 0; i \u003c cInst.routineNums; i++ { mRoutine := i wg.Add(1) // 启动协程模拟并发逻辑 go func(mCtx context.Context, mRoutine int, mParams interface{}) { defer wg.Done() workFun( mCtx, CInstParams{ Routine: mRoutine, ConcurrentEventLogger: cInst.concurrentEventLogger, CustomParams: mParams, }, ) }(ctx, mRoutine, customParams) } wg.Wait() } ","date":"2024-03-26","objectID":"/2024-03-26/example-golang/:1:3","tags":["redis","golang","实战"],"title":"『实战』使用Golang实现Redis经典应用案例","uri":"/2024-03-26/example-golang/"},{"categories":["redis"],"content":"main 方法 作为程序的入口，我们为了更好的运行实现好的案例，需要对输入的参数进行解析。例如要运行的 Example，运行需要的参数信息等。 main.go代码如下： package main import ( \"context\" \"fmt\" \"os\" \"strings\" \"go-redis-example/example\" ) func main() { defer func() { _ = example.RedisCli.Close() }() argsProg := os.Args var argsWithoutProg []string if len(argsProg) \u003e 0 { argsWithoutProg = os.Args[1:] fmt.Printf(\"输入参数:\\n%s\\n----------\\n\", strings.Join(argsWithoutProg, \"\\n\")) } ctx := context.Background() runExample := argsWithoutProg[0] exampleParams := argsWithoutProg[1:] switch runExample { case \"Ex01\": example.Ex01(ctx, exampleParams) case \"Ex02\": example.Ex02(ctx) case \"Ex03\": example.Ex03(ctx) case \"Ex04\": example.Ex04(ctx) case \"Ex05\": example.Ex05(ctx, exampleParams) case \"Ex06\": example.Ex06(ctx, exampleParams) case \"Ex07\": example.Ex07(ctx) default: panic(fmt.Sprintf(\"not support type: %s\", runExample)) } } 暂未实现的 example 注释即可，等实现完成之后，记得取消注释，否则无法运行。 到此为止，我们预先的准备工作都已经就绪，现在开始实战案例。 ","date":"2024-03-26","objectID":"/2024-03-26/example-golang/:1:4","tags":["redis","golang","实战"],"title":"『实战』使用Golang实现Redis经典应用案例","uri":"/2024-03-26/example-golang/"},{"categories":["redis"],"content":"01-基于Incr的签到功能 ","date":"2024-03-26","objectID":"/2024-03-26/example-golang/:2:0","tags":["redis","golang","实战"],"title":"『实战』使用Golang实现Redis经典应用案例","uri":"/2024-03-26/example-golang/"},{"categories":["redis"],"content":"业务分析 对于每日签到功能，我们需要记录连续签到天数，并且如果用户在当天没有签到的话，清空计数。 可以发现使用 Redis 的 String 类型搭配设置过期时间就可以很好的解决这个问题。 对于过期时间的设置，如果我们在当天签到成功，则第二天不签到就会清空计数。所以把过期时间设置在第三天的凌晨 0 点即可。 ","date":"2024-03-26","objectID":"/2024-03-26/example-golang/:2:1","tags":["redis","golang","实战"],"title":"『实战』使用Golang实现Redis经典应用案例","uri":"/2024-03-26/example-golang/"},{"categories":["redis"],"content":"代码实现 package example import ( \"context\" \"fmt\" \"log\" \"strconv\" \"time\" ) const continueCheckKey = \"cc_uid_%d\" func Ex01(ctx context.Context, params []string) { userID, err := strconv.ParseInt(params[0], 10, 64) if err != nil { err = fmt.Errorf(\"参数错误：params = %+v, error = %v\", params, err) panic(err) } ex01AddContinueDays(ctx, userID) } // 用户签到 func ex01AddContinueDays(ctx context.Context, userID int64) { key := ex01GetContinueCheckKey(userID) // 1. 签到天数+1 if err := RedisCli.Incr(ctx, key).Err(); err != nil { err = fmt.Errorf(\"user[%d]签到失败, %v\", userID, err) panic(err) } // 2. 设置签到时间为后天0点过期 expAt := ex01BeginningOfDay().Add(48 * time.Hour) if err := RedisCli.ExpireAt(ctx, key, expAt).Err(); err != nil { panic(err) } // 3. 打印用户签到天数 day, err := ex01GetUserCheckInDays(ctx, userID) if err != nil { panic(err) } log.Printf(\"User[%d]连续签到：%d天，过期时间：%s\", userID, day, expAt.Format(\"2006-01-02 15:04:05\")) } // 获取用户签到天数 func ex01GetUserCheckInDays(ctx context.Context, userID int64) (int64, error) { key := ex01GetContinueCheckKey(userID) days, err := RedisCli.Get(ctx, key).Result() if err != nil { return 0, err } daysInt, err := strconv.ParseInt(days, 10, 64) if err != nil { return 0, err } return daysInt, nil } // 获取今天0点时间 func ex01BeginningOfDay() time.Time { now := time.Now() y, m, d := now.Date() return time.Date(y, m, d, 0, 0, 0, 0, time.Local) } // 获取记录签到天数的key func ex01GetContinueCheckKey(userID int64) string { return fmt.Sprintf(continueCheckKey, userID) } ","date":"2024-03-26","objectID":"/2024-03-26/example-golang/:2:2","tags":["redis","golang","实战"],"title":"『实战』使用Golang实现Redis经典应用案例","uri":"/2024-03-26/example-golang/"},{"categories":["redis"],"content":"测试功能：go run main.go Ex01 1165894833417101 (base) ➜ go-redis-example git:(main) ✗ go run main.go Ex01 1165894833417101 输入参数: Ex01 1165894833417101 ---------- 2024/03/26 15:25:05 User[1165894833417101]连续签到：1天，过期时间：2024-03-28 00:00:00 (base) ➜ go-redis-example git:(main) ✗ go run main.go Ex01 1165894833417101 输入参数: Ex01 1165894833417101 ---------- 2024/03/26 15:25:09 User[1165894833417101]连续签到：2天，过期时间：2024-03-28 00:00:00 ","date":"2024-03-26","objectID":"/2024-03-26/example-golang/:2:3","tags":["redis","golang","实战"],"title":"『实战』使用Golang实现Redis经典应用案例","uri":"/2024-03-26/example-golang/"},{"categories":["redis"],"content":"02-基于SETNX的分布式锁 并发场景下，要求同时只有一个进程执行。即分布式情况下的逻辑、资源保护。 使用 redis 的 setnx 实现： 单线程，且可以保证原子性 只有不存在 key 时才可以执行成功 警告 只是体验 SetNX 的特性，不是高可用的分布式锁实现 该实现存在的问题: 业务超时解锁，导致并发问题。业务执行时间超过锁超时时间 redis 主备切换临界点问题。主备切换后，A 持有的锁还未同步到新的主节点时，B 可在新主节点获取锁，导致并发问题。 redis 集群脑裂，导致出现多个主节点 ","date":"2024-03-26","objectID":"/2024-03-26/example-golang/:3:0","tags":["redis","golang","实战"],"title":"『实战』使用Golang实现Redis经典应用案例","uri":"/2024-03-26/example-golang/"},{"categories":["redis"],"content":"代码实现 package example import ( \"context\" \"fmt\" \"strconv\" \"time\" \"go-redis-example/common\" ) const ( resourceKey = \"syncKey\" // 分布式锁的key expTime = 800 * time.Millisecond // 锁的过期时间，避免死锁 ) type Ex02Params struct { } // Ex02 只是体验SetNX的特性，不是高可用的分布式锁实现 // 该实现存在的问题: // (1) 业务超时解锁，导致并发问题。业务执行时间超过锁超时时间 // (2) redis主备切换临界点问题。主备切换后，A持有的锁还未同步到新的主节点时，B可在新主节点获取锁，导致并发问题。 // (3) redis集群脑裂，导致出现多个主节点 func Ex02(ctx context.Context) { eventLogger := common.NewConcurrentEventLog(ctx, 32) // new一个并发执行器 cInst := common.NewConcurrentRoutine(10, eventLogger) // 并发执行自定义work cInst.Run(ctx, Ex02Params{}, ex02Work) // 按时间顺序输出日志 eventLogger.PrintLogs() } func ex02Work(ctx context.Context, cInstParams common.CInstParams) { routine := cInstParams.Routine eventLogger := cInstParams.ConcurrentEventLogger defer ex02ReleaseLock(ctx, routine, eventLogger) for { // 1. 尝试获取锁 acquired, err := RedisCli.SetNX(ctx, resourceKey, routine, expTime).Result() if err != nil { err = fmt.Errorf(\"[%s] error routine[%d], %v\", time.Now().Format(time.RFC3339Nano), routine, err) eventLogger.Append(common.EventLog{ EventTime: time.Now(), Log: err.Error(), }) panic(err) } if acquired { // 2. 成功获取 eventLogger.Append(common.EventLog{ EventTime: time.Now(), Log: fmt.Sprintf(\"[%s] routine[%d] 获取锁\", time.Now().Format(time.RFC3339Nano), routine), }) // 3. 模拟业务 time.Sleep(10 * time.Millisecond) eventLogger.Append(common.EventLog{ EventTime: time.Now(), Log: fmt.Sprintf(\"[%s] routine[%d] 完成业务逻辑\", time.Now().Format(time.RFC3339Nano), routine), }) return } // 没有获取到锁，等待后重试 time.Sleep(100 * time.Millisecond) } } func ex02ReleaseLock(ctx context.Context, routine int, eventLogger *common.ConcurrentEventLogger) { routineMark, _ := RedisCli.Get(ctx, resourceKey).Result() if strconv.FormatInt(int64(routine), 10) != routineMark { // 其它协程误删lock panic(fmt.Sprintf(\"del err lock[%s] can not del by [%d]\", routineMark, routine)) } result, err := RedisCli.Del(ctx, resourceKey).Result() if result == 1 { eventLogger.Append(common.EventLog{ EventTime: time.Now(), Log: fmt.Sprintf(\"[%s] routine[%d] 释放锁\", time.Now().Format(time.RFC3339Nano), routine), }) } else { eventLogger.Append(common.EventLog{ EventTime: time.Now(), Log: fmt.Sprintf(\"[%s] routine[%d] no lock to del\", time.Now().Format(time.RFC3339Nano), routine), }) } if err != nil { err = fmt.Errorf(\"[%s] error routine=%d, %v\", time.Now().Format(time.RFC3339Nano), routine, err) eventLogger.Append(common.EventLog{ EventTime: time.Now(), Log: err.Error(), }) panic(err) } } ","date":"2024-03-26","objectID":"/2024-03-26/example-golang/:3:1","tags":["redis","golang","实战"],"title":"『实战』使用Golang实现Redis经典应用案例","uri":"/2024-03-26/example-golang/"},{"categories":["redis"],"content":"测试功能：go run main.go Ex02 (base) ➜ go-redis-example git:(main) go run main.go Ex02 输入参数: Ex02 ---------- [2024-03-26T15:53:27.623764+08:00] routine[9] 获取锁 [2024-03-26T15:53:27.634651+08:00] routine[9] 完成业务逻辑 [2024-03-26T15:53:27.664945+08:00] routine[9] 释放锁 [2024-03-26T15:53:27.743436+08:00] routine[6] 获取锁 [2024-03-26T15:53:27.753794+08:00] routine[6] 完成业务逻辑 [2024-03-26T15:53:27.754277+08:00] routine[6] 释放锁 [2024-03-26T15:53:27.852915+08:00] routine[3] 获取锁 [2024-03-26T15:53:27.863014+08:00] routine[3] 完成业务逻辑 [2024-03-26T15:53:27.864108+08:00] routine[3] 释放锁 [2024-03-26T15:53:27.950776+08:00] routine[5] 获取锁 [2024-03-26T15:53:27.961898+08:00] routine[5] 完成业务逻辑 [2024-03-26T15:53:27.96241+08:00] routine[5] 释放锁 [2024-03-26T15:53:28.052261+08:00] routine[2] 获取锁 [2024-03-26T15:53:28.062988+08:00] routine[2] 完成业务逻辑 [2024-03-26T15:53:28.063701+08:00] routine[2] 释放锁 [2024-03-26T15:53:28.152431+08:00] routine[0] 获取锁 [2024-03-26T15:53:28.162493+08:00] routine[0] 完成业务逻辑 [2024-03-26T15:53:28.162897+08:00] routine[0] 释放锁 [2024-03-26T15:53:28.253946+08:00] routine[7] 获取锁 [2024-03-26T15:53:28.264098+08:00] routine[7] 完成业务逻辑 [2024-03-26T15:53:28.264486+08:00] routine[7] 释放锁 [2024-03-26T15:53:28.354901+08:00] routine[4] 获取锁 [2024-03-26T15:53:28.365065+08:00] routine[4] 完成业务逻辑 [2024-03-26T15:53:28.36569+08:00] routine[4] 释放锁 [2024-03-26T15:53:28.458786+08:00] routine[8] 获取锁 [2024-03-26T15:53:28.469094+08:00] routine[8] 完成业务逻辑 [2024-03-26T15:53:28.471307+08:00] routine[8] 释放锁 [2024-03-26T15:53:28.560792+08:00] routine[1] 获取锁 [2024-03-26T15:53:28.584265+08:00] routine[1] 完成业务逻辑 [2024-03-26T15:53:28.618252+08:00] routine[1] 释放锁 ","date":"2024-03-26","objectID":"/2024-03-26/example-golang/:3:2","tags":["redis","golang","实战"],"title":"『实战』使用Golang实现Redis经典应用案例","uri":"/2024-03-26/example-golang/"},{"categories":["redis"],"content":"03-基于Incr和Decr的简单限流器 要求 1s 内放行的请求为 N，超过 N 的请求次数则禁止访问。 通过 redis 的 string 类型，对 key 进行 Incr 和 Decr 操作。value 与 N 比对，判断是否放行。 ","date":"2024-03-26","objectID":"/2024-03-26/example-golang/:4:0","tags":["redis","golang","实战"],"title":"『实战』使用Golang实现Redis经典应用案例","uri":"/2024-03-26/example-golang/"},{"categories":["redis"],"content":"代码实现 package example import ( \"context\" \"fmt\" \"log\" \"sync/atomic\" \"time\" \"go-redis-example/common\" ) type Ex03Params struct { } const ( ex03LimitKeyPreFix = \"common_freq_limit\" // 限流key前缀 ex03MaxQPS = 10 // 限流次数 ) var ( accessQueryNum = int32(0) ) // 返回key格式为：comment_freq_limit-1669524458, // 用来记录这1秒内的请求数量 func ex03LimitKey(currentTimeStamp time.Time) string { return fmt.Sprintf(\"%s-%d\", ex03LimitKeyPreFix, currentTimeStamp.Unix()) } // Ex03 简单限流 func Ex03(ctx context.Context) { eventLogger := common.NewConcurrentEventLog(ctx, 1000) // new一个并发执行器 cInst := common.NewConcurrentRoutine(500, eventLogger) // 并发执行自定义函数 cInst.Run(ctx, Ex03Params{}, ex03Work) // 输出日志 eventLogger.PrintLogs() log.Printf(\"放行总数：%d\", accessQueryNum) time.Sleep(1 * time.Second) fmt.Printf(\"\\n------\\n下一秒请求\\n------\\n\") // 清空日志信息 eventLogger = common.NewConcurrentEventLog(ctx, 1000) accessQueryNum = 0 // new一个并发执行器 cInst = common.NewConcurrentRoutine(10, eventLogger) // 并发执行用户自定义函数work cInst.Run(ctx, Ex03Params{}, ex03Work) // 按日志时间正序打印日志 eventLogger.PrintLogs() log.Printf(\"放行总数：%d\", accessQueryNum) } func ex03Work(ctx context.Context, cInstParams common.CInstParams) { routine := cInstParams.Routine eventLogger := cInstParams.ConcurrentEventLogger key := ex03LimitKey(time.Now()) currentQPS, err := RedisCli.Incr(ctx, key).Result() if err != nil { panic(err) } if currentQPS \u003e ex03MaxQPS { // 超过流量限制，请求受限 eventLogger.Append(common.EventLog{ EventTime: time.Now(), Log: common.LogFormat(routine, \"被限流[%d]\", currentQPS), }) // sleep模拟业务耗时 time.Sleep(50 * time.Millisecond) if err = RedisCli.Decr(ctx, key).Err(); err != nil { panic(err) } } else { // 流量放行 eventLogger.Append(common.EventLog{ EventTime: time.Now(), Log: common.LogFormat(routine, \"流量放行[%d]\", currentQPS), }) atomic.AddInt32(\u0026accessQueryNum, 1) time.Sleep(20 * time.Millisecond) } } ","date":"2024-03-26","objectID":"/2024-03-26/example-golang/:4:1","tags":["redis","golang","实战"],"title":"『实战』使用Golang实现Redis经典应用案例","uri":"/2024-03-26/example-golang/"},{"categories":["redis"],"content":"测试功能：go run main.go Ex03 (base) ➜ go-redis-example git:(main) ✗ go run main.go Ex03 输入参数: Ex03 ---------- [2024-03-26T15:59:52.869876+08:00] routine[2] 流量放行[1] [2024-03-26T15:59:52.87983+08:00] routine[32] 流量放行[2] [2024-03-26T15:59:52.881233+08:00] routine[33] 流量放行[5] [2024-03-26T15:59:52.881636+08:00] routine[6] 流量放行[4] [2024-03-26T15:59:52.88164+08:00] routine[36] 流量放行[3] [2024-03-26T15:59:52.881844+08:00] routine[25] 被限流[40] [2024-03-26T15:59:52.881856+08:00] routine[8] 被限流[42] ··· [2024-03-26T15:59:52.894559+08:00] routine[448] 被限流[490] [2024-03-26T15:59:52.894576+08:00] routine[442] 被限流[491] [2024-03-26T15:59:52.894657+08:00] routine[450] 被限流[488] [2024-03-26T15:59:52.894666+08:00] routine[451] 被限流[489] [2024-03-26T15:59:52.894673+08:00] routine[444] 被限流[487] [2024-03-26T15:59:52.89473+08:00] routine[498] 被限流[486] [2024-03-26T15:59:52.89475+08:00] routine[443] 被限流[485] 2024/03/26 15:59:52 放行总数：10 ------ 下一秒请求 ------ [2024-03-26T15:59:53.977507+08:00] routine[1] 流量放行[10] [2024-03-26T15:59:53.977535+08:00] routine[3] 流量放行[9] [2024-03-26T15:59:53.977601+08:00] routine[2] 流量放行[8] [2024-03-26T15:59:53.977656+08:00] routine[8] 流量放行[7] [2024-03-26T15:59:53.977743+08:00] routine[6] 流量放行[4] [2024-03-26T15:59:53.977752+08:00] routine[7] 流量放行[5] [2024-03-26T15:59:53.977759+08:00] routine[0] 流量放行[6] [2024-03-26T15:59:53.977772+08:00] routine[9] 流量放行[1] [2024-03-26T15:59:53.977781+08:00] routine[5] 流量放行[3] [2024-03-26T15:59:53.977785+08:00] routine[4] 流量放行[2] 2024/03/26 15:59:53 放行总数：10 ","date":"2024-03-26","objectID":"/2024-03-26/example-golang/:4:2","tags":["redis","golang","实战"],"title":"『实战』使用Golang实现Redis经典应用案例","uri":"/2024-03-26/example-golang/"},{"categories":["redis"],"content":"04-基于List的消息队列 消息队列的定义 消息队列是一种先进先出的队列型数据结构。消息被顺序插入队列中，其中发送进程将消息添加到队列末尾，接受进程从队列头读取消息。 多个进程可同时向一个消息队列发送消息，也可以同时从一个消息队列中接收消息。发送进程把消息发送到队列尾部，接受进程从消息队列头部读取消息，消息一旦被读出就从队列中删除。 使用 redis 的 List 的 lpush 和 rpop 可以实现一个简易的消息队列。 ","date":"2024-03-26","objectID":"/2024-03-26/example-golang/:5:0","tags":["redis","golang","实战"],"title":"『实战』使用Golang实现Redis经典应用案例","uri":"/2024-03-26/example-golang/"},{"categories":["redis"],"content":"代码实现 package example import ( \"context\" \"fmt\" \"strings\" \"time\" \"github.com/redis/go-redis/v9\" \"go-redis-example/common\" ) const ex04ListenList = \"ex04_list_0\" // lpush ex04_list_0 AA BB // Ex04Params Ex04的自定义函数 type Ex04Params struct { } func Ex04(ctx context.Context) { eventLogger := common.NewConcurrentEventLog(ctx, 0) // new一个并发执行器 // routineNums是消费端的数量，多消费的场景，可以使用ex04ConsumerPop，使用ex04ConsumerRange存在消息重复消费的问题。 cInst := common.NewConcurrentRoutine(3, eventLogger) go cInst.Run(ctx, Ex04Params{}, ex04ProducerPush) // 并发执行用户自定义函数work cInst.Run(ctx, Ex04Params{}, ex04ConsumerPop) // 按日志时间正序打印日志 eventLogger.PrintLogs() } func ex04ProducerPush(ctx context.Context, cInstParam common.CInstParams) { routine := cInstParam.Routine cnt := 0 for { RedisCli.LPush(ctx, ex04ListenList, fmt.Sprintf(\"producer[%d] push %d\", routine, cnt)) if cnt \u003e 3 { break } cnt++ } } // ex04ConsumerPop 使用rpop逐条消费队列中的信息，数据从队列中移除 // 生成端使用：lpush ex04_list_0 AA BB func ex04ConsumerPop(ctx context.Context, cInstParam common.CInstParams) { routine := cInstParam.Routine for { items, err := RedisCli.BRPop(ctx, time.Second, ex04ListenList).Result() if err != nil { if err == redis.Nil { fmt.Println(common.LogFormat(routine, \"任务执行结束\")) return } panic(err) } fmt.Println(common.LogFormat(routine, \"读取文章[%s]标题、正文，发送到ES更新索引\", items[1])) // 将文章内容推送到ES time.Sleep(1 * time.Second) } } // ex04ConsumerRange 使用lrange批量消费队列中的数据，数据保留在队列中 // 生成端使用：rpush ex04_list_0 AA BB // 消费端： // 方法1 lrange ex04_list_0 -3 -1 // 从FIFO队尾中一次消费3条信息 // 方法2 rpop ex04_list_0 3 func ex04ConsumerRange(ctx context.Context, cInstParam common.CInstParams) { routine := cInstParam.Routine consumeBatchSize := int64(3) // 一次取N个消息 for { // 从index(-consumeBatchSize)开始取，直到最后一个元素index(-1) items, err := RedisCli.LRange(ctx, ex04ListenList, -consumeBatchSize, -1).Result() if err != nil { panic(err) } if len(items) \u003e 0 { fmt.Println(common.LogFormat(routine, \"收到信息:%s\", strings.Join(items, \"-\u003e\"))) // 清除已消费的队列 // 方法1 使用LTrim // 保留从index(0)开始到index(-(consumeBatchSize + 1))的部分，即为未消费的部分 // RedisCli.LTrim(ctx, ex04ListenList, 0, -(consumeBatchSize + 1)) // 方法2 使用RPop RedisCli.RPopCount(ctx, ex04ListenList, int(consumeBatchSize)) } time.Sleep(3 * time.Second) } } ","date":"2024-03-26","objectID":"/2024-03-26/example-golang/:5:1","tags":["redis","golang","实战"],"title":"『实战』使用Golang实现Redis经典应用案例","uri":"/2024-03-26/example-golang/"},{"categories":["redis"],"content":"测试功能：go run main.go Ex04 (base) ➜ go-redis-example git:(main) ✗ go run main.go Ex04 输入参数: Ex04 ---------- [2024-03-26T16:18:35.394455+08:00] routine[1] 读取文章[producer[1] push 0]标题、正文，发送到ES更新索引 [2024-03-26T16:18:35.396198+08:00] routine[2] 读取文章[producer[0] push 0]标题、正文，发送到ES更新索引 [2024-03-26T16:18:35.396556+08:00] routine[0] 读取文章[producer[0] push 1]标题、正文，发送到ES更新索引 [2024-03-26T16:18:36.397106+08:00] routine[1] 读取文章[producer[0] push 2]标题、正文，发送到ES更新索引 [2024-03-26T16:18:36.397123+08:00] routine[2] 读取文章[producer[2] push 0]标题、正文，发送到ES更新索引 [2024-03-26T16:18:36.39716+08:00] routine[0] 读取文章[producer[1] push 1]标题、正文，发送到ES更新索引 [2024-03-26T16:18:37.398938+08:00] routine[2] 读取文章[producer[1] push 2]标题、正文，发送到ES更新索引 [2024-03-26T16:18:37.398954+08:00] routine[0] 读取文章[producer[2] push 1]标题、正文，发送到ES更新索引 [2024-03-26T16:18:37.398978+08:00] routine[1] 读取文章[producer[1] push 3]标题、正文，发送到ES更新索引 [2024-03-26T16:18:38.399928+08:00] routine[2] 读取文章[producer[2] push 3]标题、正文，发送到ES更新索引 [2024-03-26T16:18:38.399967+08:00] routine[1] 读取文章[producer[2] push 2]标题、正文，发送到ES更新索引 [2024-03-26T16:18:38.399979+08:00] routine[0] 读取文章[producer[1] push 4]标题、正文，发送到ES更新索引 [2024-03-26T16:18:39.401791+08:00] routine[2] 读取文章[producer[0] push 4]标题、正文，发送到ES更新索引 [2024-03-26T16:18:39.401869+08:00] routine[1] 读取文章[producer[2] push 4]标题、正文，发送到ES更新索引 [2024-03-26T16:18:39.401923+08:00] routine[0] 读取文章[producer[0] push 3]标题、正文，发送到ES更新索引 [2024-03-26T16:18:41.463624+08:00] routine[0] 任务执行结束 [2024-03-26T16:18:41.463655+08:00] routine[1] 任务执行结束 [2024-03-26T16:18:41.46367+08:00] routine[2] 任务执行结束 ","date":"2024-03-26","objectID":"/2024-03-26/example-golang/:5:2","tags":["redis","golang","实战"],"title":"『实战』使用Golang实现Redis经典应用案例","uri":"/2024-03-26/example-golang/"},{"categories":["redis"],"content":"05-基于Hash的计数器 对于一个用户有多个计数需求，例如点赞数量、粉丝数量、文章收藏数量、关注数量等，可以使用 Hash 的数据结构进行存储。 ","date":"2024-03-26","objectID":"/2024-03-26/example-golang/:6:0","tags":["redis","golang","实战"],"title":"『实战』使用Golang实现Redis经典应用案例","uri":"/2024-03-26/example-golang/"},{"categories":["redis"],"content":"代码实现 package example import ( \"context\" \"fmt\" \"log\" \"strconv\" ) const ex05UserCountKey = \"ex05_user_count\" // Ex05 hash数据结果的运用（参考掘金应用） // go run main.go Ex05 init 初始化用户计数值 // go run main.go Ex05 get 1556564194374926 // 打印用户(1556564194374926)的所有计数值 // go run main.go Ex05 incr_like 1556564194374926 // 点赞数+1 // go run main.go Ex05 incr_collect 1556564194374926 // 收藏数+1 // go run main.go Ex05 decr_like 1556564194374926 // 点赞数-1 // go run main.go Ex05 decr_collect 1556564194374926 // 收藏数-1 func Ex05(ctx context.Context, args []string) { if len(args) \u003c= 0 { panic(\"args can't be empty\") } arg1 := args[0] switch arg1 { case \"init\": Ex05InitUserCount(ctx) case \"get\": userID, err := strconv.ParseInt(args[1], 10, 64) if err != nil { panic(err) } Ex05GetUserCount(ctx, userID) case \"incr_like\": userID, err := strconv.ParseInt(args[1], 10, 64) if err != nil { panic(err) } IncrByUserLike(ctx, userID) case \"incr_collect\": userID, err := strconv.ParseInt(args[1], 10, 64) if err != nil { panic(err) } IncrByUserCollect(ctx, userID) case \"decr_like\": userID, err := strconv.ParseInt(args[1], 10, 64) if err != nil { panic(err) } DecrByUserLike(ctx, userID) case \"decr_collect\": userID, err := strconv.ParseInt(args[1], 10, 64) if err != nil { panic(err) } DecrByUserCollect(ctx, userID) default: panic(\"do not support now...\") } } func Ex05InitUserCount(ctx context.Context) { pipe := RedisCli.Pipeline() userCounters := []map[string]interface{}{ {\"user_id\": \"1556564194374926\", \"got_digg_count\": 10693, \"got_view_count\": 2238438, \"followee_count\": 176, \"follower_count\": 9895, \"follow_collect_set_count\": 0, \"subscribe_tag_count\": 95}, {\"user_id\": \"1111\", \"got_digg_count\": 19, \"got_view_count\": 4}, {\"user_id\": \"2222\", \"got_digg_count\": 1238, \"follower_count\": 379}, } for _, counter := range userCounters { uid, err := strconv.ParseInt(counter[\"user_id\"].(string), 10, 64) if err != nil { panic(err) } key := ex05GetUserCounterKey(uid) if err = pipe.Del(ctx, key).Err(); err != nil { panic(err) } if err = pipe.HMSet(ctx, key, counter).Err(); err != nil { panic(err) } log.Printf(\"设置uid[%d], key=%s\", uid, key) } if _, err := pipe.Exec(ctx); err != nil { // 再执行一次 if _, err = pipe.Exec(ctx); err != nil { panic(err) } } } // ex05GetUserCounterKey 获取用户计数的key func ex05GetUserCounterKey(userID int64) string { return fmt.Sprintf(\"%s_%d\", ex05UserCountKey, userID) } func Ex05GetUserCount(ctx context.Context, userID int64) { pipe := RedisCli.Pipeline() pipe.HGetAll(ctx, ex05GetUserCounterKey(userID)) results, err := RedisCli.HGetAll(ctx, ex05GetUserCounterKey(userID)).Result() if err != nil { panic(err) } fmt.Printf(\"User[%d]:\\n\", userID) for k, v := range results { fmt.Printf(\"%s: %s\\n\", k, v) } } // IncrByUserLike 点赞数+1 func IncrByUserLike(ctx context.Context, userID int64) { incrByUserField(ctx, userID, \"got_digg_count\") } // IncrByUserCollect 收藏数+1 func IncrByUserCollect(ctx context.Context, userID int64) { incrByUserField(ctx, userID, \"follow_collect_set_count\") } // DecrByUserLike 点赞数-1 func DecrByUserLike(ctx context.Context, userID int64) { decrByUserField(ctx, userID, \"got_digg_count\") } // DecrByUserCollect 收藏数-1 func DecrByUserCollect(ctx context.Context, userID int64) { decrByUserField(ctx, userID, \"follow_collect_set_count\") } func incrByUserField(ctx context.Context, userID int64, field string) { change(ctx, userID, field, 1) } func decrByUserField(ctx context.Context, userID int64, field string) { change(ctx, userID, field, -1) } func change(ctx context.Context, userID int64, field string, delta int64) { key := ex05GetUserCounterKey(userID) before, err := RedisCli.HGet(ctx, key, field).Result() if err != nil { panic(err) } beforeInt, err := strconv.ParseInt(before, 10, 64) if err != nil { panic(err) } if beforeInt+delta \u003c 0 { fmt.Printf(\"禁止变更计数，计数变更后小于0. %d + (%d) = %d\\n\", beforeInt, delta, beforeInt+delta) return } fmt.Printf(\"user[%d]: \\n更新前\\n%s = %s\\n--------\\n\", userID, field, before) if err = RedisCli.HIncrBy(ctx, key, field, delta).Err(); err != nil { ","date":"2024-03-26","objectID":"/2024-03-26/example-golang/:6:1","tags":["redis","golang","实战"],"title":"『实战』使用Golang实现Redis经典应用案例","uri":"/2024-03-26/example-golang/"},{"categories":["redis"],"content":"测试功能 测试脚本： go run main.go Ex05 init # 初始化用户计数值 go run main.go Ex05 get 1556564194374926 # 打印用户(1556564194374926)的所有计数值 go run main.go Ex05 incr_like 1556564194374926 # 点赞数+1 go run main.go Ex05 incr_collect 1556564194374926 # 收藏数+1 go run main.go Ex05 decr_like 1556564194374926 # 点赞数-1 go run main.go Ex05 decr_collect 1556564194374926 # 收藏数-1 go run main.go Ex05 decr_collect 1556564194374926 # 收藏数-1 执行结果： 输入参数: Ex05 init ---------- 设置uid[1556564194374926], key=ex05_user_count_1556564194374926 设置uid[1111], key=ex05_user_count_1111 设置uid[2222], key=ex05_user_count_2222 输入参数: Ex05 get 1556564194374926 ---------- User[1556564194374926]: got_view_count: 2238438 followee_count: 176 follower_count: 9895 follow_collect_set_count: 0 subscribe_tag_count: 95 user_id: 1556564194374926 got_digg_count: 10693 输入参数: Ex05 incr_like 1556564194374926 ---------- user[1556564194374926]: 更新前 got_digg_count = 10693 -------- user_id: 1556564194374926 更新后 got_digg_count = 10694 -------- 输入参数: Ex05 incr_collect 1556564194374926 ---------- user[1556564194374926]: 更新前 follow_collect_set_count = 0 -------- user_id: 1556564194374926 更新后 follow_collect_set_count = 1 -------- 输入参数: Ex05 decr_like 1556564194374926 ---------- user[1556564194374926]: 更新前 got_digg_count = 10694 -------- user_id: 1556564194374926 更新后 got_digg_count = 10693 -------- 输入参数: Ex05 decr_collect 1556564194374926 ---------- user[1556564194374926]: 更新前 follow_collect_set_count = 1 -------- user_id: 1556564194374926 更新后 follow_collect_set_count = 0 -------- 输入参数: Ex05 decr_collect 1556564194374926 ---------- 禁止变更计数，计数变更后小于0. 0 + (-1) = -1 ","date":"2024-03-26","objectID":"/2024-03-26/example-golang/:6:2","tags":["redis","golang","实战"],"title":"『实战』使用Golang实现Redis经典应用案例","uri":"/2024-03-26/example-golang/"},{"categories":["redis"],"content":"06-基于Zset的排行榜 积分榜变化时，排名要实时改变。通过 Zset 可以很好的实现功能 ","date":"2024-03-26","objectID":"/2024-03-26/example-golang/:7:0","tags":["redis","golang","实战"],"title":"『实战』使用Golang实现Redis经典应用案例","uri":"/2024-03-26/example-golang/"},{"categories":["redis"],"content":"代码实现 package example import ( \"context\" \"fmt\" \"strconv\" \"github.com/redis/go-redis/v9\" ) const ex06RankKey = \"ex06_rank_zset\" type ex06ItemScore struct { ItemName string Score float64 } // Ex06 排行榜 // go run main.go Ex06 init // 初始化积分 // go run main.go Ex06 rev_order // 输出完整榜单 // go run main.go Ex06 order_page 1 // 逆序分页输出，page=1 // go run main.go Ex06 get_rank user2 // 获取user2的排名 // go run main.go Ex06 get_score user2 // 获取user2的分数 // go run main.go Ex06 add_user_score user2 10 // 为user2设置为10分 // zadd ex06_rank_zset 15 andy // zincrby ex06_rank_zset -9 andy // andy 扣9分，排名掉到最后一名 func Ex06(ctx context.Context, args []string) { arg1 := args[0] switch arg1 { case \"init\": ex06Init(ctx) case \"rev_order\": ex06GetOrderListAll(ctx) case \"order_page\": pageSize := int64(2) if len(args[1]) \u003e 0 { offset, err := strconv.ParseInt(args[1], 10, 64) if err != nil { panic(err) } ex06GetOrderListByPage(ctx, offset, pageSize) } case \"get_rank\": ex06GetUserRankByName(ctx, args[1]) case \"get_score\": ex06GetUserScoreByName(ctx, args[1]) case \"add_user_score\": if len(args) \u003c 3 { fmt.Printf(\"参数错误，可能是缺少需要增加的分值。eg：go run main.go Ex06 add_user_score user2 10\\n\") return } score, err := strconv.ParseFloat(args[2], 64) if err != nil { panic(err) } ex06AddUserScore(ctx, args[1], score) default: panic(\"unsupported type\") } } func ex06Init(ctx context.Context) { initList := []redis.Z{ {Member: \"user1\", Score: 10}, {Member: \"user2\", Score: 232}, {Member: \"user3\", Score: 129}, {Member: \"user4\", Score: 232}, } // 清空榜单 if err := RedisCli.Del(ctx, ex06RankKey).Err(); err != nil { panic(err) } nums, err := RedisCli.ZAdd(ctx, ex06RankKey, initList...).Result() if err != nil { panic(err) } fmt.Printf(\"初始化榜单Item数量：%d\\n\", nums) } // 获取全部榜单 // 榜单逆序输出 // ZRANGE ex06_rank_zset +inf -inf BYSCORE rev WITHSCORES // 正序输出 // ZRANGE ex06_rank_zset 0 -1 WITHSCORES func ex06GetOrderListAll(ctx context.Context) { resList, err := RedisCli.ZRevRangeWithScores(ctx, ex06RankKey, 0, -1).Result() if err != nil { panic(err) } fmt.Println(\"\\n榜单：\") for i, z := range resList { fmt.Printf(\"第%d名，name=%s, score=%.2f\\n\", i+1, z.Member, z.Score) } } // 分页获取榜单 func ex06GetOrderListByPage(ctx context.Context, page, pageSize int64) { // zrange ex06_rank_zset 300 0 byscore rev limit 1 2 withscores // 取300分到0分之间的排名 // zrange ex06_rank_zset -inf +inf byscore withscores 正序输出 // zrange ex06_rank_zset +inf -inf byscore rev WITHSCORES 逆序输出所有排名 // zrange ex06_rank_zset +inf -inf byscore rev limit 0 2 withscores 逆序分页输出排名 offset := int((page - 1) * pageSize) zRangeArgs := redis.ZRangeArgs{ Key: ex06RankKey, ByScore: true, Rev: true, Start: \"-inf\", Stop: \"+inf\", Offset: int64(offset), Count: pageSize, } resList, err := RedisCli.ZRangeArgsWithScores(ctx, zRangeArgs).Result() if err != nil { panic(err) } fmt.Printf(\"榜单(page=%d, pageSize=%d)\\n\", page, pageSize) for i, z := range resList { rank := i + 1 + offset fmt.Printf(\"第%d名 %s\\t%.2f\\n\", rank, z.Member, z.Score) } } // 获取用户排名 func ex06GetUserRankByName(ctx context.Context, name string) { rank, err := RedisCli.ZRevRank(ctx, ex06RankKey, name).Result() if err != nil { panic(err) } fmt.Printf(\"name=%s, rank=%d\\n\", name, rank+1) } // 获取用户分数信息 func ex06GetUserScoreByName(ctx context.Context, name string) { score, err := RedisCli.ZScore(ctx, ex06RankKey, name).Result() if err != nil { panic(err) } fmt.Printf(\"name=%s, score=%.2f\\n\", name, score) } // ex06AddUserScore 增加用户分数 func ex06AddUserScore(ctx context.Context, name string, score float64) { num, err := RedisCli.ZIncrBy(ctx, ex06RankKey, score, name).Result() if err != nil { panic(err) } fmt.Printf(\"name=%s, add_score=%.2f, score=%.2f\\n\", name, score, num) } ","date":"2024-03-26","objectID":"/2024-03-26/example-golang/:7:1","tags":["redis","golang","实战"],"title":"『实战』使用Golang实现Redis经典应用案例","uri":"/2024-03-26/example-golang/"},{"categories":["redis"],"content":"测试功能 测试脚本： go run main.go Ex06 init # 初始化积分 go run main.go Ex06 rev_order # 输出完整榜单 go run main.go Ex06 order_page 1 # 逆序分页输出，page=1 go run main.go Ex06 order_page 2 # 逆序分页输出，page=2 go run main.go Ex06 get_rank user2 # 获取user2的排名 go run main.go Ex06 get_score user2 # 获取user2的分数 go run main.go Ex06 add_user_score user2 10 # 为user2增加10分 go run main.go Ex06 get_rank user2 # 获取user2的排名 go run main.go Ex06 get_score user2 # 获取user2的分数 执行结果： 输入参数: Ex06 init ---------- 初始化榜单Item数量：4 输入参数: Ex06 rev_order ---------- 榜单： 第1名，name=user4, score=232.00 第2名，name=user2, score=232.00 第3名，name=user3, score=129.00 第4名，name=user1, score=10.00 输入参数: Ex06 order_page 1 ---------- 榜单(page=1, pageSize=2) 第1名 user4 232.00 第2名 user2 232.00 输入参数: Ex06 order_page 2 ---------- 榜单(page=2, pageSize=2) 第3名 user3 129.00 第4名 user1 10.00 输入参数: Ex06 get_rank user2 ---------- name=user2, rank=2 输入参数: Ex06 get_score user2 ---------- name=user2, score=232.00 输入参数: Ex06 add_user_score user2 10 ---------- name=user2, add_score=10.00, score=242.00 输入参数: Ex06 get_rank user2 ---------- name=user2, rank=1 输入参数: Ex06 get_score user2 ---------- name=user2, score=242.00 ","date":"2024-03-26","objectID":"/2024-03-26/example-golang/:7:2","tags":["redis","golang","实战"],"title":"『实战』使用Golang实现Redis经典应用案例","uri":"/2024-03-26/example-golang/"},{"categories":["redis"],"content":"07-基于PubSub的消息订阅 对于文章的发布与订阅，也可以使用 PubSub 实现 ","date":"2024-03-26","objectID":"/2024-03-26/example-golang/:8:0","tags":["redis","golang","实战"],"title":"『实战』使用Golang实现Redis经典应用案例","uri":"/2024-03-26/example-golang/"},{"categories":["redis"],"content":"代码实现 package example import ( \"context\" \"fmt\" \"log\" \"strconv\" \"time\" ) const ex07Channel = \"es_ch\" func Ex07(ctx context.Context) { pubSub := RedisCli.Subscribe(ctx, ex07Channel) go func() { for i := 0; i \u003c 5; i++ { RedisCli.Publish(ctx, ex07Channel, i) } time.Sleep(time.Second) if err := pubSub.Unsubscribe(ctx, ex07Channel); err != nil { log.Fatal(err) } _ = pubSub.Close() }() for msg := range pubSub.Channel() { arcId, err := strconv.ParseInt(msg.Payload, 10, 64) if err != nil { panic(err) } fmt.Printf(\"读取文章[%d]标题、正文，发送到ES更新索引\\n\", arcId) } } ","date":"2024-03-26","objectID":"/2024-03-26/example-golang/:8:1","tags":["redis","golang","实战"],"title":"『实战』使用Golang实现Redis经典应用案例","uri":"/2024-03-26/example-golang/"},{"categories":["redis"],"content":"测试结果：go run main.go Ex07 (base) ➜ go-redis-example git:(main) ✗ go run main.go Ex07 输入参数: Ex07 ---------- 读取文章[0]标题、正文，发送到ES更新索引 读取文章[1]标题、正文，发送到ES更新索引 读取文章[2]标题、正文，发送到ES更新索引 读取文章[3]标题、正文，发送到ES更新索引 读取文章[4]标题、正文，发送到ES更新索引 ","date":"2024-03-26","objectID":"/2024-03-26/example-golang/:8:2","tags":["redis","golang","实战"],"title":"『实战』使用Golang实现Redis经典应用案例","uri":"/2024-03-26/example-golang/"},{"categories":["redis"],"content":"总结 通过上述的 Redis 实战案例，管中窥豹地了解了 Redis 的一些经典用法。实际上 Redis 的功能并不止于此，在日后的学习工作中，Redis 也将会继续发挥更大的作用。 ","date":"2024-03-26","objectID":"/2024-03-26/example-golang/:9:0","tags":["redis","golang","实战"],"title":"『实战』使用Golang实现Redis经典应用案例","uri":"/2024-03-26/example-golang/"},{"categories":["golang"],"content":"简单介绍一下 pprof 工具的采样过程以及原理 ","date":"2024-03-24","objectID":"/2024-03-24/pprof-theory/:0:0","tags":["golang","pprof","性能优化"],"title":"Golang性能分析工具之pprof采样过程与原理","uri":"/2024-03-24/pprof-theory/"},{"categories":["golang"],"content":"CPU 采样对象：函数调用和它们的占用时间 采样率：100 次/秒，固定值 采样时间：从手动开始到手动结束 采样时，进程每秒会暂停 100 次，每次暂停会记录当前的调用栈信息，汇总之后根据调用栈在采样中出现的次数来推断程序的运行时间。 CPU采样步骤 操作系统：由进程注册的定时器，每 10ms 向进程发送一次 SIGPROF 信号 进程：每次收到 SIGPROF 信号会记录调用堆栈 写缓冲：启动一个 goroutine，每 100ms 读取已经记录的调用栈并写入输入流 采样停止时，进程向 OS 取消定时器，不再接受信号，写缓冲读取不到新的堆栈信息时，结束输出 CPU采样流程 ","date":"2024-03-24","objectID":"/2024-03-24/pprof-theory/:1:0","tags":["golang","pprof","性能优化"],"title":"Golang性能分析工具之pprof采样过程与原理","uri":"/2024-03-24/pprof-theory/"},{"categories":["golang"],"content":"Heap - 堆内存 提到的内存的概念说的都是堆内存，而非内存，因为 pprof 的采样有局限性。 在实现上依赖于内存分配器的记录，所有它只记录在堆上的分配，并且会参与 GC 的内存，一些预分配的内存，例如调用结束就会回收的栈内存、一些更底层使用 cgo 分配的内存等，是不会被内存采样记录的 采样过程如下： 采样程序通过内存分配器在堆上分配和释放的内存，记录分配/释放内存的大小和数量 采样率：每分配 512KB 记录一次，可在运行的开头进行修改，设为 1 则每次分配都记录 采样时间：从程序运行开始到采样时，内存采样是一个持续的过程，会记录从运行开始所有分配或释放的内存大小和对象数量，并在采样时遍历这些结果进行汇总 采样指标：alloc_space,alloc_objects,inuse_space,inuse_objects 计算方式：$inuse = alloc - free$ ","date":"2024-03-24","objectID":"/2024-03-24/pprof-theory/:2:0","tags":["golang","pprof","性能优化"],"title":"Golang性能分析工具之pprof采样过程与原理","uri":"/2024-03-24/pprof-theory/"},{"categories":["golang"],"content":"Goroutine 协程 \u0026 ThreadCreate 线程 Goroutine：记录所有用户发起且运行中的 goroutine（即入口非 runtime 开头的），以及 main 函数所在的 goroutine 信息和创建这些 goroutine 的调用栈 ThreadCreate：记录程序创建的所有系统线程的信息 协程和线程创建的采样流程 可以发现都是在 STW 之后，遍历所有 goroutine/线程的列表（M 对应 GMP 中的 M，在 Golang 中和线程一一对应）并输出堆栈，最后 Start The World 继续运行。这个采样是立刻触发的全量记录，可以比较两个时间点的差值来得到某一时间段的指标 ","date":"2024-03-24","objectID":"/2024-03-24/pprof-theory/:3:0","tags":["golang","pprof","性能优化"],"title":"Golang性能分析工具之pprof采样过程与原理","uri":"/2024-03-24/pprof-theory/"},{"categories":["golang"],"content":"Block 阻塞 \u0026 Mutex 锁 阻塞操作： 采样阻塞操作的次数和耗时 采样率：阻塞耗时超过阈值才会被记录，设置为 1 时表示每次阻塞都会被记录 锁竞争： 采样争抢锁的次数和耗时 采样率：只记录固定比例的锁操作，设置为 1 时表示每次加锁均被记录 阻塞和锁竞争的采样流程 阻塞操作的采样率是一个阈值，消耗超过阈值时间的阻塞操作才会被记录。而锁竞争的采样率是一个比例，运行时会通过随机数来记录固定比例的锁操作。 实现上都是一个主动上报的过程，在阻塞操作和锁竞争发生时，会计算出消耗时间，连同调用栈一起上报给采样器，采样器会根据采样率丢弃一些数据。采样时，采样器会遍历已经记录的信息，统计出具体操作的次数，调用栈和总耗时。并且可以对比两个时间点的差异值。 ","date":"2024-03-24","objectID":"/2024-03-24/pprof-theory/:4:0","tags":["golang","pprof","性能优化"],"title":"Golang性能分析工具之pprof采样过程与原理","uri":"/2024-03-24/pprof-theory/"},{"categories":["golang"],"content":"Reference 性能优化分析工具 ","date":"2024-03-24","objectID":"/2024-03-24/pprof-theory/:5:0","tags":["golang","pprof","性能优化"],"title":"Golang性能分析工具之pprof采样过程与原理","uri":"/2024-03-24/pprof-theory/"},{"categories":["golang"],"content":"通过实战来了解、熟悉 pprof 工具的使用 引言 benchmark(基准测试) 可以度量某个函数或方法的性能，也就是说，如果我们知道性能的瓶颈点在哪里，benchmark 一是个非常好的方式。但是面对一个未知的程序，如何去分析这个程序的性能，并找到瓶颈点呢？ pprof 就是用来解决这个问题的。pprof 包含两部分： 编译到程序中的 runtime/pprof 包 性能剖析工具 go tool pprof pprof 主要可以分析 CPU、内存的使用情况、阻塞情况、Goroutine 的堆栈信息以及锁争用情况等性能问题。 该博客涉及到的项目代码：https://github.com/pjimming/go-pprof-practice ","date":"2024-03-24","objectID":"/2024-03-24/pprof/:0:0","tags":["golang","pprof","性能优化","实战"],"title":"Golang性能分析工具之pprof实战","uri":"/2024-03-24/pprof/"},{"categories":["golang"],"content":"环境搭建 从 GitHub 上获取一个性能堪忧的项目，有助于更好的使用 pprof 监控到程序的性能问题。 务必确保你是在个人机器上运行“炸弹”的，能接受机器死机重启的后果（虽然这发生的概率很低）。请你务必不要在危险的边缘试探，比如在线上服务器运行这个程序。 ","date":"2024-03-24","objectID":"/2024-03-24/pprof/:1:0","tags":["golang","pprof","性能优化","实战"],"title":"Golang性能分析工具之pprof实战","uri":"/2024-03-24/pprof/"},{"categories":["golang"],"content":"图形化依赖安装 选择合适的包安装工具，安装图形化依赖 graphviz brew install graphviz # macos apt install graphviz # ubuntu yum install graphviz # centos ","date":"2024-03-24","objectID":"/2024-03-24/pprof/:1:1","tags":["golang","pprof","性能优化","实战"],"title":"Golang性能分析工具之pprof实战","uri":"/2024-03-24/pprof/"},{"categories":["golang"],"content":"获取炸弹并运行 Linux(Ubuntu) 系统下： git clone git@github.com:pjimming/go-pprof-practice.git cd go-pprof-practice make run ","date":"2024-03-24","objectID":"/2024-03-24/pprof/:1:2","tags":["golang","pprof","性能优化","实战"],"title":"Golang性能分析工具之pprof实战","uri":"/2024-03-24/pprof/"},{"categories":["golang"],"content":"指标查看 保持程序的运行，打开浏览器访问 http://localhost:6060/debug/pprof/，可以看到如下的页面： /debug/pprof 页面 页面上展示了采样的信息，分别是： 类型 描述 allocs 内存分配情况的采样信息 block 阻塞操作情况的采样信息 cmdline 显示程序启动命令及参数 goroutine 当前所有协程的堆栈信息 heap 堆上内存使用情况的采样信息 mutex 锁争用情况的采样信息 profile CPU 占用情况的采样信息 threadcreate 系统线程创建情况的采样信息 trace 程序运行跟踪信息 由于直接阅读采样信息缺乏直观性，我们需要借助 go tool pprof 命令来排查问题，这个命令是 go 原生自带的，所以不用额外安装。 ","date":"2024-03-24","objectID":"/2024-03-24/pprof/:2:0","tags":["golang","pprof","性能优化","实战"],"title":"Golang性能分析工具之pprof实战","uri":"/2024-03-24/pprof/"},{"categories":["golang"],"content":"排查 CPU 占用过高 执行 top 命令，可以发现当前程序占用的 CPU 过高，如下图所示： top命令：查看当前资源使用情况 此时使用 go tool pprof 命令对 CPU 运行情况进行采样，使用下列命令，每 10s 对 CPU 使用情况进行采样。 go tool pprof \"http://localhost:6060/debug/pprof/profile?seconds=10\" 因为我们这里采集的是 profile 类型，因此需要等待一定的时间来对 CPU 做采样。你可以通过查询字符串中 seconds 参数来调节采样时间的长短（单位为秒） 等待 10s 左右之后，进入一个可交互的命令行页面： 执行命令进入CPU采样的可交互命令 执行 top 命令，查看 CPU 调用较高的函数： pprof中执行top命令 参数说明： 类型 描述 flat 当前函数本身的执行耗时 flat% flat 占 CPU 总时间的比例 sum% 上面每一行的 flat%总和 cum 指当前函数本身加上其调用函数的总耗时 cum% cum 占 CUP 总时间的比例 其中： $flat==cum$ 时，函数中没有调用其他函数 $flat==0$ 时，函数中只有其他函数的调用 发现是 Eat 函数调用 CPU 过高，此时执行 list Eat 命令，查看问题具体在代码的哪一个位置： pprof中执行list Eat命令 从输出结果里可以看到对应的文件为 /animal/felidae/tiger/tiger.go，而且具体的代码行为 24 行的一百亿次 for 循环导致的。 我们尝试注释这段代码，并且重新编译运行，看看 CPU 使用率是否会下降 func (t *Tiger) Eat() { log.Println(t.Name(), \"eat\") //loop := 10000000000 //for i := 0; i \u003c loop; i++ { // // do nothing //} } 中断之前的程序，重新执行 make run 命令，可以发现 CPU 的占用情况下降了。 top命令中，进程占用CPU出现下降情况 ","date":"2024-03-24","objectID":"/2024-03-24/pprof/:3:0","tags":["golang","pprof","性能优化","实战"],"title":"Golang性能分析工具之pprof实战","uri":"/2024-03-24/pprof/"},{"categories":["golang"],"content":"排查内存占用过高 根据上图执行的 top 命令来看，发现程序当前占用的内存较高，我们可以通过 pprof 的 heap 来查看堆内存使用情况 执行命令： go tool pprof \"http://localhost:6060/debug/pprof/heap\" 然后执行 top 命令，发现 Steal 占用大量的内存情况： pprof中执行top命令 执行 list Steal 命令，查看代码细节： pprof中执行list Steal命令 根据代码细节的问题，去按照实际情况解决即可。不过我们是否还记得之前安装的图形化依赖，可以通过图形化的方式去查看性能问题。因为 web 页面可视化的方式排查比较直观，因此命令行排查的方式就不再展开了，输入以下命令可以看到堆内存的占用情况： go tool pprof -http=:8080 \"http://localhost:6060/debug/pprof/heap\" 这个命令中 http 选项将会启动一个 web 服务器并自动打开网页。其值为 web 服务器的 endpoint 图形化页面 从上图我们可以发现 Mouse 类的 Steal 方法占用了大量的内存。我们点击 VIEW -\u003e Source 可以看到具体代码文件、行数以及资源使用情况。 代码细节 注释掉相关代码，重新编译运行，再次查看资源消耗的情况，可以发现 CPU 和内存都占用较低了。 CPU和内存占用情况下降 其中在 web 页面上，SIMPLE 里有四个选项，他们的含义为： 类型 描述 alloc_objects 程序累计申请的对象数 alloc_space 程序累计申请的内存大小 inuse_objects 程序当前持有的对象数 inuse_space 程序当前占用的内存大小 在堆内存采样中，默认展示的是 inuse_space 视图，只展示当前持有的内存，但如果有内存已经释放，这是 inuse 采样就不会展示了。 在后续排查 GC 问题的时候，也可以根据 alloc_space 指标来排查。 ","date":"2024-03-24","objectID":"/2024-03-24/pprof/:4:0","tags":["golang","pprof","性能优化","实战"],"title":"Golang性能分析工具之pprof实战","uri":"/2024-03-24/pprof/"},{"categories":["golang"],"content":"排查频繁内存回收 你应该知道，频繁的 GC 对 golang 程序性能的影响也是非常严重的。虽然现在这个炸弹程序内存使用量并不高，但这会不会是频繁 GC 之后的假象呢？ 为了获取程序运行过程中 GC 日志，我们需要先退出炸弹程序，再在重新启动前赋予一个环境变量，同时为了避免其他日志的干扰，使用 grep 筛选出 GC 日志查看： GODEBUG=gctrace=1 ./pprof-amd64-linux | grep gc 可以发现打出的 log 信息，分析可以发现，GC 差不多每 3 秒就发生一次，且每次 GC 都会从 16MB 清理到几乎 0MB，说明程序在不断的申请内存再释放，这是高性能 golang 程序所不允许的。 gc 1 @0.001s 1%: 0.005+0.64+0.001 ms clock, 0.005+0.032/0.19/0+0.001 ms cpu, 16-\u003e16-\u003e0 MB, 16 MB goal, 0 MB stacks, 0 MB globals, 1 P gc 2 @1.007s 0%: 0.021+0.36+0.002 ms clock, 0.021+0.038/0.094/0.065+0.002 ms cpu, 16-\u003e16-\u003e0 MB, 16 MB goal, 0 MB stacks, 0 MB globals, 1 P gc 3 @2.009s 0%: 0.031+0.49+0.001 ms clock, 0.031+0.088/0.10/0+0.001 ms cpu, 16-\u003e16-\u003e0 MB, 16 MB goal, 0 MB stacks, 0 MB globals, 1 P gc 4 @3.013s 0%: 0.030+0.38+0.002 ms clock, 0.030+0.040/0.11/0.034+0.002 ms cpu, 16-\u003e16-\u003e0 MB, 16 MB goal, 0 MB stacks, 0 MB globals, 1 P gc 5 @4.017s 0%: 0.033+0.40+0.002 ms clock, 0.033+0.088/0.10/0+0.002 ms cpu, 16-\u003e16-\u003e0 MB, 16 MB goal, 0 MB stacks, 0 MB globals, 1 P gc 6 @5.021s 0%: 0.031+0.34+0.002 ms clock, 0.031+0.089/0.10/0+0.002 ms cpu, 16-\u003e16-\u003e0 MB, 16 MB goal, 0 MB stacks, 0 MB globals, 1 P gc 7 @6.026s 0%: 0.43+0.35+0.002 ms clock, 0.43+0.088/0.10/0+0.002 ms cpu, 16-\u003e16-\u003e0 MB, 16 MB goal, 0 MB stacks, 0 MB globals, 1 P gc 8 @7.031s 0%: 0.031+0.42+0.002 ms clock, 0.031+0.10/0.10/0+0.002 ms cpu, 16-\u003e16-\u003e0 MB, 16 MB goal, 0 MB stacks, 0 MB globals, 1 P gc 9 @8.034s 0%: 0.030+0.40+0.002 ms clock, 0.030+0.095/0.11/0+0.002 ms cpu, 16-\u003e16-\u003e0 MB, 16 MB goal, 0 MB stacks, 0 MB globals, 1 P gc 10 @9.038s 0%: 0.030+0.40+0.002 ms clock, 0.030+0.049/0.14/0.008+0.002 ms cpu, 16-\u003e16-\u003e0 MB, 16 MB goal, 0 MB stacks, 0 MB globals, 1 P gc 11 @10.042s 0%: 0.037+0.41+0.001 ms clock, 0.037+0.058/0.15/0.001+0.001 ms cpu, 16-\u003e16-\u003e0 MB, 16 MB goal, 0 MB stacks, 0 MB globals, 1 P gc 12 @11.045s 0%: 0.033+0.47+0.001 ms clock, 0.033+0.044/0.14/0.009+0.001 ms cpu, 16-\u003e16-\u003e0 MB, 16 MB goal, 0 MB stacks, 0 MB globals, 1 P gc 13 @12.049s 0%: 0.033+0.52+0.002 ms clock, 0.033+0.054/0.15/0+0.002 ms cpu, 16-\u003e16-\u003e0 MB, 16 MB goal, 0 MB stacks, 0 MB globals, 1 P gc 14 @13.052s 0%: 0.032+0.37+0.002 ms clock, 0.032+0.048/0.11/0.038+0.002 ms cpu, 16-\u003e16-\u003e0 MB, 16 MB goal, 0 MB stacks, 0 MB globals, 1 P gc 15 @14.054s 0%: 0.032+0.41+0.001 ms clock, 0.032+0.046/0.13/0.034+0.001 ms cpu, 16-\u003e16-\u003e0 MB, 16 MB goal, 0 MB stacks, 0 MB globals, 1 P gc 16 @15.057s 0%: 0.032+0.48+0.002 ms clock, 0.032+0.045/0.15/0+0.002 ms cpu, 16-\u003e16-\u003e0 MB, 16 MB goal, 0 MB stacks, 0 MB globals, 1 P 此外也可以通过 heap 的 alloc_space 视图来查看。执行命令： go tool pprof -http=:8080 \"http://localhost:6060/debug/pprof/heap\" 选择 SIMPLE-\u003ealloc_space，发现 Dog 方法申请了大量的内存。 Dog类申请了784MB的内存 查看源码分析代码的问题，原来是 Run 方法在不断的申请内存。 Dog类申请内存代码细节 这里有个小插曲，你可尝试一下将 16 * constant.Mi 修改成一个较小的值，重新编译运行，会发现并不会引起频繁 GC，原因是在 golang 里，对象是使用堆内存还是栈内存，由编译器进行逃逸分析并决定，如果对象不会逃逸，便可在使用栈内存，但总有意外，就是对象的尺寸过大时，便不得不使用堆内存。所以这里设置申请 16 MiB 的内存就是为了避免编译器直接在栈上分配，如果那样得话就不会涉及到 GC 了。 我们同样注释掉问题代码，重新编译执行，可以看到这一次，程序的 GC 频度要低很多，以至于短时间内都看不到 GC 日志了： 执行GC追踪，发现GC不频繁了 ","date":"2024-03-24","objectID":"/2024-03-24/pprof/:5:0","tags":["golang","pprof","性能优化","实战"],"title":"Golang性能分析工具之pprof实战","uri":"/2024-03-24/pprof/"},{"categories":["golang"],"content":"排查协程泄漏问题 在http://localhost:6060/debug/pprof/页面可以发现，协程的数量居然多达 100 多个，这对这个小程序来说，是不正常的，通过运行下列命令，去查看到底是怎么回事 go tool pprof -http=:8080 \"http://localhost:6060/debug/pprof/goroutine\" 得到图形化页面，如下图所示： 协程pprof页面 发现调用的链路比较长，此时我们可以通过火焰图来更直观的查看，点击 VIEW-\u003eFlame Graph，我们可以发现是 Wolf.Drink() 这个函数产生了大量的协程。 pprof生成的火焰图 在 VIEW-\u003eSource 里，输入 Drink 来查询代码细节，可以看到，Drink 方法每次会起 10 个协程，每个协程会 sleep 30 秒再推出，而 Drink 函数又被反复的调用，这才导致了大量的协程泄漏。 Wolf类Drink方法代码细节 试想一下，如果我们业务中起的协程会永久阻塞，那么泄漏的协程数量便会持续增加，从而导致内存的持续增加，那么迟早会被 OS Kill 掉。我们通过注释掉问题代码，重新运行可以看到协程数量已经降低到个位数的水平了。 goroutine数量减少 ","date":"2024-03-24","objectID":"/2024-03-24/pprof/:6:0","tags":["golang","pprof","性能优化","实战"],"title":"Golang性能分析工具之pprof实战","uri":"/2024-03-24/pprof/"},{"categories":["golang"],"content":"排查锁的争用关系 到目前为止，我们已经基本解决了这个炸弹程序所有的资源占用问题，但是日常业务中不仅仅有资源占用问题，还有性能问题。 下面将开始对性能进行优化，首先能想到的就是不合理的锁竞争，比如加锁时间过长。发现 debug 页面里存在锁的竞争情况。执行下列命令进行查看。 go tool pprof -http=:8080 \"http://localhost:6060/debug/pprof/mutex\" 可以发现 Wolf 这个类里，存在锁长时间等待问题。 Wolf锁竞争图形化页面 锁竞争具体代码细节 可以看到，这个锁由主协程 Lock，并启动子协程去 Unlock，主协程会阻塞在第二次 Lock 这里等待子协程完成任务，但由于子协程足足睡眠了一秒，导致主协程等待这个锁释放足足等了一秒钟。我们对此处代码进行修改即可修复问题。 ","date":"2024-03-24","objectID":"/2024-03-24/pprof/:7:0","tags":["golang","pprof","性能优化","实战"],"title":"Golang性能分析工具之pprof实战","uri":"/2024-03-24/pprof/"},{"categories":["golang"],"content":"排查协程阻塞问题 除了锁会阻塞之外，还有很多逻辑会导致当前协程阻塞。可以发现 debug 页面上，存在两个 block。 /debug/pprof页面 执行命令查看 block 信息： go tool pprof -http=:8080 \"http://localhost:6060/debug/pprof/block\" 可以发现存在 Cat 类的方法导致存在协程阻塞。 Cat阻塞 查询 Cat 涉及到的源码 Cat代码细节 可以看到这里不同于直接 sleep 一秒，这里是从一个 channel 里读数据时，发生了阻塞。直到这个 channel 在一秒后才有数据读出，因此这里会导致程序阻塞，而不是睡眠。 我们对此代码注释掉，重新编译运行后发现程序还有一个 block。通过排查分析后我们发现是因为程序提供了 HTTP 的 pprof 服务，程序阻塞在对 HTTP 端口的监听上，因此这个阻塞是正常的。 ","date":"2024-03-24","objectID":"/2024-03-24/pprof/:8:0","tags":["golang","pprof","性能优化","实战"],"title":"Golang性能分析工具之pprof实战","uri":"/2024-03-24/pprof/"},{"categories":["golang"],"content":"排查内存泄漏 pprof 中有一个 -base 选项，它用于指定基准采样文件，这样可以通过比较两个采样数据，从而查看到指标的变化，例如函数的 CPU 使用时间或内存分配情况。 举个具体的例子，在业务中有一个低频调用的接口存在内存泄漏（OOM），它每被调用一就会泄漏 1MiB 的内存。这个接口每天被调用 10 次。假设我们给这个服务分配了 100MiB 空余的内存，也就是说这个接口基本上每十天就会挂一次，但当我们排查问题的时候，会发现内存是缓慢增长的。此时如果你仅通过 pprof 采样单个文件来观察，基本上很难会发现泄漏点。 这时候 base 选项就派上用场了，我们可以在服务启动后采集一个基准样本，过几天后再采集一次。通过比对这两个样本增量数据，我们就很容易发现出泄漏点。 同样的，这个炸弹我也已经预埋了这样一个缓慢的泄漏点，但时间我缩短了一下。相信在上面的实操过程中你也发现了端倪，下面我们开始实操一下。 我们运行这个炸弹程序，将启动时的堆内存分配情况保存下来，你可以在 debug 页面点击下载，也可以在终端中执行 curl -o heap-base http://localhost:6060/debug/pprof/heap 来下载。 在资源管理器中我们可以看到程序刚启动的时候，内存占用并不高： top命令里进程消耗资源情况 过了一段时间之后，我们可以清楚的发现程序内存开始逐渐增长： 一段时间后进程资源消耗情况 此时我们再执行 curl -o heap-target http://localhost:6060/debug/pprof/heap 获取到当前的采样数据。 再获取到两个样本数据后，我们通过 base 选项将 heap-base 作为基准，查看运行的这段时间内哪里内存增长了 go tool pprof -http=:8080 -base heap-base heap-target 可以发现在这段时间内，Mouse.Pee()方法增长了 768MB 的内存，显然这里发生了内存泄漏。 Mouse内存泄漏 通过查看源码，修复问题。 Mouse代码细节 ","date":"2024-03-24","objectID":"/2024-03-24/pprof/:9:0","tags":["golang","pprof","性能优化","实战"],"title":"Golang性能分析工具之pprof实战","uri":"/2024-03-24/pprof/"},{"categories":["golang"],"content":"总结 本文主要内容为 pprof 工具的使用，介绍了通过命令行、可视化等方式进行排查。虽然例子比较简单，但是相信通过这些简单的例子可以让你不在畏惧 pprof。 ","date":"2024-03-24","objectID":"/2024-03-24/pprof/:10:0","tags":["golang","pprof","性能优化","实战"],"title":"Golang性能分析工具之pprof实战","uri":"/2024-03-24/pprof/"},{"categories":["golang"],"content":"Reference golang pprof 实战 Go 性能分析工具 ","date":"2024-03-24","objectID":"/2024-03-24/pprof/:11:0","tags":["golang","pprof","性能优化","实战"],"title":"Golang性能分析工具之pprof实战","uri":"/2024-03-24/pprof/"},{"categories":["paper"],"content":"泛读小红书 InstantX 团队与北京大学联合发表的InstantID论文 ","date":"2024-03-21","objectID":"/2024-03-21/instantid/:0:0","tags":["paper","InstantID","AIGC"],"title":"【论文泛读】InstantID: Zero-shot Identity-Preserving Generation in Seconds","uri":"/2024-03-21/instantid/"},{"categories":["paper"],"content":"Motivation 现有 Face Customization 存在的缺点： High storage demands: 需要大量的空间去存储训练得到的模型 Lengthy fine-tuning process: 训练代价大 Need multiple reference images: 需要多张参考图 InstantID 改善： Zero-shot: 零插拔 Tuning-free: 低代价 High fidelity: 高保真 ","date":"2024-03-21","objectID":"/2024-03-21/instantid/:1:0","tags":["paper","InstantID","AIGC"],"title":"【论文泛读】InstantID: Zero-shot Identity-Preserving Generation in Seconds","uri":"/2024-03-21/instantid/"},{"categories":["paper"],"content":"Method InstantID的算法流程 通过 Face Encoder 解码人脸信息，代替 CLIP Encoder，并使用可训练的投影层将其投影到文本特征空间，将投影后得到的特征作为 Face Embedding 引入轻量级解耦交叉注意力自适应模块（Image Adapter），将 Face Embedding 与 Text Embedding 结合，支持图像作为提示，与 IP-Adapter 类似，把 Embedding 注入到 UNet 中 改动 ControlNet，提出 IdentityNet，对输入的图片提取 landmarks，得到五官的点位，与之前得到的 Face Embedding 结合，避免表情、环境、姿势影响身份信息，消除 Text 的影响，对参考人脸图像的详细特征进行编码，并具有额外的空间控制 ","date":"2024-03-21","objectID":"/2024-03-21/instantid/:2:0","tags":["paper","InstantID","AIGC"],"title":"【论文泛读】InstantID: Zero-shot Identity-Preserving Generation in Seconds","uri":"/2024-03-21/instantid/"},{"categories":["paper"],"content":"Result InstantID的成果 ","date":"2024-03-21","objectID":"/2024-03-21/instantid/:3:0","tags":["paper","InstantID","AIGC"],"title":"【论文泛读】InstantID: Zero-shot Identity-Preserving Generation in Seconds","uri":"/2024-03-21/instantid/"},{"categories":["paper"],"content":"Reference InstantID: Zero-shot Identity-Preserving Generation in Seconds 【InstantID 论文解析】小红书+北大爆火的项目 InstantID，连 LeCun 都点赞！ ","date":"2024-03-21","objectID":"/2024-03-21/instantid/:4:0","tags":["paper","InstantID","AIGC"],"title":"【论文泛读】InstantID: Zero-shot Identity-Preserving Generation in Seconds","uri":"/2024-03-21/instantid/"},{"categories":["golang"],"content":"介绍 Golang 编码中，对于性能方面的调优方法 前言 性能优化的前提是满足正确、可靠、健壮、可读 性能优化时综合评估，有时候时间效率和空间效率可能会相互对立 该文章中涉及到的代码：https://github.com/pjimming/blog-code/tree/main/go-performance-optimization ","date":"2024-03-21","objectID":"/2024-03-21/performance-optimization/:0:0","tags":["golang","性能优化"],"title":"Golang高性能优化实战案例","uri":"/2024-03-21/performance-optimization/"},{"categories":["golang"],"content":"性能衡量工具：Benchmark Go benchmark 详解 接下来测试下列代码的性能 func Fib(n int) int { if n \u003c 2 { return n } return Fib(n-1) + Fib(n-2) } func BenchmarkFib10(b *testing.B) { for i := 0; i \u003c b.N; i++ { Fib(10) } } 通过运行 go test -bench=. -benchmem 来统计代码占用内存信息 (base) ➜ benchmark git:(main) ✗ go test -bench=. -benchmem goos: darwin goarch: amd64 pkg: go-performance-optimization/benchmark cpu: Intel(R) Core(TM) i5-7360U CPU @ 2.30GHz BenchmarkFib10-4 4193748 291.2 ns/op 0 B/op 0 allocs/op PASS ok go-performance-optimization/benchmark 2.111s (base) ➜ benchmark git:(main) ✗ 对于运行结果第六行的参数解析： BenchmarkFib10-4：BenchmarkFib10 是测试函数名，-4 代表 GOMAXPROCS 的值为 4 4193748：表示一共执行了 4193748，即 b.N 的值 291.2 ns/op：每次执行花费 291.2ns 0 B/op：每次执行申请的内存 0 allocs/op：每次执行申请几次内存 ","date":"2024-03-21","objectID":"/2024-03-21/performance-optimization/:1:0","tags":["golang","性能优化"],"title":"Golang高性能优化实战案例","uri":"/2024-03-21/performance-optimization/"},{"categories":["golang"],"content":"Slice：优化内存空间 ","date":"2024-03-21","objectID":"/2024-03-21/performance-optimization/:2:0","tags":["golang","性能优化"],"title":"Golang高性能优化实战案例","uri":"/2024-03-21/performance-optimization/"},{"categories":["golang"],"content":"预分配内存 尽可能在使用 make()初始化切片时提供容量信息 测试代码： func NoPreAlloc(size int) { data := make([]int, 0) for i := 0; i \u003c size; i++ { data = append(data, i) } } func PreAlloc(size int) { data := make([]int, 0, size) for i := 0; i \u003c size; i++ { data = append(data, i) } } func BenchmarkNoPreAlloc(b *testing.B) { for i := 0; i \u003c b.N; i++ { NoPreAlloc(1000) } } func BenchmarkPreAlloc(b *testing.B) { for i := 0; i \u003c b.N; i++ { PreAlloc(1000) } } 运行结果： (base) ➜ go-performance-optimization git:(main) ✗ go test ./slice -bench=. -benchmem goos: darwin goarch: amd64 pkg: go-performance-optimization/slice cpu: Intel(R) Core(TM) i5-7360U CPU @ 2.30GHz BenchmarkNoPreAlloc-4 217953 4963 ns/op 25208 B/op 12 allocs/op BenchmarkPreAlloc-4 640620 1809 ns/op 8192 B/op 1 allocs/op PASS ok go-performance-optimization/slice 2.890s ","date":"2024-03-21","objectID":"/2024-03-21/performance-optimization/:2:1","tags":["golang","性能优化"],"title":"Golang高性能优化实战案例","uri":"/2024-03-21/performance-optimization/"},{"categories":["golang"],"content":"陷阱：大内存未释放 在已有切片的基础上创建切片，不会创建新的底层数组 场景： 原切片较大，代码在原切片的基础上新建小切片 原底层数组在内存中有引用，得不到释放 解决：使用 copy 替代 re-slice 代码： func generateWithCap(n int) []int { r := rand.New(rand.NewSource(time.Now().UnixNano())) nums := make([]int, 0, n) for i := 0; i \u003c n; i++ { nums = append(nums, r.Int()) } return nums } func printMem(t *testing.T) { t.Helper() var rtm runtime.MemStats runtime.ReadMemStats(\u0026rtm) t.Logf(\"%.2f MB\", float64(rtm.Alloc)/1024./1024.) } func testLastChars(t *testing.T, f func([]int) []int) { t.Helper() ans := make([][]int, 0) for k := 0; k \u003c 100; k++ { origin := generateWithCap(128 * 1024) // 1M ans = append(ans, f(origin)) } printMem(t) _ = ans } func GetLastBySlice(origin []int) []int { return origin[len(origin)-2:] } func GetLastByCopy(origin []int) []int { ret := make([]int, 2) copy(ret, origin[len(origin)-2:]) return ret } func TestLastCharsBySlice(t *testing.T) { testLastChars(t, GetLastBySlice) } func TestLastCharsByCopy(t *testing.T) { testLastChars(t, GetLastByCopy) } 运行结果： (base) ➜ go-performance-optimization git:(main) ✗ go test ./slice -run=^TestLastChars -v === RUN TestLastCharsBySlice slice_test.go:74: 100.24 MB --- PASS: TestLastCharsBySlice (0.15s) === RUN TestLastCharsByCopy slice_test.go:78: 3.12 MB --- PASS: TestLastCharsByCopy (0.15s) PASS ok go-performance-optimization/slice 0.759s 结果差异非常明显，lastNumsBySlice 耗费了 100.24 MB 内存，也就是说，申请的 100 个 1 MB 大小的内存没有被回收。因为切片虽然只使用了最后 2 个元素，但是因为与原来 1M 的切片引用了相同的底层数组，底层数组得不到释放，因此，最终 100 MB 的内存始终得不到释放。而 lastNumsByCopy 仅消耗了 3.12 MB 的内存。这是因为，通过 copy，指向了一个新的底层数组，当 origin 不再被引用后，内存会被垃圾回收(garbage collector, GC)。 如果在循环里面显性的调用 runtime.GC()，效果更明显： func testLastChars(t *testing.T, f func([]int) []int) { t.Helper() ans := make([][]int, 0) for k := 0; k \u003c 100; k++ { origin := generateWithCap(128 * 1024) // 1M ans = append(ans, f(origin)) runtime.GC() // 显性垃圾回收 } printMem(t) _ = ans } 执行结果： (base) ➜ go-performance-optimization git:(main) ✗ go test ./slice -run=^TestLastChars -v === RUN TestLastCharsBySlice slice_test.go:75: 100.11 MB --- PASS: TestLastCharsBySlice (0.14s) === RUN TestLastCharsByCopy slice_test.go:79: 0.11 MB --- PASS: TestLastCharsByCopy (0.09s) PASS ok go-performance-optimization/slice 0.812s ","date":"2024-03-21","objectID":"/2024-03-21/performance-optimization/:2:2","tags":["golang","性能优化"],"title":"Golang高性能优化实战案例","uri":"/2024-03-21/performance-optimization/"},{"categories":["golang"],"content":"Map：预分配内存 不断向 map 里添加元素的操作会触发 map 的扩容 提前分配好空间可以减少内存拷贝以及 Rehash 的消耗 根据实际需求提前预估好需要的空间 代码： func NoPreAlloc(size int) { data := make(map[int]int) for i := 0; i \u003c size; i++ { data[i] = i } } func PreAlloc(size int) { data := make(map[int]int, size) for i := 0; i \u003c size; i++ { data[i] = i } } func BenchmarkNoPreAlloc(b *testing.B) { for i := 0; i \u003c b.N; i++ { NoPreAlloc(1000) } } func BenchmarkPreAlloc(b *testing.B) { for i := 0; i \u003c b.N; i++ { PreAlloc(1000) } } 运行结果： (base) ➜ go-performance-optimization git:(main) ✗ go test ./map -bench=. -benchmem goos: darwin goarch: amd64 pkg: go-performance-optimization/map cpu: Intel(R) Core(TM) i5-7360U CPU @ 2.30GHz BenchmarkNoPreAlloc-4 16059 74349 ns/op 86551 B/op 64 allocs/op BenchmarkPreAlloc-4 37770 29789 ns/op 41097 B/op 6 allocs/op PASS ok go-performance-optimization/map 3.938s ","date":"2024-03-21","objectID":"/2024-03-21/performance-optimization/:3:0","tags":["golang","性能优化"],"title":"Golang高性能优化实战案例","uri":"/2024-03-21/performance-optimization/"},{"categories":["golang"],"content":"字符串：使用strings.Builder 常见的字符串拼接方式： func Plus(n int, str string) string { s := \"\" for i := 0; i \u003c n; i++ { s += str } return s } func StrBuilder(n int, str string) string { var builder strings.Builder for i := 0; i \u003c n; i++ { builder.WriteString(str) } return builder.String() } func ByteBuffer(n int, str string) string { buf := new(bytes.Buffer) for i := 0; i \u003c n; i++ { buf.WriteString(str) } return buf.String() } func BenchmarkPlus(b *testing.B) { for i := 0; i \u003c b.N; i++ { Plus(100, \"abc\") } } func BenchmarkStrBuilder(b *testing.B) { for i := 0; i \u003c b.N; i++ { StrBuilder(100, \"abc\") } } func BenchmarkByteBuffer(b *testing.B) { for i := 0; i \u003c b.N; i++ { ByteBuffer(100, \"abc\") } } 运行结果： (base) ➜ go-performance-optimization git:(main) ✗ go test ./string -bench=. -benchmem goos: darwin goarch: amd64 pkg: go-performance-optimization/string cpu: Intel(R) Core(TM) i5-7360U CPU @ 2.30GHz BenchmarkPlus-4 181742 6054 ns/op 15992 B/op 99 allocs/op BenchmarkStrBuilder-4 2173779 689.9 ns/op 1016 B/op 7 allocs/op BenchmarkByteBuffer-4 1253618 915.8 ns/op 1280 B/op 5 allocs/op PASS ok go-performance-optimization/string 5.977s 结论：使用+拼接性能最差，strings.Builder, bytes.Buffer 相近，strings.Buffer 更快 分析： 字符串在 Go 中是不可变类型，所占内存大小是固定的 每次+操作都会重新分配内存 而strings.Builder 和 bytes.Buffer 底层都是[]byte 数组 通过 slice 扩容策略，不需要每次拼接都分配内存 ","date":"2024-03-21","objectID":"/2024-03-21/performance-optimization/:4:0","tags":["golang","性能优化"],"title":"Golang高性能优化实战案例","uri":"/2024-03-21/performance-optimization/"},{"categories":["golang"],"content":"为什么 strings.Builder 更快？ 先上源码： // strings.Builder // String returns the accumulated string. func (b *Builder) String() string { return unsafe.String(unsafe.SliceData(b.buf), len(b.buf)) } // bytes.Buffer // String returns the contents of the unread portion of the buffer // as a string. If the [Buffer] is a nil pointer, it returns \"\u003cnil\u003e\". // // To build strings more efficiently, see the strings.Builder type. func (b *Buffer) String() string { if b == nil { // Special case, useful in debugging. return \"\u003cnil\u003e\" } return string(b.buf[b.off:]) } 根据源码可知： bytes.Buffer 转化为字符串时重新分配了一块空间 strings.Builder 直接将底层的 []byte 转换成了字符串 ","date":"2024-03-21","objectID":"/2024-03-21/performance-optimization/:4:1","tags":["golang","性能优化"],"title":"Golang高性能优化实战案例","uri":"/2024-03-21/performance-optimization/"},{"categories":["golang"],"content":"字符串也可以预分配内存 func PreStrBuilder(n int, str string) string { var builder strings.Builder builder.Grow(n * len(str)) for i := 0; i \u003c n; i++ { builder.WriteString(str) } return builder.String() } func PreByteBuffer(n int, str string) string { buf := new(bytes.Buffer) buf.Grow(n * len(str)) for i := 0; i \u003c n; i++ { buf.WriteString(str) } return buf.String() } func BenchmarkPreStrBuilder(b *testing.B) { for i := 0; i \u003c b.N; i++ { PreStrBuilder(100, \"abc\") } } func BenchmarkPreByteBuffer(b *testing.B) { for i := 0; i \u003c b.N; i++ { PreByteBuffer(100, \"abc\") } } 运行结果： (base) ➜ go-performance-optimization git:(main) ✗ go test ./string -bench=. -benchmem goos: darwin goarch: amd64 pkg: go-performance-optimization/string cpu: Intel(R) Core(TM) i5-7360U CPU @ 2.30GHz BenchmarkPlus-4 191355 6443 ns/op 15992 B/op 99 allocs/op BenchmarkStrBuilder-4 2216818 503.1 ns/op 1016 B/op 7 allocs/op BenchmarkByteBuffer-4 1288650 1528 ns/op 1280 B/op 5 allocs/op BenchmarkPreStrBuilder-4 2805319 468.2 ns/op 320 B/op 1 allocs/op BenchmarkPreByteBuffer-4 1594519 877.2 ns/op 640 B/op 2 allocs/op PASS ok go-performance-optimization/string 12.373s 根据上面的运行结果可知，bytes.Buffer 分配了两次内存 ","date":"2024-03-21","objectID":"/2024-03-21/performance-optimization/:4:2","tags":["golang","性能优化"],"title":"Golang高性能优化实战案例","uri":"/2024-03-21/performance-optimization/"},{"categories":["golang"],"content":"空结构体：节省内存资源 空结构体实例不占据任何内存空间，可作为各场景下的占位符使用，比如用 map 实现 set func EmptyStructMap(n int) { m := make(map[int]struct{}) for i := 0; i \u003c n; i++ { m[i] = struct{}{} } } func BoolMap(n int) { m := make(map[int]bool) for i := 0; i \u003c n; i++ { m[i] = false } } func BenchmarkEmptyStructMap(b *testing.B) { for i := 0; i \u003c b.N; i++ { EmptyStructMap(1000) } } func BenchmarkBoolMap(b *testing.B) { for i := 0; i \u003c b.N; i++ { BoolMap(1000) } } 运行结果： (base) ➜ go-performance-optimization git:(main) ✗ go test ./struct -bench=. -benchmem goos: darwin goarch: amd64 pkg: go-performance-optimization/struct cpu: Intel(R) Core(TM) i5-7360U CPU @ 2.30GHz BenchmarkEmptyStructMap-4 17043 84522 ns/op 47735 B/op 65 allocs/op BenchmarkBoolMap-4 10000 130275 ns/op 53316 B/op 73 allocs/op PASS ok go-performance-optimization/struct 4.088s ","date":"2024-03-21","objectID":"/2024-03-21/performance-optimization/:5:0","tags":["golang","性能优化"],"title":"Golang高性能优化实战案例","uri":"/2024-03-21/performance-optimization/"},{"categories":["golang"],"content":"atomic 包：并发情况下的资源保护 锁的实现是通过操作系统来实现，属于系统调用 atomic 通过硬件实现，效率比锁高 sync.Mutex 应该用于保护一段逻辑，而非仅仅保护一个变量 对于非数值操作，可以使用 atomic.Value，可以承载一个 interface{} 代码： type atomicCounter struct { i int32 } func AtomicAddOne(c *atomicCounter) { atomic.AddInt32(\u0026c.i, 1) } type mutexCounter struct { i int32 sync.Mutex } func MutexAddOne(c *mutexCounter) { c.Lock() c.i++ c.Unlock() } func BenchmarkAtomicAddOne(b *testing.B) { for i := 0; i \u003c b.N; i++ { c := new(atomicCounter) AtomicAddOne(c) } } func BenchmarkMutexAddOne(b *testing.B) { for i := 0; i \u003c b.N; i++ { c := new(mutexCounter) MutexAddOne(c) } } 运行结果： (base) ➜ go-performance-optimization git:(main) ✗ go test ./atomic -bench=. -benchmem goos: darwin goarch: amd64 pkg: go-performance-optimization/atomic cpu: Intel(R) Core(TM) i5-7360U CPU @ 2.30GHz BenchmarkAtomicAddOne-4 69622866 17.44 ns/op 4 B/op 1 allocs/op BenchmarkMutexAddOne-4 34958937 32.44 ns/op 16 B/op 1 allocs/op PASS ok go-performance-optimization/atomic 3.967s ","date":"2024-03-21","objectID":"/2024-03-21/performance-optimization/:6:0","tags":["golang","性能优化"],"title":"Golang高性能优化实战案例","uri":"/2024-03-21/performance-optimization/"},{"categories":["golang"],"content":"小结 避免常见的性能陷阱可以保证大部分程序的性能 普通应用，不要一味地追求程序的性能 越高深的性能优化手段越容易出现问题 在满足正确、可靠、简洁、清晰等质量要求的前提下，提高程序性能 ","date":"2024-03-21","objectID":"/2024-03-21/performance-optimization/:7:0","tags":["golang","性能优化"],"title":"Golang高性能优化实战案例","uri":"/2024-03-21/performance-optimization/"},{"categories":["golang"],"content":"参考 Go 语言高性能编程 ","date":"2024-03-21","objectID":"/2024-03-21/performance-optimization/:8:0","tags":["golang","性能优化"],"title":"Golang高性能优化实战案例","uri":"/2024-03-21/performance-optimization/"},{"categories":[],"content":" 前言 分享一些自己已读、未读或正在读的书籍，包括但不限于技术、哲学、社会科学、自然科学、文学类 如果有好书推荐，请您留言告知，不胜感激！ Z-Library 中国区官方：https://zh.zlibrary-global.se/ ","date":"2024-03-20","objectID":"/book-list/:0:0","tags":[],"title":"书中自有黄金屋","uri":"/book-list/"},{"categories":[],"content":"技术类 书名 开始时间 结束时间 评价 《自己动手写 Docker》 2024.02.14 2024.03.02 深入浅出，通过手写代码的方式，去了解 docker 的底层实现，例如 namespace、cgroups、rootfs 以及虚拟网络 《设计模式之美》 《凤凰架构》 《数据密集型应用系统设计》 《MySQL 实战 45 讲》 2024.04.24 ","date":"2024-03-20","objectID":"/book-list/:1:0","tags":[],"title":"书中自有黄金屋","uri":"/book-list/"},{"categories":["paper"],"content":"泛读腾讯 ARC Lab 与南开大学程明明老师联合发表的PhotoMaker论文，大致介绍动机、实现方法与成果 ","date":"2024-03-20","objectID":"/2024-03-20/photomaker/:0:0","tags":["paper","PhotoMaker","AIGC"],"title":"【论文泛读】PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding","uri":"/2024-03-20/photomaker/"},{"categories":["paper"],"content":"动机 ","date":"2024-03-20","objectID":"/2024-03-20/photomaker/:1:0","tags":["paper","PhotoMaker","AIGC"],"title":"【论文泛读】PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding","uri":"/2024-03-20/photomaker/"},{"categories":["paper"],"content":"DreamBooth 痛点 定制时间慢：由于需要在“测试”（定制）阶段对模型进行微调，理论上消耗的时间往往需要大约 15 分钟，在一些商业化的 APP 上，由于资源分配和排队的问题这一定制时间甚至要更久（数小时到数天）。 消耗显存高：如果不进行额外的优化，在 SDXL 底模上执行定制化过程只能在专业级显卡上进行，这些专业级显卡的昂贵都是出了名的。 对输入素材要求高：以妙鸭举例，它要求用户输入 20 张以上高质量的人像照片，且每次定制过程都需要重新进行收集。对用户来说非常不友好。 ","date":"2024-03-20","objectID":"/2024-03-20/photomaker/:1:1","tags":["paper","PhotoMaker","AIGC"],"title":"【论文泛读】PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding","uri":"/2024-03-20/photomaker/"},{"categories":["paper"],"content":"Insight 先前的工作都局限于下列两点： 输入图像和输出图像都来源于同一张图片，即得到的 embedding 很容易学习到姿态、表情这些与身份 ID 不相关的属性。 输入的每个 ID 图像都表征为了单一的 embedding。缺乏一定的可编辑性与变化，很难改变人脸相关的属性。 ","date":"2024-03-20","objectID":"/2024-03-20/photomaker/:1:2","tags":["paper","PhotoMaker","AIGC"],"title":"【论文泛读】PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding","uri":"/2024-03-20/photomaker/"},{"categories":["paper"],"content":"Target high efficiency: 高性能、低耗时的生成 AI 图像 promising identity (ID) fidelity: 高度保真的身份 ID flexible text controllability: 灵活可靠的控制能力，主要体现在文本参数 ","date":"2024-03-20","objectID":"/2024-03-20/photomaker/:1:3","tags":["paper","PhotoMaker","AIGC"],"title":"【论文泛读】PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding","uri":"/2024-03-20/photomaker/"},{"categories":["paper"],"content":"实现方法 PhotoMaker的算法流程与数据集准备 ","date":"2024-03-20","objectID":"/2024-03-20/photomaker/:2:0","tags":["paper","PhotoMaker","AIGC"],"title":"【论文泛读】PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding","uri":"/2024-03-20/photomaker/"},{"categories":["paper"],"content":"解决方案 训练时，对于输入图像和输出的目标图像不来源与同一个图像。 送入多个同一身份 ID 的图像，提取 embedding 以输出一个全面而统一的表达，称为 Stacked ID embedding。 Stacked ID embedding 中存取的每个 embedding 它们的图像来源可能姿态不同，表情不同以及配饰不同，但 ID 都是相同的，因此可以隐式的将 ID 与其他与 ID 无关的信息解耦，以使其只表征待输出的 ID 信息。 ","date":"2024-03-20","objectID":"/2024-03-20/photomaker/:2:1","tags":["paper","PhotoMaker","AIGC"],"title":"【论文泛读】PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding","uri":"/2024-03-20/photomaker/"},{"categories":["paper"],"content":"训练流程 PhotoMaker的训练流程 把同一 ID 的多个图像送入图像编码器进行编码，得到多个 Image Embedding； 对下方输入的文本进行 Encode 得到 Text Embedding，并且找出触发词，如图中输入的man。 使用 MLP 对 Text Embedding 和 Image Embedding 进行混合得到 Stacked ID Embedding，即 Text Embedding 与每个 Image Embedding 进行混合 将得到的 Stacked ID Embedding 与 Text Embedding 中对应位触发词位置的 Embedding 进行替换，进而得到更新后的 Text Embedding。 将更新后的 Text Embedding 放入 Diffusion Model 中，通过 Cross Attention 层进行融合。此外，还在每一个注意力层中添加了 LoRA 模块进行更新。 训练细节 训练时，并不训练 Diffusion Model 的原始参数，而是对每个 Cross 训练 LoRA，这样子既可以保留原始 Diffusion Model 的 Performance，也可以避免训练时大参数的时间消耗，并且 LoRA 可以有助于保存当前人脸身份。不仅微调的参数量变少了、消耗的资源更少了、速度变快了，还可以达到比 DreamBooth 更好的效果。 ","date":"2024-03-20","objectID":"/2024-03-20/photomaker/:2:2","tags":["paper","PhotoMaker","AIGC"],"title":"【论文泛读】PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding","uri":"/2024-03-20/photomaker/"},{"categories":["paper"],"content":"数据集 以ID为中心的数据组装流程 ","date":"2024-03-20","objectID":"/2024-03-20/photomaker/:2:3","tags":["paper","PhotoMaker","AIGC"],"title":"【论文泛读】PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding","uri":"/2024-03-20/photomaker/"},{"categories":["paper"],"content":"结果 ","date":"2024-03-20","objectID":"/2024-03-20/photomaker/:3:0","tags":["paper","PhotoMaker","AIGC"],"title":"【论文泛读】PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding","uri":"/2024-03-20/photomaker/"},{"categories":["paper"],"content":"Realistic Realistic generation ","date":"2024-03-20","objectID":"/2024-03-20/photomaker/:3:1","tags":["paper","PhotoMaker","AIGC"],"title":"【论文泛读】PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding","uri":"/2024-03-20/photomaker/"},{"categories":["paper"],"content":"Stylization Stylization generation ","date":"2024-03-20","objectID":"/2024-03-20/photomaker/:3:2","tags":["paper","PhotoMaker","AIGC"],"title":"【论文泛读】PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding","uri":"/2024-03-20/photomaker/"},{"categories":["paper"],"content":"参考 PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding 【腾讯 ARC Lab+南开程明明】PhotoMaker 论文讲解 程明明：PhotoMaker: 高效个性化定制人像照片文生图 ","date":"2024-03-20","objectID":"/2024-03-20/photomaker/:4:0","tags":["paper","PhotoMaker","AIGC"],"title":"【论文泛读】PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding","uri":"/2024-03-20/photomaker/"},{"categories":["ACM"],"content":"讲解树状数组的实现原理以及使用例子 ","date":"2024-03-19","objectID":"/2024-03-19/fenwick/:0:0","tags":["算法","树状数组","数据结构","ACM"],"title":"深入浅出理解树状数组","uri":"/2024-03-19/fenwick/"},{"categories":["ACM"],"content":"引入问题 给出一个长度为 $n$ 的数组，完成以下两种操作： 将第 $i$ 个数加上 $k$ 输出区间 $[i,j]$ 内每个数的和 ","date":"2024-03-19","objectID":"/2024-03-19/fenwick/:1:0","tags":["算法","树状数组","数据结构","ACM"],"title":"深入浅出理解树状数组","uri":"/2024-03-19/fenwick/"},{"categories":["ACM"],"content":"朴素算法 单点修改：$O(1)$ 区间查询：$O(n)$ ","date":"2024-03-19","objectID":"/2024-03-19/fenwick/:1:1","tags":["算法","树状数组","数据结构","ACM"],"title":"深入浅出理解树状数组","uri":"/2024-03-19/fenwick/"},{"categories":["ACM"],"content":"使用树状数组 单点修改：$O(\\log n)$ 区间查询：$O(\\log n)$ ","date":"2024-03-19","objectID":"/2024-03-19/fenwick/:1:2","tags":["算法","树状数组","数据结构","ACM"],"title":"深入浅出理解树状数组","uri":"/2024-03-19/fenwick/"},{"categories":["ACM"],"content":"前置知识 lowbit()运算：非负整数 $x$ 在二进制表示下最低位 $1$ 及其后面的 $0$ 构成的数值。 ","date":"2024-03-19","objectID":"/2024-03-19/fenwick/:2:0","tags":["算法","树状数组","数据结构","ACM"],"title":"深入浅出理解树状数组","uri":"/2024-03-19/fenwick/"},{"categories":["ACM"],"content":"举例说明： $lowbit(12)=lowbit([1100]_2)=[100]_2=4$ ","date":"2024-03-19","objectID":"/2024-03-19/fenwick/:2:1","tags":["算法","树状数组","数据结构","ACM"],"title":"深入浅出理解树状数组","uri":"/2024-03-19/fenwick/"},{"categories":["ACM"],"content":"函数实现： int lowbit(int x) { return x \u0026 -x; } ","date":"2024-03-19","objectID":"/2024-03-19/fenwick/:2:2","tags":["算法","树状数组","数据结构","ACM"],"title":"深入浅出理解树状数组","uri":"/2024-03-19/fenwick/"},{"categories":["ACM"],"content":"树状数组思想 树状数组的本质思想是使用树结构维护前缀和，从而把时间复杂度降为 $O(\\log n)$。 对于一个序列，对其建立如下树形结构： 每个结点 $tr[x]$ 保存以 $x$ 为根的子树中叶结点值的和； 每个结点覆盖的长度为 $lowbit(x)$； $tr[x]$ 结点的父结点为 $tr[x + lowbit(x)]$； 树的深度为 $\\log_2{n}+1$。 树状数组 ","date":"2024-03-19","objectID":"/2024-03-19/fenwick/:3:0","tags":["算法","树状数组","数据结构","ACM"],"title":"深入浅出理解树状数组","uri":"/2024-03-19/fenwick/"},{"categories":["ACM"],"content":"树状数组操作 ","date":"2024-03-19","objectID":"/2024-03-19/fenwick/:4:0","tags":["算法","树状数组","数据结构","ACM"],"title":"深入浅出理解树状数组","uri":"/2024-03-19/fenwick/"},{"categories":["ACM"],"content":"add(x, k)表示将序列中第 x 个数加上 k 以 add(3, 5) 为例： 在整棵树上维护这个值，需要一层一层向上找到父结点，并将这些结点上的 $tr[x]$ 值都加上 $k$，这样保证计算区间和时的结果正确。时间复杂度为 $O(\\log n)$。 add void add(int x, int k) { for (int i = x; i \u003c= n; i += lowbit(i)) tr[i] += k; } ","date":"2024-03-19","objectID":"/2024-03-19/fenwick/:4:1","tags":["算法","树状数组","数据结构","ACM"],"title":"深入浅出理解树状数组","uri":"/2024-03-19/fenwick/"},{"categories":["ACM"],"content":"sum(x) 表示将查询序列前 x 个数的和 以 sum(7) 为例： 查询这个点的前缀和，需要从这个点向左上找到上一个结点，将加上其结点的值。向左上找到上一个结点，只需要将下标 $x -= lowbit(x)$，例如 $7 - lowbit(7) = 6$。 sum int sum(int x) { int res = 0; for (int i = x; i; i -= lowbit(i)) res += tr[i]; return res; } ","date":"2024-03-19","objectID":"/2024-03-19/fenwick/:4:2","tags":["算法","树状数组","数据结构","ACM"],"title":"深入浅出理解树状数组","uri":"/2024-03-19/fenwick/"},{"categories":["ACM"],"content":"树状数组核心代码 树状数组三大核心操作： lowbit(x) 求非负整数 $x$ 在二进制表示下最低位 $1$ add(x, k) 在第 x 个位置上加上 k sum(x) 求第 1~x 个元素的和 在 c/c++ 中，为了解决一些频繁调用的小函数大量消耗栈空间（栈内存）的问题，特别的引入了 inline 修饰符，表示为内联函数。 inline int lowbit(int x) { return x \u0026 (-x); } inline void add(int x, int k) { for (int i = x; i \u003c= n; i += lowbit(i)) tr[i] += k; } inline int sum(int x) { int res = 0; for (int i = x; i; i -= lowbit(i)) res += tr[i]; return res; } ","date":"2024-03-19","objectID":"/2024-03-19/fenwick/:5:0","tags":["算法","树状数组","数据结构","ACM"],"title":"深入浅出理解树状数组","uri":"/2024-03-19/fenwick/"},{"categories":["ACM"],"content":"区间修改，单点查询 给区间里的所有数加上 $k$ 查询某个下标的数的值 ","date":"2024-03-19","objectID":"/2024-03-19/fenwick/:6:0","tags":["算法","树状数组","数据结构","ACM"],"title":"深入浅出理解树状数组","uri":"/2024-03-19/fenwick/"},{"categories":["ACM"],"content":"差分 先来介绍一下差分 设数组 $a={1,6,8,5,10}$，那么差分数组 $b={1,5,2,-3,5}$ 也就是说 $b[i]=a[i]-a[i-1](a[0]=0)$，那么 $a[i]=b[1]+….+b[i]$ 假如区间 $[2,4]$ 都加上 $2$ 的话 $a$ 数组变为 $a={1,8,10,7,10}$，$b$ 数组变为 $b={1,7,2,-3,3}$ 其中，$b$ 数组只有 $b[2]$ 和 $b[5]$ 变了，因为区间 $[2,4]$ 是同时加上 2 的,所以在区间内 $a[i]-a[i-1]$ 是不变的. 所以对区间 $[x,y]$ 进行修改,只用修改 $b[x]$ 与 $b[y+1]$: $b[x]=b[x]+k$ $b[y+1]=b[y+1]-k$ 因此，本题可以用树状数组维护一个差分序列。 ","date":"2024-03-19","objectID":"/2024-03-19/fenwick/:6:1","tags":["算法","树状数组","数据结构","ACM"],"title":"深入浅出理解树状数组","uri":"/2024-03-19/fenwick/"},{"categories":["ACM"],"content":"代码 #include \u003cbits/stdc++.h\u003e const int N = 500010; int n, m; int a[N], tr[N]; inline int lowbit(int x) { return x \u0026 -x; } inline void add(int x, int k) { for (int i = x; i \u003c= n; i += lowbit(i)) tr[i] += k; } inline int sum(int x) { int res = 0; for (int i = x; i; i -= lowbit(i)) res += tr[i]; return res; } int main() { std::ios::sync_with_stdio(0); std::cin.tie(0); std::cin \u003e\u003e n \u003e\u003e m; for (int i = 1; i \u003c= n; i++) { std::cin \u003e\u003e a[i]; add(i, a[i] - a[i - 1]); } int op, x, y, k; while (m--) { std::cin \u003e\u003e op; if (op == 1) { std::cin \u003e\u003e x \u003e\u003e y \u003e\u003e k; add(x, k); add(y + 1, -k); } else { std::cin \u003e\u003e x; std::cout \u003c\u003c sum(x) \u003c\u003c '\\n'; } } return 0; } ","date":"2024-03-19","objectID":"/2024-03-19/fenwick/:6:2","tags":["算法","树状数组","数据结构","ACM"],"title":"深入浅出理解树状数组","uri":"/2024-03-19/fenwick/"},{"categories":["ACM"],"content":"逆序对 原题链接 逆序对定义：对于给定的一段正整数序列，逆序对就是序列中 $a_i\u003ea_j$ 且 $i\u003cj$ 的有序对。 ","date":"2024-03-19","objectID":"/2024-03-19/fenwick/:7:0","tags":["算法","树状数组","数据结构","ACM"],"title":"深入浅出理解树状数组","uri":"/2024-03-19/fenwick/"},{"categories":["ACM"],"content":"离散化(Discretization) 在以前介绍的树状数组中，只需要开一个与原序列中最大元素相等的长度数组就行，那么如果我的序列是 1，5，3，8，999，本来 5 个元素，却需要开到 999 这么大，造成了巨大的空间浪费， 离散化就是另开一个数组$d$，$d[i]$用来存放第 $i$ 小的数在原序列的什么位置，比如原序列 $a={999,333,444,21,1}$，第一小就是 1，他在 $a$ 中的位是 5，所以 $d[1]=5$，同理 $d[2]=3$，…，所以 $d$ 数组为 $d={5,3,4,2,1}$， 具体实现： for (int i = 1; i \u003c= n; i++) { std::cin \u003e\u003e a[i]; v.push_back(a[i]); } std::sort(v.begin(), v.end()); v.erase(unique(v.begin(), v.end()), v.end()); for (int i = 1; i \u003c= n; i++) a[i] = std::upper_bound(v.begin(), v.end(), a[i]) - v.begin(); ","date":"2024-03-19","objectID":"/2024-03-19/fenwick/:7:1","tags":["算法","树状数组","数据结构","ACM"],"title":"深入浅出理解树状数组","uri":"/2024-03-19/fenwick/"},{"categories":["ACM"],"content":"树状数组求和 根据上面的步骤每一次把一个新的数 x 放进去之后，都要求比他大的元素有几个，而比他大的元素个数一定是 $x+1$ 到 $n$ 中存在数的个数，也就是 $[x+1,n]$ 中有几个数，是不是很耳熟，有点像之前讲的前缀和了，只不过树状数组 $tr$ 表是的不是前缀和了，$tr[x]$ 表示的是 $[1,x]$ 中有几个数已经存在，这样我们每次把一个新的数 $x$ 放进去的时候，都需要把包含这个数的结点更新，然后查询 $[x+1,n]$ 有几个数已经存在。 即 $ans=sum(n)-sum(x)$ 具体实现： i64 res = 0; for (int i = 1; i \u003c= n; i++) { res += sum(n) - sum(a[i]); add(a[i], 1); } ","date":"2024-03-19","objectID":"/2024-03-19/fenwick/:7:2","tags":["算法","树状数组","数据结构","ACM"],"title":"深入浅出理解树状数组","uri":"/2024-03-19/fenwick/"},{"categories":["ACM"],"content":"代码 #include \u003cbits/stdc++.h\u003e using i64 = long long; const int N = 500010; int n; int w[N], tr[N]; std::vector\u003cint\u003e v; inline int lowbit(int x) { return x \u0026 -x; } inline void add(int x, int k) { for (int i = x; i \u003c= n; i += lowbit(i)) tr[i] += k; } inline int sum(int x) { int res = 0; for (int i = x; i; i -= lowbit(i)) res += tr[i]; return res; } int main() { std::ios::sync_with_stdio(0); std::cin.tie(0); std::cin \u003e\u003e n; for (int i = 1; i \u003c= n; i++) { std::cin \u003e\u003e w[i]; v.push_back(w[i]); } std::sort(v.begin(), v.end()); v.erase(unique(v.begin(), v.end()), v.end()); for (int i = 1; i \u003c= n; i++) w[i] = std::upper_bound(v.begin(), v.end(), w[i]) - v.begin(); i64 res = 0; for (int i = 1; i \u003c= n; i++) { res += sum(n) - sum(w[i]); add(w[i], 1); } std::cout \u003c\u003c res \u003c\u003c '\\n'; return 0; } ","date":"2024-03-19","objectID":"/2024-03-19/fenwick/:7:3","tags":["算法","树状数组","数据结构","ACM"],"title":"深入浅出理解树状数组","uri":"/2024-03-19/fenwick/"},{"categories":["摄影"],"content":"记录使用 iPhone 15 Pro Max 拍下的瞬间 ","date":"2024-03-18","objectID":"/2024-03-18/2024-01/:0:0","tags":["摄影","blog","生活"],"title":"个人摄影记录归档：2024.01 ~ 2024.03","uri":"/2024-03-18/2024-01/"},{"categories":["golang"],"content":"探究在 defer 中修改返回值，对结果是否产生变化 ","date":"2024-03-18","objectID":"/2024-03-18/defer-return/:0:0","tags":["golang","defer","interview"],"title":"Golang中使用defer语句修改返回值会发生什么？","uri":"/2024-03-18/defer-return/"},{"categories":["golang"],"content":"无名返回值 // Result: 1 func test01() int { ret := 1 defer func() { ret++ }() return ret } // Result: 1 func test02() int { ret := 1 defer func(ret int) { ret++ }(ret) return ret } 其中ret在函数内定义，是一个局部变量，此时执行return ret时，函数的返回值就等于了ret = 1，因此后续在defer语句中，无论如何修改ret的值，返回值不变。 ","date":"2024-03-18","objectID":"/2024-03-18/defer-return/:1:0","tags":["golang","defer","interview"],"title":"Golang中使用defer语句修改返回值会发生什么？","uri":"/2024-03-18/defer-return/"},{"categories":["golang"],"content":"有名返回值 // Result: 2 func test03() (ret int) { ret = 1 defer func() { ret++ }() return ret } 其中 ret 在函数签名时就已经定义，因此返回值就是 ret，后续对 ret 的修改，就是对返回值的修改。 // Result: 1 func test04() (ret int) { ret = 1 defer func(ret int) { ret++ }(ret) return } 需要注意的是，在 defer 中传入 ret 参数时，此时 defer 中的 ret 为形参，指向的是一个新的内存地址，因此不会对返回值进行影响。 ","date":"2024-03-18","objectID":"/2024-03-18/defer-return/:2:0","tags":["golang","defer","interview"],"title":"Golang中使用defer语句修改返回值会发生什么？","uri":"/2024-03-18/defer-return/"},{"categories":["golang"],"content":"返回值为指针 // Result: 10 func test05() *int { var ret int defer func() { ret = 10 }() return \u0026ret } // Result: 0 func test06() *int { var ret int defer func(ret int) { ret = 10 }(ret) return \u0026ret } // Result: 10 func test07() *int { var ret int defer func(ret *int) { *ret = 10 }(\u0026ret) return \u0026ret } 此时函数的返回值为指向ret的指针，后续对ret进行内容上的修改，指针指向ret的内容，因此返回值会因为defer的操作而改变。 同时需要注意，在defer里如果没有传入指针，而是ret的形参时，由于拷贝赋值，修改的不是ret所指向的内存空间，因此返回值不变。 ","date":"2024-03-18","objectID":"/2024-03-18/defer-return/:3:0","tags":["golang","defer","interview"],"title":"Golang中使用defer语句修改返回值会发生什么？","uri":"/2024-03-18/defer-return/"},{"categories":["golang"],"content":"总结 defer 对返回值修改的情况： 无名返回值：不会修改返回值； 有名返回值：如果在 defer 里修改返回值，并且以闭包的形式修改，那么返回值会被修改； 返回值为指针：如果修改返回值指向的内存空间，那么 defer 会修改返回值。 ","date":"2024-03-18","objectID":"/2024-03-18/defer-return/:4:0","tags":["golang","defer","interview"],"title":"Golang中使用defer语句修改返回值会发生什么？","uri":"/2024-03-18/defer-return/"},{"categories":["golang"],"content":"代码 package defer_test import ( \"testing\" ) func test01() int { ret := 1 defer func() { ret++ }() return ret } func test02() int { ret := 1 defer func(ret int) { ret++ }(ret) return ret } func test03() (ret int) { ret = 1 defer func() { ret++ }() return ret } func test04() (ret int) { ret = 1 defer func(ret int) { ret++ }(ret) return } func test05() *int { var ret int defer func() { ret = 10 }() return \u0026ret } func test06() *int { var ret int defer func(ret int) { ret = 10 }(ret) return \u0026ret } func test07() *int { var ret int defer func(ret *int) { *ret = 10 }(\u0026ret) return \u0026ret } func TestDefer(t *testing.T) { t.Logf(\"test01: %d\", test01()) t.Logf(\"test02: %d\", test02()) t.Logf(\"test03: %d\", test03()) t.Logf(\"test04: %d\", test04()) t.Logf(\"test05: %d\", *test05()) t.Logf(\"test06: %d\", *test06()) t.Logf(\"test07: %d\", *test07()) } ","date":"2024-03-18","objectID":"/2024-03-18/defer-return/:4:1","tags":["golang","defer","interview"],"title":"Golang中使用defer语句修改返回值会发生什么？","uri":"/2024-03-18/defer-return/"},{"categories":["golang"],"content":"执行结果 === RUN TestDefer defer_test.go:64: test01: 1 defer_test.go:65: test02: 1 defer_test.go:66: test03: 2 defer_test.go:67: test04: 1 defer_test.go:68: test05: 10 defer_test.go:69: test06: 0 defer_test.go:70: test07: 10 --- PASS: TestDefer (0.00s) PASS ","date":"2024-03-18","objectID":"/2024-03-18/defer-return/:4:2","tags":["golang","defer","interview"],"title":"Golang中使用defer语句修改返回值会发生什么？","uri":"/2024-03-18/defer-return/"},{"categories":["blog"],"content":"记录与本科室友李想在杭州灵隐寺、法喜寺的一日游记 信息 拍摄设备：iPhone 15 Pro Max 部分消费：飞来峰门票 45r、灵隐寺香火钱 15r、法喜寺香火钱 10r；共计 70r ","date":"2024-03-12","objectID":"/2024-03-12/20240312/:0:0","tags":["blog","生活","随笔"],"title":"随笔：灵隐寺、法喜寺一日游记","uri":"/2024-03-12/20240312/"},{"categories":["blog"],"content":"契机 我的本科毕业论文开题答辩定于 2024-03-12 13:30:00(UTC+8)，刚好因为与工程实习缓答辩在同一天，由于缓答人数过多，开题答辩很快就结束了。 时间结束的尚早，最近刚好在祈求好运，因此和李想约了此次的寺庙祈福之旅。 当日微信步数： 警告 前方多图预警 ","date":"2024-03-12","objectID":"/2024-03-12/20240312/:1:0","tags":["blog","生活","随笔"],"title":"随笔：灵隐寺、法喜寺一日游记","uri":"/2024-03-12/20240312/"},{"categories":["blog"],"content":"灵隐寺 从屏峰站坐上杭港地铁三号线后，没过多久，便到了地铁路线的“终点站”——黄龙体育中心站。 由于之前去过灵隐寺的经验，我们明智的选择了骑小黄去解决这最后的几公里，谁知……这一路上基本上都是上坡，大腿表示乳酸堆积的很厉害 T^T 很快便到了飞来峰景区的门口，其实很想不明白去灵隐寺为什么要买两次票…… 飞来峰景区口——江明摄 在景区内逛了逛，担心太晚灵隐寺关门，便去匆匆买了票。有意思的是购买学生票的时候，没带学生证，就用学信网的信息做证明，买票阿姨用麦克风大声的说了——“科技大学”四个大字，这个快乐谁都啊哈哈哈 灵隐寺大雄宝殿前祈福的众生——江明摄 在天王殿里拍到的落日与古建筑的交相辉映，金碧辉煌，庄严肃穆。 天王殿内的落日一角——江明摄 据说殿内那手持金刚杵的韦陀菩萨像是南宋遗物，距今已有 700 年的历史。 天王殿内手持金刚杵的韦陀菩萨佛像——江明摄 后面就在灵隐寺的每个殿里都拜了拜，包括药师殿、华严殿以及五百罗汉殿。 灵隐寺大雄宝殿背面观世音菩萨像及诸位童子——李想摄 灵隐寺与游人——江明摄 灵隐寺一角——江明摄 ","date":"2024-03-12","objectID":"/2024-03-12/20240312/:2:0","tags":["blog","生活","随笔"],"title":"随笔：灵隐寺、法喜寺一日游记","uri":"/2024-03-12/20240312/"},{"categories":["blog"],"content":"法喜寺 从灵隐寺出来，时间尚早，本着“来都来了”的中国人处事原则，我们决定徒步前往上天竺法喜寺，中间有很多黑车司机想赚我们一笔，可惜我们都是铁公鸡，宁愿走路前往，也不愿接受他们的“助人为乐”。 走了半个小时，多亏了路上玉米的补充，并不是很累，赶在六点关门前，进入了传说中的法喜寺。 法喜寺吃猫粮的猫🐱——江明摄 法喜寺一角——江明摄 法喜寺经典机位——江明摄 ","date":"2024-03-12","objectID":"/2024-03-12/20240312/:3:0","tags":["blog","生活","随笔"],"title":"随笔：灵隐寺、法喜寺一日游记","uri":"/2024-03-12/20240312/"},{"categories":["blog"],"content":"In The End 有点小累，希望祈福可以带来好结果啦！拜托，拜托 🙏 潘江明 二〇二四年三月十三日 凌晨 记于 浙江科技大学 ","date":"2024-03-12","objectID":"/2024-03-12/20240312/:4:0","tags":["blog","生活","随笔"],"title":"随笔：灵隐寺、法喜寺一日游记","uri":"/2024-03-12/20240312/"},{"categories":["interview"],"content":"总结一些常考的 MySQL 面试题，相关资料皆从网络上收集 ","date":"2024-03-11","objectID":"/2024-03-11/mysql/:0:0","tags":["interview","mysql"],"title":"面试题精选--MySQL篇","uri":"/2024-03-11/mysql/"},{"categories":["interview"],"content":"事物 ","date":"2024-03-11","objectID":"/2024-03-11/mysql/:1:0","tags":["interview","mysql"],"title":"面试题精选--MySQL篇","uri":"/2024-03-11/mysql/"},{"categories":["interview"],"content":"事物的四大特性 事物的四大特性：原子性、一致性、隔离性、持久性，简称 ACID 原子性：事物是最小的执行单位，不允许分割。要么全都执行，要么全都不执行 一致性：执⾏事务前后，数据保持⼀致，多个事务对同⼀个数据读取的结果是相同的 隔离性：并发访问数据库时，一个用户的事物不被其他事物所干扰，各并发事物之间数据库是独立的 持久性：一个事物被提交后，对于数据库的改变是持久的，即使数据库发生故障也不应该对其有任何影响 实现保证：MySQL 的存储引擎 InnoDB 使用重做日志保证一致性与持久性，回滚日志保证原子性，使用各种锁来保证隔离性。 ","date":"2024-03-11","objectID":"/2024-03-11/mysql/:1:1","tags":["interview","mysql"],"title":"面试题精选--MySQL篇","uri":"/2024-03-11/mysql/"},{"categories":["interview"],"content":"事物的隔离级别 读未提交：最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。 读已提交：允许读取并发事务已经提交的数据，可以阻⽌脏读，但是幻读或不可重复读仍有可能发⽣。 可重复读：同⼀字段的多次读取结果都是⼀致的，除⾮数据是被本身事务⾃⼰所修改，可以阻⽌脏读和不可重复读，会有幻读。 串行化：最⾼的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执⾏，这样事务之间就完全不可能产⽣⼲扰。 隔离级别 并发问题 读未提交 可能导致脏读、幻读或不可重复读 读已提交 可能导致幻读或不可重复读 可重复读 可能导致幻读 串行化 不会产生干扰 ","date":"2024-03-11","objectID":"/2024-03-11/mysql/:1:2","tags":["interview","mysql"],"title":"面试题精选--MySQL篇","uri":"/2024-03-11/mysql/"},{"categories":["interview"],"content":"什么是脏读、不可重复读和幻读 脏读 脏读（Dirty Read）是指一个事务读取了另一个未提交的事务所写入的数据。 假设有两个事务 T1 和 T2，T1 在读取某个数据之后，T2 修改了该数据但尚未提交，如果 T1 再次读取该数据，就会读取到 T2 修改后的“脏数据”，因为 T2 的修改最终可能被回滚，导致读取到的数据不正确。 不可重复读 不可重复读（Non-repeatable Read）是指一个事务在相同的查询条件下多次读取同一行数据时，得到的结果不一致。 假设事务 T1 执行了一次查询并读取了某行数据，然后事务 T2 修改了该行数据并提交，如果 T1 再次执行相同的查询，得到的结果就可能与之前不同。 幻读 幻读（Phantom Read）是指一个事务在相同的查询条件下多次执行查询，得到的结果集不一致。 假设事务 T1 执行了一次查询并返回了一些行数据，然后事务 T2 在这些行数据中插入了新的数据并提交，如果 T1 再次执行相同的查询，得到的结果集就可能与之前不同。 ","date":"2024-03-11","objectID":"/2024-03-11/mysql/:1:3","tags":["interview","mysql"],"title":"面试题精选--MySQL篇","uri":"/2024-03-11/mysql/"},{"categories":["interview"],"content":"默认隔离级别-RR MySQL 默认的隔离级别为可重复读，即：同⼀字段的多次读取结果都是⼀致的，除⾮数据是被本身事务⾃⼰所修改； 可重复读是有可能出现幻读的，如果要保证绝对的安全只能把隔离级别设置成 SERIALIZABLE；这样所有事务都只能顺序执行，自然不会因为并发有什么影响了，但是性能会下降许多。 第二种方式，针对快照读（普通 select 语句），是通过 MVCC 方式解决了幻读，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。 select id from table_xx where id = ? and version = Vupdate; select id from table_xx where id = ? and version = V + 1; 第三种方式，针对当前读（select ... for update 等语句），是通过 next-key lock（记录锁+间隙锁）方式解决了幻读，因为当执行 select ... for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。 select id from table_xx where id \u003e 100 for update; select id from table_xx where id \u003e 100 lock in share mode; ","date":"2024-03-11","objectID":"/2024-03-11/mysql/:1:4","tags":["interview","mysql"],"title":"面试题精选--MySQL篇","uri":"/2024-03-11/mysql/"},{"categories":["interview"],"content":"RR 和 RC 使用场景 事务隔离级别 RC(read commit)和 RR（repeatable read）两种事务隔离级别基于多版本并发控制 MVCC(multi-version concurrency control）来实现。 「读提交」隔离级别是在每个 select 都会生成一个新的 Read View，也意味着，事务期间的多次读取同一条数据，前后两次读的数据可能会出现不一致，因为可能这期间另外一个事务修改了该记录，并提交了事务。 「可重复读」隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View，这样就保证了在事务期间读到的数据都是事务启动前的记录。 RC RR 实现 多个 select 会创建多个不同的 Read View 仅需要一个版本的 Read View 粒度 语句级读一致性 事物级读一致性 准确性 每次语句执行时间点的数据 第一条语句执行时间点的数据 ","date":"2024-03-11","objectID":"/2024-03-11/mysql/:1:5","tags":["interview","mysql"],"title":"面试题精选--MySQL篇","uri":"/2024-03-11/mysql/"},{"categories":["interview"],"content":"行锁，表锁，意向锁 InnoDB ⽀持⾏级锁(row-level locking)和表级锁，默认为⾏级锁 InnoDB 按照不同的分类的锁： 共享/排它锁(Shared and Exclusive Locks)：行级别锁， 意向锁(Intention Locks)，表级别锁 间隙锁(Gap Locks)，锁定一个区间 记录锁(Record Locks)，锁定一个行记录 表级锁：（串行化） Mysql 中锁定粒度最大的一种锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM 和 InnoDB 引擎都支持表级锁。 行级锁：（RR、RC） Mysql 中锁定粒度最小的一种锁，只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。InnoDB 支持的行级锁，包括如下几种： 记录锁（Record Lock）: 对索引项加锁，锁定符合条件的行。其他事务不能修改和删除加锁项； 间隙锁（Gap Lock）: 对索引项之间的“间隙”加锁，锁定记录的范围，不包含索引项本身，其他事务不能在锁范围内插入数据。 Next-key Lock： 锁定索引项本身和索引范围。即 Record Lock 和 Gap Lock 的结合。可解决幻读问题。 InnoDB 支持多粒度锁（multiple granularity locking），它允许行级锁与表级锁共存，而意向锁就是其中的一种表锁。 共享锁（ shared lock, S ）锁允许持有锁读取行的事务。加锁时将自己和子节点全加 S 锁，父节点直到表头全加 IS 锁 排他锁（ exclusive lock， X ）锁允许持有锁修改行的事务。 加锁时将自己和子节点全加 X 锁，父节点直到表头全加 IX 锁 意向共享锁（intention shared lock, IS）：事务有意向对表中的某些行加共享锁（S 锁） 意向排他锁（intention exclusive lock, IX）：事务有意向对表中的某些行加排他锁（X 锁） 互斥性 共享锁（S） 排他锁（X） 意向共享锁（IS） 意向排他锁（IX） 共享锁 ✅ ❌ ✅ ❌ 排他锁 ❌ ❌ ❌ ❌ 意向共享锁 ✅ ❌ ✅ ✅ 意向排他锁 ❌ ❌ ✅ ✅ ","date":"2024-03-11","objectID":"/2024-03-11/mysql/:1:6","tags":["interview","mysql"],"title":"面试题精选--MySQL篇","uri":"/2024-03-11/mysql/"},{"categories":["interview"],"content":"MVCC 多版本并发控制 MVCC 是一种多版本并发控制机制，通过事务的可见性看到自己预期的数据，能降低其系统开销。（RC 和 RR 级别工作） InnoDB 的 MVCC,是通过在每行记录后面保存系统版本号(可以理解为事务的 ID)，每开始一个新的事务，系统版本号就会自动递增，事务开始时刻的系统版本号会作为事务的 ID。这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的，防止幻读的产生。 MVCC 手段只适用于 Msyql 隔离级别中的读已提交（Read committed）和可重复读（Repeatable Read）. Read uncimmitted 由于存在脏读，即能读到未提交事务的数据行，所以不适用 MVCC. 简单的 select 快照度不会加锁，删改及 select for update 等需要当前读的场景会加锁 原因是 MVCC 的创建版本和删除版本只要在事务提交后才会产生。客观上，mysql 使用的是乐观锁的一整实现方式，就是每行都有版本号，保存时根据版本号决定是否成功。Innodb 的 MVCC 使用到的快照存储在 Undo 日志中，该日志通过回滚指针把一个数据行所有快照连接起来。 在 InnoDB 引擎表中，它的聚簇索引记录中有两个必要的隐藏列： trx_id：这个 id 用来存储的每次对某条聚簇索引记录进行修改的时候的事务 id。 roll_pointer：每次对哪条聚簇索引记录有修改的时候，都会把老版本写入 undo 日志中。这个 roll_pointer 就是存了一个指针，它指向这条聚簇索引记录的上一个版本的位置，通过它来获得上一个版本的记录信息。(注意插入操作的 undo 日志没有这个属性，因为它没有老版本) Read View： Read View 有四个重要的字段： m_ids ：指的是在创建 Read View 时，当前数据库中「活跃事务」的事务 id 列表，注意是一个列表，“活跃事务”指的就是，启动了但还没提交的事务。 min_trx_id ：指的是在创建 Read View 时，当前数据库中「活跃事务」中事务 id 最小的事务，也就是 m_ids 的最小值。 max_trx_id ：这个并不是 m_ids 的最大值，而是创建 Read View 时当前数据库中应该给下一个事务的 id 值，也就是全局事务中最大的事务 id 值 + 1； creator_trx_id ：指的是创建该 Read View 的事务的事务 id。 每次修改都会在版本链中记录。SELECT 可以去版本链中拿记录，这就实现了读-写，写-读的并发执行，提升了系统的性能。 trx_id： 一个事务去访问记录的时候，除了自己的更新记录总是可见之外，还有这几种情况： 如果记录的 trx_id 值小于 Read View 中的 min_trx_id 值，表示这个版本的记录是在创建 Read View 前已经提交的事务生成的，所以该版本的记录对当前事务可见。 如果记录的 trx_id 值大于等于 Read View 中的 max_trx_id 值，表示这个版本的记录是在创建 Read View 后才启动的事务生成的，所以该版本的记录对当前事务不可见。 如果记录的 trx_id 值在 Read View 的 min_trx_id 和 max_trx_id 之间，需要判断 trx_id 是否在 m_ids 列表中： 如果记录的 trx_id 在 m_ids 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务不可见。 如果记录的 trx_id 不在 m_ids 列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务可见。 ","date":"2024-03-11","objectID":"/2024-03-11/mysql/:1:7","tags":["interview","mysql"],"title":"面试题精选--MySQL篇","uri":"/2024-03-11/mysql/"},{"categories":["interview"],"content":"索引 ","date":"2024-03-11","objectID":"/2024-03-11/mysql/:2:0","tags":["interview","mysql"],"title":"面试题精选--MySQL篇","uri":"/2024-03-11/mysql/"},{"categories":["interview"],"content":"Innodb 和 Myisam 引擎 Myisam：支持表锁，适合读密集的场景，不支持外键，不支持事务，索引与数据在不同的文件 Innodb：支持行、表锁，默认为行锁，适合并发场景，支持外键，支持事务，索引与数据同一文件 ","date":"2024-03-11","objectID":"/2024-03-11/mysql/:2:1","tags":["interview","mysql"],"title":"面试题精选--MySQL篇","uri":"/2024-03-11/mysql/"},{"categories":["interview"],"content":"哈希索引 哈希索引用索引列的值计算该值的 hashCode，然后在 hashCode 相应的位置存执该值所在行数据的物理位置，因为使用散列算法，因此访问速度非常快，但是一个值只能对应一个 hashCode，而且是散列的分布方式，因此哈希索引不支持范围查找和排序的功能。 ","date":"2024-03-11","objectID":"/2024-03-11/mysql/:2:2","tags":["interview","mysql"],"title":"面试题精选--MySQL篇","uri":"/2024-03-11/mysql/"},{"categories":["interview"],"content":"B+树索引 优点： B+树的磁盘读写代价低，更少的查询次数，查询效率更加稳定，有利于对数据库的扫描 B+树是 B 树的升级版，B+树只有叶节点存放数据，其余节点用来索引。索引节点可以全部加入内存，增加查询效率，叶子节点可以做双向链表，从而提高范围查找的效率，增加的索引的范围。 在大规模数据存储的时候，红黑树往往出现由于树的深度过大而造成磁盘 I/O 读写过于频繁，进而导致效率低下的情况。所以，只要我们通过某种较好的树结构减少树的结构尽量减少树的高度，B 树与 B+树可以有多个子女，从几十到上千，可以降低树的高度。 磁盘预读原理：将一个节点的大小设为等于一个页，这样每个节点只需要一次 I/O 就可以完全载入。为了达到这个目的，在实际实现 B-Tree 还需要使用如下技巧：每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个 node 只需一次 I/O。 ","date":"2024-03-11","objectID":"/2024-03-11/mysql/:2:3","tags":["interview","mysql"],"title":"面试题精选--MySQL篇","uri":"/2024-03-11/mysql/"},{"categories":["interview"],"content":"创建索引 CREATE [UNIQUE | FULLTEXT] INDEX 索引名 ON 表名(字段名) [USING 索引方法]; 说明： UNIQUE：可选。表示索引为唯一性索引。 FULLTEXT：可选。表示索引为全文索引。 INDEX 和 KEY：用于指定字段为索引，两者选择其中之一就可以了，作用是一样的。 索引名：可选。给创建的索引取一个新名称。 字段名：指定索引对应的字段的名称，该字段必须是前面定义好的字段。 索引方法：默认使用 B+TREE。 ","date":"2024-03-11","objectID":"/2024-03-11/mysql/:2:4","tags":["interview","mysql"],"title":"面试题精选--MySQL篇","uri":"/2024-03-11/mysql/"},{"categories":["interview"],"content":"聚簇索引和非聚簇索引 聚簇索引：将数据存储与索引放到了一块，索引结构的叶子节点保存了行数据（主键索引） 非聚簇索引：将数据与索引分开存储，索引结构的叶子节点指向了数据对应的位置（辅助索引） 聚簇索引的叶子节点就是数据节点，而非聚簇索引的叶子节点仍然是索引节点，只不过有指向对应数据块的指针。 ","date":"2024-03-11","objectID":"/2024-03-11/mysql/:2:5","tags":["interview","mysql"],"title":"面试题精选--MySQL篇","uri":"/2024-03-11/mysql/"},{"categories":["interview"],"content":"最左前缀问题 最左前缀原则主要使用在联合索引中，联合索引的 B+Tree 是按照第一个关键字进行索引排列的。 联合索引的底层是一颗 B+树，只不过联合索引的 B+树节点中存储的是键值。由于构建一棵 B+树只能根据一个值来确定索引关系，所以数据库依赖联合索引最左的字段来构建。 采用\u003e、\u003c等进行匹配都会导致后面的列无法走索引，因为通过以上方式匹配到的数据是不可知的。 ","date":"2024-03-11","objectID":"/2024-03-11/mysql/:2:6","tags":["interview","mysql"],"title":"面试题精选--MySQL篇","uri":"/2024-03-11/mysql/"},{"categories":["interview"],"content":"SQL 查询 ","date":"2024-03-11","objectID":"/2024-03-11/mysql/:3:0","tags":["interview","mysql"],"title":"面试题精选--MySQL篇","uri":"/2024-03-11/mysql/"},{"categories":["interview"],"content":"SQL 语句执行过程 查询语句： select * from student A where A.age='18' and A.name='张三'; 结合上面的说明，我们分析下这个语句的执行流程： 通过客户端/服务器通信协议与 MySQL 建立连接。并查询是否有权限 Mysql8.0 之前开看是否开启缓存，开启了 Query Cache 且命中完全相同的 SQL 语句，则将查询结果直接返回给客户端； 由解析器进行语法语义解析，并生成解析树。如查询是 select、表名 tb_student、条件是 id=‘1’ 查询优化器生成执行计划。根据索引看看是否可以优化 查询执行引擎执行 SQL 语句，根据存储引擎类型，得到查询结果。若开启了 Query Cache，则缓存，否则直接返回。 ","date":"2024-03-11","objectID":"/2024-03-11/mysql/:3:1","tags":["interview","mysql"],"title":"面试题精选--MySQL篇","uri":"/2024-03-11/mysql/"},{"categories":["interview"],"content":"回表查询和覆盖索引 普通索引（唯一索引+联合索引+全文索引）需要扫描两遍索引树 先通过普通索引定位到主键值 id=5； 在通过聚集索引定位到行记录； 这就是所谓的回表查询，先定位主键值，再定位行记录，它的性能较扫一遍索引树更低。 覆盖索引：主键索引==聚簇索引==覆盖索引 如果 where 条件的列和返回的数据在一个索引中，那么不需要回查表，那么就叫覆盖索引。 实现覆盖索引：常见的方法是，将被查询的字段，建立到联合索引里去。 ","date":"2024-03-11","objectID":"/2024-03-11/mysql/:3:2","tags":["interview","mysql"],"title":"面试题精选--MySQL篇","uri":"/2024-03-11/mysql/"},{"categories":["interview"],"content":"Explain 及优化 Explain 结果每个字段的含义说明 索引优化： 最左前缀索引：like 只用于'string%'，语句中的=和 in 会动态调整顺序 唯一索引：唯一键区分度在 0.1 以上 无法使用索引：!=、is null、 or、\u003e\u003c、（5.7 以后根据数量自动判定）in、not in 联合索引：避免 select * ，查询列使用覆盖索引 # 创建联合覆盖索引，避免回表查询 ALTER TABLE user add index idx_gid_ctime_uid (gid, ctime, uid); SELECT uid From user Where gid = 2 order by ctime asc limit 10; 语句优化： char 固定长度查询效率高，varchar 第一个字节记录数据长度 应该针对 Explain 中 Rows 增加索引 group/order by 字段均会涉及索引 Limit 中分页查询会随着 start 值增大而变缓慢，通过子查询+表连接解决 select * from mytbl order by id limit 100000,10; # 改进后的 SQL 语句如下： select * from mytbl where id \u003e= (select id from mytbl order by id limit 100000,1) limit 10; select * from mytbl inner ori join (select id from mytbl order by id limit 100000,10) as tmp on tmp.id=ori.id; count 会进行全表扫描，如果估算可以使用 explain delete 删除表时会增加大量 undo 和 redo 日志， 确定删除可使用 trancate 表结构优化： 单库不超过 200 张表 单表不超过 500w 数据 单表不超过 40 列 单表索引不超过 5 个 数据库范式 ： 第一范式（1NF）列不可分割 第二范式（2NF）属性完全依赖于主键 [ 消除部分子函数依赖 ] 第三范式（3NF）属性不依赖于其它非主属性 [ 消除传递依赖 ] 配置优化： 配置连接数、禁用 Swap、增加内存、升级 SSD 硬盘 ","date":"2024-03-11","objectID":"/2024-03-11/mysql/:3:3","tags":["interview","mysql"],"title":"面试题精选--MySQL篇","uri":"/2024-03-11/mysql/"},{"categories":["interview"],"content":"JOIN 查询 left join(左联接) 返回包括左表中的所有记录和右表中关联字段相等的记录 right join(右联接) 返回包括右表中的所有记录和左表中关联字段相等的记录 inner join(等值连接) 只返回两个表中关联字段相等的行 ","date":"2024-03-11","objectID":"/2024-03-11/mysql/:3:4","tags":["interview","mysql"],"title":"面试题精选--MySQL篇","uri":"/2024-03-11/mysql/"},{"categories":["interview"],"content":"集群 ","date":"2024-03-11","objectID":"/2024-03-11/mysql/:4:0","tags":["interview","mysql"],"title":"面试题精选--MySQL篇","uri":"/2024-03-11/mysql/"},{"categories":["interview"],"content":"主从复制过程 MySQl 主从复制： 原理：将主服务器的 binlog 日志复制到从服务器上执行一遍，达到主从数据的一致状态。 过程：从库开启一个 I/O 线程，向主库请求 Binlog 日志。主节点开启一个 binlog dump 线程，检查自己的二进制日志，并发送给从节点；从库将接收到的数据保存到中继日志（Relay log）中，另外开启一个 SQL 线程，把 Relay 中的操作在自身机器上执行一遍 优点： 作为备用数据库，并且不影响业务 可做读写分离，一个写库，一个或多个读库，在不同的服务器上，充分发挥服务器和数据库的性能，但要保证数据的一致性 binlog 记录格式：statement、row、mixed 基于语句 statement 的复制、基于行 row 的复制、基于语句和行（mix）的复制。其中基于 row 的复制方式更能保证主从库数据的一致性，但日志量较大，在设置时考虑磁盘的空间问题。 ","date":"2024-03-11","objectID":"/2024-03-11/mysql/:4:1","tags":["interview","mysql"],"title":"面试题精选--MySQL篇","uri":"/2024-03-11/mysql/"},{"categories":["interview"],"content":"数据一致性问题 “主从复制有延时”，这个延时期间读取从库，可能读到不一致的数据。 缓存记录写 key 法： 在 cache 里记录哪些记录发生过的写请求，来路由读主库还是读从库 异步复制： 在异步复制中，主库执行完操作后，写入 binlog 日志后，就返回客户端，这一动作就结束了，并不会验证从库有没有收到，完不完整，所以这样可能会造成数据的不一致。 半同步复制： 当主库每提交一个事务后，不会立即返回，而是等待其中一个从库接收到 Binlog 并成功写入 Relay-log 中才返回客户端，通过一份在主库的 Binlog，另一份在其中一个从库的 Relay-log，可以保证了数据的安全性和一致性。 全同步复制： 指当主库执行完一个事务，所有的从库都执行了该事务才返回给客户端。因为需要等待所有从库执行完该事务才能返回，所以全同步复制的性能必然会收到严重的影响。 ","date":"2024-03-11","objectID":"/2024-03-11/mysql/:4:2","tags":["interview","mysql"],"title":"面试题精选--MySQL篇","uri":"/2024-03-11/mysql/"},{"categories":["interview"],"content":"总结一些常考的 Golang 面试题，相关资料皆从网络上收集 ","date":"2024-03-11","objectID":"/2024-03-11/golang/:0:0","tags":["interview","golang"],"title":"面试题精选--Golang篇","uri":"/2024-03-11/golang/"},{"categories":["interview"],"content":"切片 - Slice ","date":"2024-03-11","objectID":"/2024-03-11/golang/:1:0","tags":["interview","golang"],"title":"面试题精选--Golang篇","uri":"/2024-03-11/golang/"},{"categories":["interview"],"content":"同一 slice 上的切片其底层数组是同一个吗 同一切片上的切片共享相同的底层数组。在 Go 中，切片是对数组的一个引用，而不是值的拷贝。当你对一个切片进行切片操作时，产生的新切片将仍然引用相同的底层数组，而不会创建新的底层数组。这意味着，无论你如何对切片进行切割或修改，底层数组都会相应地被修改。 // PASS func TestSlice1(t *testing.T) { s := []int{1, 2, 3, 4, 5} s1 := s[:] s2 := s[1:4] s[0], s[2] = 100, 99 assert.True(t, s1[0] == 100) assert.True(t, s1[2] == 99) assert.True(t, s2[1] == 99) } ","date":"2024-03-11","objectID":"/2024-03-11/golang/:1:1","tags":["interview","golang"],"title":"面试题精选--Golang篇","uri":"/2024-03-11/golang/"},{"categories":["interview"],"content":"append 操作返回的底层数组会变吗 在使用 append 函数向切片中添加元素时，如果当前切片容量不足以容纳新元素，append 函数会分配一个新的底层数组，将原切片中的元素复制到新的数组中，并在新的数组中添加新元素。这意味着 append 操作可能会返回一个指向不同底层数组的新切片。 // PASS func TestSlice2(t *testing.T) { s1 := []int{1, 2, 3} s2 := append(s1, 4) s1[0] = 100 assert.True(t, s1[0] != s2[0]) } 当切片容量足够时，append 函数会原地修改原切片，因此返回的切片仍然指向相同的底层数组。在这种情况下，原切片可能会被修改，但它仍然引用相同的底层数组。 ","date":"2024-03-11","objectID":"/2024-03-11/golang/:1:2","tags":["interview","golang"],"title":"面试题精选--Golang篇","uri":"/2024-03-11/golang/"},{"categories":["interview"],"content":"如果对 slice 中的元素取指针，放到一个新的数组中，新数组中的值是什么样的 考察对 for...range... 的了解。 对于for _, v := range array，每次都会对 v 进行赋值，所以最后取到的都是变量 v 的地址。 可通过下列两种方式获得所有元素的地址： // 方法一：局部变量拷贝v，也可以用其他变量名 for i, v := range nums { v := v pointers[i] = \u0026v } // 方法二：直接通过下标获取 for i := range nums { pointers[i] = \u0026nums[i] } ","date":"2024-03-11","objectID":"/2024-03-11/golang/:1:3","tags":["interview","golang"],"title":"面试题精选--Golang篇","uri":"/2024-03-11/golang/"},{"categories":["interview"],"content":"映射 - Map ","date":"2024-03-11","objectID":"/2024-03-11/golang/:2:0","tags":["interview","golang"],"title":"面试题精选--Golang篇","uri":"/2024-03-11/golang/"},{"categories":["interview"],"content":"Map 是并发安全的吗 不是，Map 不并发安全，如果同时写同一个 Map，会造成 panic ","date":"2024-03-11","objectID":"/2024-03-11/golang/:2:1","tags":["interview","golang"],"title":"面试题精选--Golang篇","uri":"/2024-03-11/golang/"},{"categories":["interview"],"content":"通道 - Channel ","date":"2024-03-11","objectID":"/2024-03-11/golang/:3:0","tags":["interview","golang"],"title":"面试题精选--Golang篇","uri":"/2024-03-11/golang/"},{"categories":["interview"],"content":"有缓冲与无缓冲的 Channel 之间的区别 主要体现在两个方面：阻塞行为和并发性能。 缓冲 channel： 缓冲 channel 允许在发送数据时，如果 channel 中还有可用的缓冲区，则发送操作不会被阻塞，直接将数据发送到缓冲区中。 在接收数据时，如果 channel 中有数据可用，则接收操作不会被阻塞，直接从缓冲区中读取数据。 当 channel 中的缓冲区满了时，发送操作会阻塞直到有其他 goroutine 从 channel 中接收数据，腾出缓冲区空间。 同样地，当 channel 中的缓冲区为空时，接收操作会阻塞直到有其他 goroutine 向 channel 中发送数据。 无缓冲 channel： 无缓冲 channel 发送数据时，发送操作会阻塞直到有其他 goroutine 准备好接收数据。 接收数据时，接收操作会阻塞直到有其他 goroutine 发送数据到 channel 中。 无缓冲 channel 的发送和接收操作是同步的，它们会导致发送和接收两个 goroutine 同时被阻塞，直到它们能够匹配到对应的操作。 无缓冲 channel 通常用于同步 goroutine 之间的通信，保证数据的可靠传输和同步。 ","date":"2024-03-11","objectID":"/2024-03-11/golang/:3:1","tags":["interview","golang"],"title":"面试题精选--Golang篇","uri":"/2024-03-11/golang/"},{"categories":["interview"],"content":"上下文 - Context ","date":"2024-03-11","objectID":"/2024-03-11/golang/:4:0","tags":["interview","golang"],"title":"面试题精选--Golang篇","uri":"/2024-03-11/golang/"},{"categories":["interview"],"content":"什么是 Context 在 Go 语言中，context.Context 是一个用于在 Goroutine 之间传递请求相关值、取消信号和截止时间的标准方式。它主要用于控制 Goroutine 的生命周期，以及在并发环境下进行请求处理、超时控制和取消操作等。 context.Context 的核心方法包括： context.Background()：返回一个空的 Context，用作父 Context，通常在整个请求的生命周期中作为顶级的 Context 使用。 context.WithCancel(parent)：返回一个带有取消信号的 Context 和一个取消函数。当调用取消函数时，该 Context 及其所有子 Context 都会收到取消信号。 context.WithDeadline(parent, deadline)：返回一个带有截止时间的 Context。当到达截止时间时，该 Context 及其所有子 Context 都会收到取消信号。 context.WithTimeout(parent, timeout)：返回一个带有超时时间的 Context。当超过指定的超时时间时，该 Context 及其所有子 Context 都会收到取消信号。 context.WithValue(parent, key, value)：返回一个带有请求相关值的 Context。这些值可以在 Goroutine 之间传递，但不应该用于传递可选参数。 Context 的值应该是请求范围内的元数据，例如请求 ID、用户身份验证信息等。不应该用于传递可选参数，而应该通过函数参数传递。 context.Context 的主要用途包括： 取消信号传递：用于在 Goroutine 中传递取消信号，以便在需要时取消处理。 超时控制：用于在一定时间内进行请求处理，并在超时时取消处理。 请求范围值传递：用于在 Goroutine 之间传递请求相关值，例如请求 ID、用户身份验证信息等。 使用 context.Context 可以有效地控制 Goroutine 的生命周期，避免资源泄漏和 Goroutine 泄漏，并实现更健壮的并发程序。 ","date":"2024-03-11","objectID":"/2024-03-11/golang/:4:1","tags":["interview","golang"],"title":"面试题精选--Golang篇","uri":"/2024-03-11/golang/"},{"categories":["interview"],"content":"并发模型 - Goroutine 与 GMP ","date":"2024-03-11","objectID":"/2024-03-11/golang/:5:0","tags":["interview","golang"],"title":"面试题精选--Golang篇","uri":"/2024-03-11/golang/"},{"categories":["interview"],"content":"什么是协程泄漏 协程泄露是指在使用协程时，由于某些原因导致协程无法被及时回收和释放，从而占用了系统资源而无法被重复利用的情况。协程泄露可能会导致内存泄露或者系统资源耗尽等问题，影响程序的性能和稳定性。 常见引起协程泄露的原因包括： 未关闭通道（Channel）： 当一个协程向通道发送数据后，如果没有其他协程接收数据，通道将会一直阻塞，导致该协程无法退出，从而产生协程泄露。因此，在使用通道时需要确保及时关闭通道以释放协程。 循环引用： 如果协程持有某些资源，而这些资源又持有了对协程的引用，形成了循环引用，那么即使协程不再需要这些资源，也无法被回收，从而导致协程泄露。这种情况下，需要仔细检查资源的生命周期，确保适时释放资源。 阻塞操作： 协程在执行过程中可能会发生阻塞，例如等待 I/O 操作完成或者等待锁释放等，如果阻塞时间过长或者无法及时结束，可能会导致协程泄露。需要谨慎设计协程的执行逻辑，避免长时间的阻塞操作。 未处理异常： 如果协程发生了未捕获的异常，并且没有恢复或处理这些异常，那么协程可能会被永久性地终止而无法被回收，从而导致泄露。 ","date":"2024-03-11","objectID":"/2024-03-11/golang/:5:1","tags":["interview","golang"],"title":"面试题精选--Golang篇","uri":"/2024-03-11/golang/"},{"categories":["interview"],"content":"什么是 GMP 模型 Goroutine（Go 协程）： Goroutine 是 Go 语言中的轻量级线程，它由 Go 运行时（runtime）调度和管理。Goroutine 可以看作是执行并发任务的独立单位，相较于传统的线程，Goroutine 的创建和切换成本非常低，因此可以高效地支持大量的并发任务。 M（线程）： M 代表着操作系统的线程（machine thread）。每个 M 都会关联一个线程，它负责执行 Goroutine。M 的数量是由 Go 运行时动态管理的，它会根据系统的核心数量等因素动态调整 M 的数量，以充分利用系统资源。 P（处理器）： P 是一种逻辑处理器，它负责调度和管理 Goroutine。P 的数量通常是固定的，并且与 CPU 核心数有关。P 会将 Goroutine 分配给 M，并负责调度 M 在 CPU 上执行。P 的数量可以通过 Go 语言的 GOMAXPROCS 环境变量来控制。 ","date":"2024-03-11","objectID":"/2024-03-11/golang/:5:2","tags":["interview","golang"],"title":"面试题精选--Golang篇","uri":"/2024-03-11/golang/"},{"categories":["interview"],"content":"M 和 P 是一对一的吗 M 和 P 是多对多的关系，一个 P 可以管理多个 M，但一个 M 同一时间只能被一个 P 所关联。 ","date":"2024-03-11","objectID":"/2024-03-11/golang/:5:3","tags":["interview","golang"],"title":"面试题精选--Golang篇","uri":"/2024-03-11/golang/"},{"categories":["interview"],"content":"处理器 P 如何管理多个线程 M 本地队列（Local Queue）： 每个 P 都有一个本地队列，用于存储被当前 P 管理的 Goroutine。这个队列是针对当前 P 而言的，因此可以高效地进行操作，比如入队和出队。本地队列可以减少锁的竞争，提高并发性能。 全局队列（Global Queue）： 所有 P 共享一个全局队列，用于存储没有被任何 P 管理的 Goroutine。当一个 P 的本地队列空了，它可以从全局队列中获取 Goroutine 来执行。全局队列通常会使用锁进行保护，因为多个 P 可能同时竞争全局队列中的 Goroutine。 空闲 M 列表（Idle M List）： P 还会维护一个空闲 M 的列表。当 P 的本地队列满了或者被阻塞时，它可以从空闲 M 列表中获取一个空闲的 M 来执行 Goroutine。 P 通过这些队列来动态管理多个 M 的调度和执行，从而实现高效的并发调度。当一个 M 执行完成或者阻塞时，它会回到 P 的管理下，然后再次被分配 Goroutine 执行。 ","date":"2024-03-11","objectID":"/2024-03-11/golang/:5:4","tags":["interview","golang"],"title":"面试题精选--Golang篇","uri":"/2024-03-11/golang/"},{"categories":["interview"],"content":"死循环的协程如何调度 Preemption（抢占）： Go 语言的运行时系统会在一定的时间间隔内（通常几毫秒）进行抢占调度，即使一个协程正在执行一个死循环，也会在一定的时间后将处理器让给其他协程执行。这种机制能够保证其他协程不会因为某个协程的死循环而无法执行。 系统调用或阻塞操作： 如果一个协程在执行死循环时发起了系统调用或者进行了阻塞操作（如等待 IO 完成），那么它会被 Go 运行时系统暂时挂起，直到系统调用完成或阻塞操作解除，从而让其他协程有机会执行。 手动控制： 在一些特殊情况下，可以手动控制死循环协程的执行。例如，可以使用 Go 语言的 select{} 语句结合 time.After 通道来设置一个超时，以便让死循环协程周期性地让出处理器，从而允许其他协程执行。但这种方法需要手动在死循环中加入超时检查的逻辑。 ","date":"2024-03-11","objectID":"/2024-03-11/golang/:5:5","tags":["interview","golang"],"title":"面试题精选--Golang篇","uri":"/2024-03-11/golang/"},{"categories":["interview"],"content":"阻塞的协程如何调度 系统调用阻塞： 当一个协程执行系统调用（如文件读取、网络请求等）而导致阻塞时，Go 调度器会将该协程暂停，并尝试调度其他可运行的协程来继续执行。当系统调用完成后，阻塞的协程会重新被调度执行。 通道阻塞： 当一个协程试图发送或接收数据到或从一个无缓冲通道时，如果通道中没有对应的接收方或发送方，该协程会被阻塞。在这种情况下，Go 调度器会暂停被阻塞的协程，并尝试调度其他可运行的协程执行，直到通道操作可以完成。 等待组（WaitGroup）阻塞： 当主协程等待一组其他协程完成时，通常会使用 sync.WaitGroup 进行同步。在这种情况下，主协程会调用 WaitGroup.Wait() 方法阻塞等待，直到所有其他协程完成并调用 WaitGroup.Done() 通知完成。Go 调度器会在这种情况下暂停主协程，并继续执行其他可运行的协程。 ","date":"2024-03-11","objectID":"/2024-03-11/golang/:5:6","tags":["interview","golang"],"title":"面试题精选--Golang篇","uri":"/2024-03-11/golang/"},{"categories":["interview"],"content":"垃圾回收 - GC ","date":"2024-03-11","objectID":"/2024-03-11/golang/:6:0","tags":["interview","golang"],"title":"面试题精选--Golang篇","uri":"/2024-03-11/golang/"},{"categories":["interview"],"content":"Go 中的垃圾回收是怎样的 Go 语言的垃圾回收（Garbage Collection，GC）是一种自动管理内存的机制，它负责在程序运行时自动识别并释放不再使用的内存对象，以避免内存泄漏和提高内存利用率。 以下是 Go 语言的垃圾回收的一些特点和工作原理： 并发标记清除： Go 语言的垃圾回收器采用了并发标记清除（Concurrent Mark and Sweep）算法。在标记阶段，垃圾回收器会从根对象开始，遍历程序中的对象图，并标记出所有可达的对象。在清除阶段，垃圾回收器会扫描堆中的对象，清除所有未被标记的对象。这个过程是并发执行的，不会阻塞用户程序的执行。 三色标记法： Go 语言的垃圾回收器使用了三色标记法，将对象分为三种状态：白色、灰色和黑色。白色表示对象未被访问，灰色表示对象被标记但其子对象还未被标记，黑色表示对象及其子对象已被标记。在标记阶段，垃圾回收器通过遍历对象图，将对象从白色变为灰色，并将其子对象加入标记队列。在清除阶段，垃圾回收器清除所有白色对象。 分代回收： Go 语言的垃圾回收器采用了分代回收策略，将堆中的对象分为几个代（generation）。新分配的对象会被分配到年轻代，经过多次垃圾回收后仍然存活的对象会被晋升到老年代。由于年轻代的对象生命周期较短，因此可以采用更频繁的垃圾回收策略，而老年代的对象则采用更慢的垃圾回收策略，以提高性能。 写屏障： Go 语言的垃圾回收器使用写屏障技术，记录对象的写入操作，以便在垃圾回收过程中正确识别对象的引用关系。写屏障会在写入指针时触发，将被修改的对象标记为灰色，并将新写入的指针加入标记队列。 ","date":"2024-03-11","objectID":"/2024-03-11/golang/:6:1","tags":["interview","golang"],"title":"面试题精选--Golang篇","uri":"/2024-03-11/golang/"},{"categories":["interview"],"content":"三色标记的过程 三色标记法是一种用于标记-清除（mark-sweep）垃圾回收算法的优化技术，它将对象的标记状态分为三种颜色：白色、灰色和黑色。以下是三色标记法的基本过程： 初始标记（Initial Mark）： 在初始标记阶段，垃圾回收器从根对象开始，标记所有直接可达的对象为灰色，并将它们加入标记队列。根对象通常是全局变量、栈上的变量以及活跃的协程等。 并发标记（Concurrent Mark）： 在并发标记阶段，垃圾回收器并发地遍历堆中的对象图，标记所有可达的对象为灰色，并将其子对象加入标记队列。如果发现新的灰色对象，将其标记为黑色，并将其子对象加入标记队列。 重新标记（Re-Mark）： 在并发标记过程中，程序可能会产生新的对象，这些新对象可能会在标记过程中被修改，因此需要重新标记。重新标记阶段会对之前标记的所有灰色对象进行重新扫描，将其子对象加入标记队列，并标记为黑色。 清除（Sweep）： 在清除阶段，垃圾回收器扫描整个堆，清除所有未被标记的白色对象，并将它们释放回内存池。清除过程是并发执行的，不会阻塞程序的执行。 ","date":"2024-03-11","objectID":"/2024-03-11/golang/:6:2","tags":["interview","golang"],"title":"面试题精选--Golang篇","uri":"/2024-03-11/golang/"},{"categories":["interview"],"content":"其他 ","date":"2024-03-11","objectID":"/2024-03-11/golang/:7:0","tags":["interview","golang"],"title":"面试题精选--Golang篇","uri":"/2024-03-11/golang/"},{"categories":["interview"],"content":"Go 中的 make 和 new 的区别 在 Go 语言中，make 和 new 都是用于创建数据结构的内置函数，但它们的使用场景和作用不同。 make： make 函数主要用于创建 slice、map 和 channel 这三种引用类型的数据结构，并且返回的是一个初始化之后的数据结构。 例如，使用 make 函数创建一个长度为 5 的整型 slice：s := make([]int, 5) make 函数的签名为：func make(t Type, size ...IntegerType) Type，其中 t 表示数据结构的类型，size 表示数据结构的大小或者容量（对于 slice 和 channel）。 new： new 函数用于创建某种类型的指针，并且返回该类型的指针的零值，即指向该类型的新分配的零值的指针。 例如，使用 new 函数创建一个整型指针：p := new(int) new 函数的签名为：func new(Type) *Type，其中 Type 表示要创建的类型。 总的来说，make 用于创建引用类型的数据结构，返回的是一个已初始化的数据结构；而 new 用于创建某种类型的指针，返回的是该类型的零值的指针。 ","date":"2024-03-11","objectID":"/2024-03-11/golang/:7:1","tags":["interview","golang"],"title":"面试题精选--Golang篇","uri":"/2024-03-11/golang/"},{"categories":["interview"],"content":"在 defer 中修改了局部变量并 return，返回值为类型和(变量+类型)两种情况下会返回什么 在 Go 中，defer 语句中对局部变量的修改对函数的返回值没有影响。无论函数返回值是单个变量还是多个变量（包括变量及其类型），在 defer 中对局部变量的修改不会影响函数返回值。这是因为 Go 在函数返回时会将函数的返回值保存在栈中，并不会受到 defer 中对变量的修改影响。 ","date":"2024-03-11","objectID":"/2024-03-11/golang/:7:2","tags":["interview","golang"],"title":"面试题精选--Golang篇","uri":"/2024-03-11/golang/"},{"categories":[],"content":"朋友：三人行，必有我师 fyq \"一位CS专业ACMer搭建的个人Wiki。\" YZBlog \"个人博客，随便写写，就当个云笔记用吧\" guangju's blog \"B站：guangju_dev\" HansFang's Blog \"Hans的ACM记录\" ","date":"2024-03-10","objectID":"/friend/:1:0","tags":[],"title":"有朋自远方来","uri":"/friend/"},{"categories":[],"content":"如何交换友链 友链须知 若您的头像无法获取时，会自动使用默认头像。 当您的网站存在无法访问、404、友链入口难以发现、删除本站友链等情况时，本站可能会在不通知的情况下撤掉贵站链接！如需恢复需要再次申请。 请在本页评论区里（也可以通过邮件 📧 panjm2001@126.com 的方式）添加如下格式，添加友链成功后会通过回复评论的邮件通知进行反馈： name：站点名字 url：站点地址 logo：站点图标或个人头像 word：站点描述 下面是可选项： primary-color：边框及鼠标悬停的背景颜色，允许设置渐变色 支持 7 种：default、red、green、blue、linear-red、linear-green、linear-blue img-animation：头像动画 rotate(鼠标悬停时旋转，此为默认效果)、auto_rotate_left(左旋转)、auto_rotate_right(右旋转) border-animation：边框动画 shadow(阴影，此为默认效果)、borderFlash(边框闪现)、led(跑马灯)、bln(主颜色呼吸灯) 示例： name=\"江明说|Jimmy Talk\" url=\"https://blog.pjmcode.top/\" logo=\"https://blog.pjmcode.top/images/avatar.jpeg\" word=\"江明说代码，说生活，说万物。\" ","date":"2024-03-10","objectID":"/friend/:2:0","tags":[],"title":"有朋自远方来","uri":"/friend/"},{"categories":["博客搭建"],"content":"介绍网站类型，框架类型以及为什么选择使用 Hugo 搭建 ","date":"2024-03-09","objectID":"/2024-03-09/build-0/:0:0","tags":["博客搭建","blog","hugo"],"title":"零成本搭建个人博客系列--第一篇 为什么选择Hugo？","uri":"/2024-03-09/build-0/"},{"categories":["博客搭建"],"content":"网站分类 动态网站 动态网站并不是指具有动画功能的网站，而是指​网站内容可根据不同情况动态变更的网站，一般情况下动态网站通过数据库进行架构。 动态网站除了要设计网页外，还要通过数据库和编程序来使网站具有更多自动的和高级的功能。动态网站体现在网页一般是以asp，jsp，php，aspx等技术，而静态网页一般是HTML（标准通用标记语言的子集）结尾，动态网站服务器空间配置要比静态的网页要求高，费用也相应的高，不过动态网页利于网站内容的更新，适合企业建站。动态是相对于静态网站而言。 ——百度百科 静态网站 技术上来讲，静态网站是指网页不是由服务器动态生成的。HTML、CSS 和 JavaScript 文件就静静地躺在服务器的某个路径下，它们的内容与终端用户接收到的版本是一样的。原始的源码文件已经提前编译好了，源码在每次请求后都不会变化。 ","date":"2024-03-09","objectID":"/2024-03-09/build-0/:1:0","tags":["博客搭建","blog","hugo"],"title":"零成本搭建个人博客系列--第一篇 为什么选择Hugo？","uri":"/2024-03-09/build-0/"},{"categories":["博客搭建"],"content":"框架选择 WordPress 官网：https://wordpress.org/ WordPress 是一款免费开源的内容管理系统（CMS），它是目前世界上使用最广泛的网站建设平台之一。 WordPress 可以帮助用户快速创建和管理各种类型的网站，例如博客、企业网站、电子商务网站等。 Hexo 官网：https://hexo.io/zh-cn/index.html Hexo 是一个快速、简洁且高效的博客框架。它允许用户使用 Markdown 语言编写内容，并将其渲染为静态网页。 它相当于与一个网站的主题模板，只需要做简单的配置就能够完成页面的渲染。 其主要特点包括快速部署，Markdown 支持，灵活的布局，丰富的插件。 Hugo 官网：https://gohugo.io/ Hugo 是由 Go 编写的快速现代静态网站生成器。 ","date":"2024-03-09","objectID":"/2024-03-09/build-0/:2:0","tags":["博客搭建","blog","hugo"],"title":"零成本搭建个人博客系列--第一篇 为什么选择Hugo？","uri":"/2024-03-09/build-0/"},{"categories":["博客搭建"],"content":"为什么选择 hugo 了解需求 使用简单，轻量级，尽可能的渲染快 有好看且丰富的主题可供选择 一篇文章需要良好的书写排版，比如支持渲染 markdown 博客并不需要实时更新，且学生党需要考虑服务器等成本 有相关的发布平台支持，比如 netlify、vercel 或 github page 选择 hugo 的原因 Hugo 依靠 Go 语言进行开发，号称世界上最快的构建网站工具 Hugo 有多种主题可供选择，可自定义配置 Hugo 支持 markdown Hugo 是一个静态网站框架 Hugo 可以支持基于发布平台进行 CI/CD 由于 Hugo 的强大性能，使得渲染快速，可以所见即所得，方便调试 谁适合 Hugo Hugo 适用于更喜欢在文本编辑器而不是浏览器中编写的人。 Hugo 适用于那些想要手动编码自己的网站而又不想担心设置复杂的运行时、依赖和数据库的人。 Hugo 适用于构建博客、公司网站、作品集网站、文档、单个落地页或拥有数千个页面的网站的人。 ","date":"2024-03-09","objectID":"/2024-03-09/build-0/:3:0","tags":["博客搭建","blog","hugo"],"title":"零成本搭建个人博客系列--第一篇 为什么选择Hugo？","uri":"/2024-03-09/build-0/"},{"categories":["golang"],"content":"介绍 Golang 中的 channel 是什么，如何使用以及一些 channel 的使用例子 ","date":"2024-03-08","objectID":"/2024-03-08/channel/:0:0","tags":["golang","channel"],"title":"深入理解Go语言的Channel","uri":"/2024-03-08/channel/"},{"categories":["golang"],"content":"什么是 channel channel(一般简写为 chan) 管道提供了一种机制，它是一种类型，类似于队列或管道，可以用于在 goroutine 之间传递数据。 此外，channel 是并发安全的。 ","date":"2024-03-08","objectID":"/2024-03-08/channel/:1:0","tags":["golang","channel"],"title":"深入理解Go语言的Channel","uri":"/2024-03-08/channel/"},{"categories":["golang"],"content":"channel 的基本使用 通信操作符 \u003c- 的箭头指示数据流向，箭头指向哪里，数据就流向哪里，它是一个二元操作符，可以支持任意类型。 ","date":"2024-03-08","objectID":"/2024-03-08/channel/:2:0","tags":["golang","channel"],"title":"深入理解Go语言的Channel","uri":"/2024-03-08/channel/"},{"categories":["golang"],"content":"创建 channel channel 有两种类型，区分类型为无缓冲与有缓冲。 // 无缓冲channel，同步channel，缓冲区大小为0，即必须有同步协程进行读写操作 ch := make(chan T) // 有缓冲channel，异步channel，缓冲区大小为10，即channel里最多有10个元素 ch := make(chan T, 10) ","date":"2024-03-08","objectID":"/2024-03-08/channel/:2:1","tags":["golang","channel"],"title":"深入理解Go语言的Channel","uri":"/2024-03-08/channel/"},{"categories":["golang"],"content":"向 channel 里写数据 ch \u003c- data // 向channel内写入data的数据 ","date":"2024-03-08","objectID":"/2024-03-08/channel/:2:2","tags":["golang","channel"],"title":"深入理解Go语言的Channel","uri":"/2024-03-08/channel/"},{"categories":["golang"],"content":"从 channel 里读数据 // 从 channel 中接收数据并赋值给 data data := \u003c-ch // 从 channel 中接收数据并丢弃 \u003c-ch ","date":"2024-03-08","objectID":"/2024-03-08/channel/:2:3","tags":["golang","channel"],"title":"深入理解Go语言的Channel","uri":"/2024-03-08/channel/"},{"categories":["golang"],"content":"关闭 channel close(ch) // 用于关闭一个channel 关闭channel时，需要注意以下细节 读取关闭后的无缓存通道，不管通道中是否有数据，返回值都为 0 和 false 读取关闭后的有缓存通道，将缓存数据读取完后，再读取返回值为 0 和 false 对于一个关闭的 channel，如果继续向 channel 发送数据，会引起 panic channel 不能 close 两次，多次 close 会 panic ","date":"2024-03-08","objectID":"/2024-03-08/channel/:2:4","tags":["golang","channel"],"title":"深入理解Go语言的Channel","uri":"/2024-03-08/channel/"},{"categories":["golang"],"content":"channel 场景分析 写操作：ch\u003c- 读操作：\u003c-ch 关闭操作：close(ch) channel 为nil 阻塞 阻塞 panic 无缓冲的 channel 阻塞，除非有其他协程同时读 阻塞，除非有其他协程同时写 成功 有缓冲的 channel 成功，直到缓冲区满时阻塞 成功，除非缓冲区为空时阻塞 成功 已经close的 channel panic 读出缓冲区内存在的内容，后续只能读到类型的零值，可以根据断言判断是否获取到数据 panic ","date":"2024-03-08","objectID":"/2024-03-08/channel/:3:0","tags":["golang","channel"],"title":"深入理解Go语言的Channel","uri":"/2024-03-08/channel/"},{"categories":["golang"],"content":"channel 使用例子 ","date":"2024-03-08","objectID":"/2024-03-08/channel/:4:0","tags":["golang","channel"],"title":"深入理解Go语言的Channel","uri":"/2024-03-08/channel/"},{"categories":["golang"],"content":"使用 for-range 读 channel 适合场景：需要不断的从 channel 里读取数据 使用for-range读取 channel，这样既安全又便利，当 channel 关闭时，for 循环会自动退出，无需主动监测 channel 是否关闭，可以防止读取已经关闭的 channel，造成读到数据为通道所存储的数据类型的零值。 for x := range ch { fmt.Println(x) } ","date":"2024-03-08","objectID":"/2024-03-08/channel/:4:1","tags":["golang","channel"],"title":"深入理解Go语言的Channel","uri":"/2024-03-08/channel/"},{"categories":["golang"],"content":"使用v,ok := \u003c-ch + select操作判断 channel 是否关闭 ok 的结果和含义： true：读到通道数据，不确定是否关闭，可能 channel 还有保存的数据，但 channel 已关闭。 false：通道关闭，无数据读到。 从关闭的 channel 读值读到是 channel 所传递数据类型的零值，这个零值有可能是发送者发送的，也可能是 channel 关闭了。 _, ok := \u003c-ch与 select 配合使用的，当 ok 为 false 时，代表了 channel 已经 close。下面解释原因，\u003cspan\u003e \u003c/span\u003e_,ok := \u003c-ch对应的函数是func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool)，入参 block 含义是当前 goroutine 是否可阻塞，当 block 为 false 代表的是 select 操作，不可阻塞当前 goroutine 的在 channel 操作，否则是普通操作（即_, ok不在 select 中）。返回值 selected 代表当前操作是否成功，主要为 select 服务，返回received 代表是否从 channel 读到有效值。它有 3 种返回值情况： block 为 false，即执行 select 时，如果 channel 为空，返回(false,false)，代表 select 操作失败，没接收到值。 否则，如果 channel 已经关闭，并且没有数据，ep 即接收数据的变量设置为零值，返回(true,false)，代表 select 操作成功，但 channel 已关闭，没读到有效值。 否则，其他读到有效数据的情况，返回(true,ture)。 package main func main() { ch := make(chan int, 1) // 发送1个数据关闭channel ch \u003c- 1 close(ch) print(\"close channel\\n\") // 不停读数据直到channel没有有效数据 for { select { case v, ok := \u003c-ch: print(\"v: \", v, \", ok:\", ok, \"\\n\") if !ok { print(\"channel is close\\n\") return } default: print(\"nothing\\n\") } } } // output: // close channel // v: 1, ok:true // v: 0, ok:false // channel is close ","date":"2024-03-08","objectID":"/2024-03-08/channel/:4:2","tags":["golang","channel"],"title":"深入理解Go语言的Channel","uri":"/2024-03-08/channel/"},{"categories":["golang"],"content":"使用 select 处理多个 channel 适合场景：需要对多个通道进行同时处理，但只处理最先发生的 channel 时 select可以同时监控多个通道的情况，只处理未阻塞的 case。当通道为 nil 时，对应的 case 永远为阻塞，无论读写。特殊关注：普通情况下，对 nil 的通道写操作是要 panic 的。 // 分配job时，如果收到关闭的通知则退出，不分配job func (h *Handler) handle(job *Job) { select { case h.jobCh\u003c-job: return case \u003c-h.stopCh: return } } ","date":"2024-03-08","objectID":"/2024-03-08/channel/:4:3","tags":["golang","channel"],"title":"深入理解Go语言的Channel","uri":"/2024-03-08/channel/"},{"categories":["golang"],"content":"使用 channel 的声明控制读写权限 适合场景：协程对某个通道只读或只写时 目的： 使代码更易读、更易维护， 防止只读协程对通道进行写数据，但通道已关闭，造成 panic。 用法： 如果协程对某个 channel 只有写操作，则这个 channel 声明为只写。 如果协程对某个 channel 只有读操作，则这个 channe 声明为只读。 // 只有generator进行对outCh进行写操作，返回声明 // \u003c-chan int，可以防止其他协程乱用此通道，造成隐藏bug func generator(int n) \u003c-chan int { outCh := make(chan int) go func(){ for i:=0;i\u003cn;i++{ outCh\u003c-i } }() return outCh } // consumer只读inCh的数据，声明为\u003c-chan int // 可以防止它向inCh写数据 func consumer(inCh \u003c-chan int) { for x := range inCh { fmt.Println(x) } } ","date":"2024-03-08","objectID":"/2024-03-08/channel/:4:4","tags":["golang","channel"],"title":"深入理解Go语言的Channel","uri":"/2024-03-08/channel/"},{"categories":["golang"],"content":"为操作加上超时 适用场景：需要超时控制的操作 使用select和time.After，看操作和定时器哪个先返回，处理先完成的，就达到了超时控制的效果 func doWithTimeOut(timeout time.Duration) (int, error) { select { case ret := \u003c-do(): return ret, nil case \u003c-time.After(timeout): return 0, errors.New(\"timeout\") } } func do() \u003c-chan int { outCh := make(chan int) go func() { // do work }() return outCh } ","date":"2024-03-08","objectID":"/2024-03-08/channel/:4:5","tags":["golang","channel"],"title":"深入理解Go语言的Channel","uri":"/2024-03-08/channel/"},{"categories":["golang"],"content":"使用 time 实现 channel 无阻塞读写 场景：并不希望在 channel 的读写上浪费时间 是为操作加上超时的扩展，这里的操作是 channel 的读或写 // time.After等待可以替换为default，则是channel阻塞时，立即返回的效果 func unBlockRead(ch chan int) (x int, err error) { select { case x = \u003c-ch: return x, nil case \u003c-time.After(time.Microsecond): return 0, errors.New(\"read time out\") } } func unBlockWrite(ch chan int, x int) (err error) { select { case ch \u003c- x: return nil case \u003c-time.After(time.Microsecond): return errors.New(\"read time out\") } } ","date":"2024-03-08","objectID":"/2024-03-08/channel/:4:6","tags":["golang","channel"],"title":"深入理解Go语言的Channel","uri":"/2024-03-08/channel/"},{"categories":["golang"],"content":"无缓冲 channel 可用于协程间同步 package main import \"fmt\" func goroutine1(ch chan\u003c- bool) { fmt.Println(\"Goroutine 1 is doing something\") ch \u003c- true } func goroutine2(ch \u003c-chan bool, exit chan\u003c- struct{}) { \u003c-ch fmt.Println(\"Goroutine 2 received data\") exit \u003c- struct{}{} } func main() { ch := make(chan bool) exit := make(chan struct{}) go goroutine1(ch) go goroutine2(ch, exit) \u003c-exit } // output: // Goroutine 1 is doing something // Goroutine 2 received data ","date":"2024-03-08","objectID":"/2024-03-08/channel/:4:7","tags":["golang","channel"],"title":"深入理解Go语言的Channel","uri":"/2024-03-08/channel/"},{"categories":["golang"],"content":"有缓冲 channel 生产者-消费者模型 package main import ( \"fmt\" \"time\" ) func producer(ch chan\u003c- int) { for i := 0; i \u003c 5; i++ { ch \u003c- i time.Sleep(time.Second) } close(ch) } func consumer(ch \u003c-chan int, exit chan\u003c- struct{}) { for num := range ch { fmt.Println(\"Received:\", num) } exit \u003c- struct{}{} } func main() { ch := make(chan int) exit := make(chan struct{}) defer close(exit) go producer(ch) go consumer(ch, exit) \u003c-exit } // output: // Received: 0 // Received: 1 // Received: 2 // Received: 3 // Received: 4 协程池：控制并发数量 package main import ( \"fmt\" \"time\" ) func worker(id int, jobs \u003c-chan int, results chan\u003c- int) { for job := range jobs { fmt.Printf(\"Worker %d started job %d\\n\", id, job) time.Sleep(time.Second) fmt.Printf(\"Worker %d finished job %d\\n\", id, job) results \u003c- job * 2 } } func main() { numJobs := 5 numWorkers := 3 jobs := make(chan int, numJobs) results := make(chan int, numJobs) for w := 1; w \u003c= numWorkers; w++ { go worker(w, jobs, results) } for j := 1; j \u003c= numJobs; j++ { jobs \u003c- j } close(jobs) for r := 1; r \u003c= numJobs; r++ { \u003c-results } } // output: // Worker 3 started job 1 // Worker 1 started job 2 // Worker 2 started job 3 // Worker 2 finished job 3 // Worker 2 started job 4 // Worker 3 finished job 1 // Worker 3 started job 5 // Worker 1 finished job 2 // Worker 2 finished job 4 // Worker 3 finished job 5 ","date":"2024-03-08","objectID":"/2024-03-08/channel/:4:8","tags":["golang","channel"],"title":"深入理解Go语言的Channel","uri":"/2024-03-08/channel/"},{"categories":["golang"],"content":"与 select 配合 避免协程泄漏 finish := make(chan struct{}) defer close(finish) go func() { ... select { case \u003c-finish: // avoid goroutine memory leak ... your code ... return ... }() 上述代码中，finish chan 一直被阻塞读出，父协程退出时，defer 执行，此时 channel 关闭，读操作不再收到阻塞，通过 select 轮询即可退出子协程，避免协程的内存泄漏。 ","date":"2024-03-08","objectID":"/2024-03-08/channel/:4:9","tags":["golang","channel"],"title":"深入理解Go语言的Channel","uri":"/2024-03-08/channel/"},{"categories":["linux"],"content":"介绍什么是僵尸进程，以及如何处理与预防僵尸进程的产生 ","date":"2024-03-06","objectID":"/2024-03-06/zombie/:0:0","tags":["linux","操作系统"],"title":"Linux系统中僵尸进程的二三事","uri":"/2024-03-06/zombie/"},{"categories":["linux"],"content":"僵尸进程产生的原因 ps 查看进程状态时，僵尸进程的 STAT 栏为 defunct，该进程早已死亡，但在进程表仍占用了一个 slot。由于进程表的容量是有限的，所以，defunct 进程不仅占用系统的内存资源，影响系统的性能，而且如果其数目太多，还会导致系统瘫痪。 子进程先于父进程退出，比如子进程内执行了 exit 命令（exit 的作用是使进程退出，并不能将其完全销毁）。此时进程表中的数据会被该进程的退出码（exit code）、执行时所用的 CPU 时间等数据所取代，这些数据会一直保留到系统将它传递给它的父进程为止。 僵尸进程放弃了几乎所有的内存空间，没有任何可执行代码，也不能被调度，仅仅在进程列表中保留一个位置，记载该进程的退出信息供其他进程收集，此外僵尸进程不占用任何存储空间。 ","date":"2024-03-06","objectID":"/2024-03-06/zombie/:1:0","tags":["linux","操作系统"],"title":"Linux系统中僵尸进程的二三事","uri":"/2024-03-06/zombie/"},{"categories":["linux"],"content":"如何杀死僵尸进程 defunct 状态下的僵尸进程不能直接使用 kill -9 命令杀死。 ","date":"2024-03-06","objectID":"/2024-03-06/zombie/:2:0","tags":["linux","操作系统"],"title":"Linux系统中僵尸进程的二三事","uri":"/2024-03-06/zombie/"},{"categories":["linux"],"content":"普通进程 杀死父进程，此时僵尸进程会变成孤儿进程，由 pid=1 的 init 进程会扫描被杀死进程下的子进程，并且把僵尸进程进行回收。 使用 ps -ef | grep defunct_process_id 命令可以找到 defunct 的僵尸进程的父进程。 ","date":"2024-03-06","objectID":"/2024-03-06/zombie/:2:1","tags":["linux","操作系统"],"title":"Linux系统中僵尸进程的二三事","uri":"/2024-03-06/zombie/"},{"categories":["linux"],"content":"ppid=1 的进程 init 会时刻扫描子进程的状态，那么会在什么情况下，产生 ppid 为 1 的僵尸进程呢？ 进程还在被其他进程使用，但是已退出 进程的子进程还在执行任务，但是父进程已经死亡 进程阻塞在某次 I/O 请求上，此时控制权交到了内核，如果该进程被 kill，那么就会成为 ppid=1 的僵尸进程，这个进程不会退出，会一直阻塞直到 I/O 请求被满足。 因此，当出现 ppid=1 的僵尸进程时，可以从以下情况分析： 查看当前僵尸进程是否被其他进程调用，如被跟踪、调试等 用ps -T -p查看下这个僵尸进程的主线程是否退出 用strace跟踪下这个僵尸进程看看是否有 io 在等待，或者查看下载僵尸之前是否有 io 类的操作发生 使用 ps -ef | grep default_process_id 搜出 gdb attach defunct_process_id，kill 掉 gdb attach 后，僵尸进程就被回收了。 ","date":"2024-03-06","objectID":"/2024-03-06/zombie/:2:2","tags":["linux","操作系统"],"title":"Linux系统中僵尸进程的二三事","uri":"/2024-03-06/zombie/"},{"categories":["linux"],"content":"如何预防僵尸进程 在父进程创建子进程之前，就向系统申明自己并不会对这个子进程的 exit 动作进行任何关注行为，这样的话，子进程一旦退出后，系统就不会去等待父进程的操作，而是直接将该子进程的资源回收掉，也就不会出现僵尸进程了。具体的办法就是，在父进程的初始化函数中，调用这个函数：signal(SIGCHLD,SIG_IGN) 如果上述语句没来得及调用，也有另外一个办法。那就是在创建完子进程后，用waitpid()等待子进程返回，也能达到上述效果 如果上述两个办法都不愿意采用，那还有一招：在父进程创建子进程的时候，连续调用两次fork()，而且使紧跟的子进程直接退出，使其孙子进程成为孤儿进程，从而 init 进程将代替父进程来接手，负责清除这个孤儿进程。于是，父进程就无需进行任何的清理行为，系统会自动处理 ","date":"2024-03-06","objectID":"/2024-03-06/zombie/:3:0","tags":["linux","操作系统"],"title":"Linux系统中僵尸进程的二三事","uri":"/2024-03-06/zombie/"},{"categories":["linux"],"content":"介绍 Linux 中平均负载的相关概念 ","date":"2024-03-03","objectID":"/2024-03-03/load-average/:0:0","tags":["linux","运维","操作系统"],"title":"Linux系统中Load Average的二三事","uri":"/2024-03-03/load-average/"},{"categories":["linux"],"content":"什么是 Load Average 系统负载（System Load）是系统 CPU 繁忙程度的度量，即有多少进程在等待被 CPU 调度（进程等待队列的长度）。 平均负载（Load Average）是一段时间内系统的平均负载，这个一段时间一般取 1 分钟、5 分钟、15 分钟。 即，Linux 系统对当前 CPU 工作量的度量。 ","date":"2024-03-03","objectID":"/2024-03-03/load-average/:1:0","tags":["linux","运维","操作系统"],"title":"Linux系统中Load Average的二三事","uri":"/2024-03-03/load-average/"},{"categories":["linux"],"content":"如何查看 Load Average uptime、top、w皆可查看系统负载。 ➜ ~ w 20:11:32 up 14:11, 0 users, load average: 0.00, 0.01, 0.00 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT ➜ ~ uptime 20:11:36 up 14:11, 0 users, load average: 0.00, 0.01, 0.00 ➜ ~ top top - 20:11:41 up 14:11, 0 users, load average: 0.00, 0.01, 0.00 Tasks: 27 total, 1 running, 26 sleeping, 0 stopped, 0 zombie %Cpu(s): 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st MiB Mem : 7626.3 total, 5361.5 free, 781.8 used, 1483.0 buff/cache MiB Swap: 2048.0 total, 2048.0 free, 0.0 used. 6549.0 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1 root 20 0 2456 1612 1500 S 0.0 0.0 0:00.52 init(Ubuntu-20. 4 root 20 0 2556 288 196 S 0.0 0.0 0:43.55 init 9164 root 20 0 2464 112 0 S 0.0 0.0 0:00.00 SessionLeader 9165 root 20 0 2480 120 0 S 0.0 0.0 0:00.06 Relay(9166) 9166 pjm 20 0 2616 596 528 S 0.0 0.0 0:00.01 sh 9167 pjm 20 0 2616 600 528 S 0.0 0.0 0:00.00 sh 9192 pjm 20 0 2616 596 528 S 0.0 0.0 0:00.00 sh 9254 pjm 20 0 962848 103232 42044 S 0.0 1.3 0:37.84 node 9274 pjm 20 0 739296 74784 38820 S 0.0 1.0 0:59.74 node 9310 pjm 20 0 851080 58720 38612 S 0.0 0.8 0:07.65 node 9343 pjm 20 0 1012872 154420 43844 S 0.0 2.0 7:31.38 node 9367 pjm 20 0 625704 72716 38576 S 0.0 0.9 0:10.73 node 9524 pjm 20 0 12692 6724 4524 S 0.0 0.1 0:00.28 zsh 9657 pjm 20 0 15628 7524 5148 S 0.0 0.1 0:00.63 zsh 16458 root 20 0 2464 112 0 S 0.0 0.0 0:00.00 SessionLeader 16459 root 20 0 2480 120 0 S 0.0 0.0 0:00.07 Relay(16460) 16460 pjm 20 0 16348 8152 5364 S 0.0 0.1 0:00.60 zsh 19286 root 20 0 2484 112 0 S 0.0 0.0 0:00.00 SessionLeader 19287 root 20 0 2500 124 0 S 0.0 0.0 0:01.37 Relay(19288) 19288 pjm 20 0 602504 56584 37424 S 0.0 0.7 0:05.53 node 19298 root 20 0 2484 112 0 S 0.0 0.0 0:00.00 SessionLeader 19299 root 20 0 2500 124 0 S 0.0 0.0 0:00.54 Relay(19300) 19300 pjm 20 0 601480 52768 37308 S 0.0 0.7 0:02.34 node ➜ ~ ","date":"2024-03-03","objectID":"/2024-03-03/load-average/:2:0","tags":["linux","运维","操作系统"],"title":"Linux系统中Load Average的二三事","uri":"/2024-03-03/load-average/"},{"categories":["linux"],"content":"Load Average 值的含义 ","date":"2024-03-03","objectID":"/2024-03-03/load-average/:3:0","tags":["linux","运维","操作系统"],"title":"Linux系统中Load Average的二三事","uri":"/2024-03-03/load-average/"},{"categories":["linux"],"content":"1. 单核处理器 假设我们的系统是单 CPU 单内核的，把它比喻成是一条单向马路，把 CPU 任务比作汽车。 当车不多的时候，load \u003c 1； 当车占满整个马路的时候 load = 1； 当马路都站满了，而且马路外还堆满了汽车的时候，load \u003e 1。 ","date":"2024-03-03","objectID":"/2024-03-03/load-average/:3:1","tags":["linux","运维","操作系统"],"title":"Linux系统中Load Average的二三事","uri":"/2024-03-03/load-average/"},{"categories":["linux"],"content":"2. 多核处理器 我们经常会发现服务器 Load \u003e 1 但是运行仍然不错，那是因为服务器是多核处理器(Multi-core)。 假设我们服务器 CPU 是 2 核，那么将意味我们拥有 2 条马路，我们的 Load = 2 时，所有马路都跑满车辆。 注：查看 cpu 核数命令： ➜ ~ grep 'model name' /proc/cpuinfo | wc -l 16 ","date":"2024-03-03","objectID":"/2024-03-03/load-average/:3:2","tags":["linux","运维","操作系统"],"title":"Linux系统中Load Average的二三事","uri":"/2024-03-03/load-average/"},{"categories":["linux"],"content":"对于不同 Load Average 值，哪些值得警惕？(单核) Load \u003c 0.7：系统很闲，马路上没什么车，要考虑多部署一些服务 0.7 \u003c Load \u003c 1：系统状态不错，马路可以轻松应对 Load == 1：系统马上要处理不多来了，赶紧找一下原因 Load \u003e 1：马路已经非常繁忙了，进入马路的每辆汽车都要无法很快的运行 ","date":"2024-03-03","objectID":"/2024-03-03/load-average/:4:0","tags":["linux","运维","操作系统"],"title":"Linux系统中Load Average的二三事","uri":"/2024-03-03/load-average/"},{"categories":["linux"],"content":"三种 Load Average 情况分析（单核） 1 分钟 Load\u003e1，5 分钟 Load\u003c1，15 分钟 Load\u003c1 短期内繁忙，中长期空闲，初步判断是一个“抖动”，或者是“拥塞前兆” 1 分钟 Load\u003e1，5 分钟 Load\u003e1，15 分钟 Load\u003c1 短期内繁忙，中期内紧张，很可能是一个“拥塞的开始” 1 分钟 Load\u003e1，5 分钟 Load\u003e1，15 分钟 Load\u003e1 短、中、长期都繁忙，系统“正在拥塞” 1 分钟 Load\u003c1，5 分钟 Load\u003e1，15 分钟 Load\u003e1 短期内空闲，中、长期繁忙，不用紧张，系统“拥塞正在好转” ","date":"2024-03-03","objectID":"/2024-03-03/load-average/:5:0","tags":["linux","运维","操作系统"],"title":"Linux系统中Load Average的二三事","uri":"/2024-03-03/load-average/"},{"categories":["linux"],"content":"介绍Linux常用网络相关的命令 ","date":"2024-03-03","objectID":"/2024-03-03/network/:0:0","tags":["linux","计算机网络"],"title":"Linux常用命令--网络篇","uri":"/2024-03-03/network/"},{"categories":["linux"],"content":"网络的性能指标 带宽，表示链路的最大传输速率，单位是 b/s （比特 / 秒），带宽越大，其传输能力就越强。 延时，表示请求数据包发送后，收到对端响应，所需要的时间延迟。不同的场景有着不同的含义，比如可以表示建立 TCP 连接所需的时间延迟，或一个数据包往返所需的时间延迟。 吞吐率，表示单位时间内成功传输的数据量，单位是 b/s（比特 / 秒）或者 B/s（字节 / 秒），吞吐受带宽限制，带宽越大，吞吐率的上限才可能越高。 PPS，全称是 Packet Per Second（包 / 秒），表示以网络包为单位的传输速率，一般用来评估系统对于网络的转发能力。 网络的可用性，表示网络能否正常通信； 并发连接数，表示 TCP 连接数量； 丢包率，表示所丢失数据包数量占所发送数据组的比率； 重传率，表示重传网络包的比例； ","date":"2024-03-03","objectID":"/2024-03-03/network/:1:0","tags":["linux","计算机网络"],"title":"Linux常用命令--网络篇","uri":"/2024-03-03/network/"},{"categories":["linux"],"content":"查看网络配置 要想知道网络的配置和状态，我们可以使用 ifconfig​ 或者 ip​ 命令来查看。 由于 ifconfig ​的 net-tools​ 网络包已不再维护，推荐使用 ip​ 命令。 ","date":"2024-03-03","objectID":"/2024-03-03/network/:2:0","tags":["linux","计算机网络"],"title":"Linux常用命令--网络篇","uri":"/2024-03-03/network/"},{"categories":["linux"],"content":"IP命令示例 # 网络接口的状态与配置 ip link show # 显示网络接口信息 ip link set eth0 up # 开启网卡 ip link set eth0 down # 关闭网卡 ip link set eth0 promisc on # 开启网卡的混合模式 ip link set eth0 promisc offi # 关闭网卡的混个模式 ip link set eth0 txqueuelen 1200 # 设置网卡队列长度 ip link set eth0 mtu 1400 # 设置网卡最大传输单元 # 网络接口IP地址信息 ip addr show # 显示网卡IP信息 ip addr add 192.168.0.1/24 dev eth0 # 设置eth0网卡IP地址192.168.0.1 ip addr del 192.168.0.1/24 dev eth0 # 删除eth0网卡IP地址 # 路由表相关信息配置 ip route show # 显示系统路由 ip route add default via 192.168.1.254 # 设置系统默认路由 ip route list # 查看路由信息 ip route add 192.168.4.0/24 via 192.168.0.254 dev eth0 # 设置192.168.4.0网段的网关为192.168.0.254,数据走eth0接口 ip route add default via 192.168.0.254 dev eth0 # 设置默认网关为192.168.0.254 ip route del 192.168.4.0/24 # 删除192.168.4.0网段的网关 ip route del default # 删除默认路由 ip route delete 192.168.1.0/24 dev eth0 # 删除路由 ","date":"2024-03-03","objectID":"/2024-03-03/network/:2:1","tags":["linux","计算机网络"],"title":"Linux常用命令--网络篇","uri":"/2024-03-03/network/"},{"categories":["linux"],"content":"查看socket信息 我们可以使用 netstat​ 或者 ss​，这两个命令查看 socket、网络协议栈、网口以及路由表的信息。 两个命令都包含了 socket 的状态（State）、接收队列（Recv-Q）、发送队列（Send-Q）、本地地址（Local Address）、远端地址（Foreign Address）、进程 PID 和进程名称（PID/Program name）等。 接收队列（Recv-Q）和发送队列（Send-Q）比较特殊，在不同的 socket 状态。它们表示的含义是不同的。 当 socket 状态处于 Established​时： Recv-Q 表示 socket 缓冲区中还没有被应用程序读取的字节数； Send-Q 表示 socket 缓冲区中还没有被远端主机确认的字节数； 而当 socket 状态处于 Listen​ 时： Recv-Q 表示全连接队列的长度； Send-Q 表示全连接队列的最大长度； ","date":"2024-03-03","objectID":"/2024-03-03/network/:3:0","tags":["linux","计算机网络"],"title":"Linux常用命令--网络篇","uri":"/2024-03-03/network/"},{"categories":["linux"],"content":"netstat​ 基本信息展示 # -n 以数字方式显示ip与端口 # -l 只显示Listen状态的socket # -p 显示进程信息 ➜ ~ netstat -nlp (Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.) Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 127.0.0.1:34229 0.0.0.0:* LISTEN 9254/node tcp 0 0 127.0.0.1:45609 0.0.0.0:* LISTEN 9343/node tcp6 0 0 :::1313 :::* LISTEN 16288/hugo udp 0 0 127.0.0.1:323 0.0.0.0:* - udp6 0 0 ::1:323 :::* - Active UNIX domain sockets (only servers) Proto RefCnt Flags Type State I-Node PID/Program name Path unix 2 [ ACC ] STREAM LISTENING 26665 - /run/WSL/1_interop unix 2 [ ACC ] STREAM LISTENING 18869 - /run/WSL/1_interop unix 2 [ ACC ] STREAM LISTENING 20540 - /var/run/dbus/system_bus_socket unix 2 [ ACC ] SEQPACKET LISTENING 23571 - /mnt/wslg/weston-notify.sock unix 2 [ ACC ] STREAM LISTENING 17371 - /mnt/wslg/runtime-dir/wayland-0 unix 2 [ ACC ] STREAM LISTENING 17372 - /tmp/.X11-unix/X0 unix 2 [ ACC ] STREAM LISTENING 21543 - /mnt/wslg/runtime-dir/pulse/native unix 2 [ ACC ] STREAM LISTENING 85688 - /run/WSL/9165_interop unix 2 [ ACC ] STREAM LISTENING 495179 - /run/WSL/3624_interop unix 2 [ ACC ] STREAM LISTENING 522857 - /run/WSL/3633_interop unix 2 [ ACC ] STREAM LISTENING 21548 - /mnt/wslg/PulseServer unix 2 [ ACC ] STREAM LISTENING 23578 - /tmp/dbus-Q2X6vqhXOW unix 2 [ ACC ] STREAM LISTENING 80580 9343/node /mnt/wslg/runtime-dir/vscode-ipc-6af430c3-a503-4265-877e-5ab3f607f5a0.sock unix 2 [ ACC ] STREAM LISTENING 53922 9343/node /mnt/wslg/runtime-dir/vscode-git-33e3af7794.sock unix 2 [ ACC ] STREAM LISTENING 89624 9254/node /mnt/wslg/runtime-dir/vscode-ipc-ffd4384c-903f-4fff-af02-e9e3884a301b.sock unix 2 [ ACC ] STREAM LISTENING 89627 9254/node /mnt/wslg/runtime-dir/vscode-ipc-093af220-9378-437a-8879-fc47c92425a2.sock unix 2 [ ACC ] STREAM LISTENING 518896 - /mnt/wslg/PulseAudioRDPSource unix 2 [ ACC ] STREAM LISTENING 536065 - /mnt/wslg/PulseAudioRDPSink unix 2 [ ACC ] STREAM LISTENING 629995 - /run/WSL/16459_interop 查看协议栈统计信息 ​netstat​ 更为详细，显示了 TCP 协议的主动连接（active connections openings）、被动连接（passive connection openings）、失败重试（failed connection attempts）、发送（segments send out）和接收（segments received）的分段数量等各种信息。 ➜ ~ netstat -s Ip: Forwarding: 2 135347 total packets received 0 forwarded 0 incoming packets discarded 129806 incoming packets delivered 129703 requests sent out Icmp: 324 ICMP messages received 137 input ICMP message failed ICMP input histogram: destination unreachable: 263 echo requests: 33 echo replies: 28 365 ICMP messages sent 0 ICMP messages failed ICMP output histogram: destination unreachable: 299 echo requests: 33 echo replies: 33 IcmpMsg: InType0: 28 InType3: 263 InType8: 33 OutType0: 33 OutType3: 299 OutType8: 33 Tcp: 170 active connection openings 288 passive connection openings 3 failed connection attempts 77 connection resets received 7 connections established 137529 segments received 154330 segments sent out 15 segments retransmitted 0 bad segments received 266 resets sent Udp: 47 packets received 37 packets to unknown port received 0 packet receive errors 158 packets sent 0 receive buffer errors 0 send buffer errors IgnoredMulti: 674 UdpLite: TcpExt: 99 TCP sockets finished time wait in fast timer 6799 delayed acks sent 3 delayed acks further delayed because of locked socket Quick ack mode was activated 1109 times 38886 packet headers predicted 14754 acknowledgments not containing data payload received 62405 predicted acknowledgments TCPSackRecovery: 1 Detected reordering 6 times using SACK 1 congestion windows fully recovered without slow start TCPLostRetransmit: 8 2 fast retransmits TCPTimeouts: 12 TCPLossProbes: 2 TCPBacklogCoalesce: 250 TCPDSACKOldSent: 1109 TCPDSACKRecv: 1 73 connections reset due to unexpected data 4 connections reset due to early user close TCPSackShiftFallback: 5 TCPRcvCoalesce: 728 TCPOFOQueue: 63 TCPChallengeACK: 3 TCPSYNChallenge: 3 TCPAutoCorking: 182 TCPWan","date":"2024-03-03","objectID":"/2024-03-03/network/:3:1","tags":["linux","计算机网络"],"title":"Linux常用命令--网络篇","uri":"/2024-03-03/network/"},{"categories":["linux"],"content":"ss​ 查看基础信息 ➜ ~ ss -tnp State Recv-Q Send-Q Local Address:Port Peer Address:Port Process ESTAB 0 0 127.0.0.1:34229 127.0.0.1:34364 users:((\"node\",pid=9254,fd=23)) ESTAB 0 0 127.0.0.1:34364 127.0.0.1:34229 users:((\"node\",pid=3625,fd=18)) ESTAB 0 0 127.0.0.1:34229 127.0.0.1:34368 users:((\"node\",pid=9343,fd=21)) ESTAB 0 0 127.0.0.1:34368 127.0.0.1:34229 users:((\"node\",pid=3634,fd=18)) ESTAB 0 0 [::1]:59648 [::1]:1313 ESTAB 0 0 [::ffff:172.23.52.96]:1313 [::ffff:172.23.48.1]:55386 users:((\"hugo\",pid=16288,fd=12)) ESTAB 0 0 [::1]:1313 [::1]:59648 users:((\"hugo\",pid=16288,fd=9)) ➜ ~ 统计协议栈信息 ​ss​ 只显示已经连接（estab）、关闭（closed）、孤儿（orphaned） socket 等简要统计。 ➜ ~ ss -s Total: 120 TCP: 10 (estab 7, closed 0, orphaned 0, timewait 0) Transport Total IP IPv6 RAW 0 0 0 UDP 2 1 1 TCP 10 6 4 INET 12 7 5 FRAG 0 0 0 ➜ ~ ","date":"2024-03-03","objectID":"/2024-03-03/network/:3:2","tags":["linux","计算机网络"],"title":"Linux常用命令--网络篇","uri":"/2024-03-03/network/"},{"categories":["linux"],"content":"查看网络吞吐率和PPS ","date":"2024-03-03","objectID":"/2024-03-03/network/:4:0","tags":["linux","计算机网络"],"title":"Linux常用命令--网络篇","uri":"/2024-03-03/network/"},{"categories":["linux"],"content":"使用 sar​​ 获取网口统计信息 ➜ ~ sar -n DEV 1 Linux 5.15.133.1-microsoft-standard-WSL2 (pjm2001) 03/03/24 _x86_64_ (16 CPU) 17:20:57 IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s %ifutil 17:20:58 lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 17:20:58 eth0 1.00 0.00 0.21 0.00 0.00 0.00 1.00 0.00 17:20:58 IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s %ifutil 17:20:59 lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 17:20:59 eth0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 17:20:59 IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s %ifutil 17:21:00 lo 2.00 2.00 0.12 0.12 0.00 0.00 0.00 0.00 17:21:00 eth0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 17:21:00 IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s %ifutil 17:21:01 lo 4.00 4.00 0.24 0.24 0.00 0.00 0.00 0.00 17:21:01 eth0 1.00 1.00 0.04 0.04 0.00 0.00 0.00 0.00 ^C Average: IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s %ifutil Average: lo 1.50 1.50 0.09 0.09 0.00 0.00 0.00 0.00 Average: eth0 0.50 0.25 0.06 0.01 0.00 0.00 0.25 0.00 ➜ ~ ​rxpck/s​ 和 txpck/s​ 分别是接收和发送的 PPS，单位为包 / 秒。 ​rxkB/s​ 和 txkB/s​ 分别是接收和发送的吞吐率，单位是 KB/ 秒。 ​rxcmp/s​ 和 txcmp/s​ 分别是接收和发送的压缩数据包数，单位是包 / 秒。 ","date":"2024-03-03","objectID":"/2024-03-03/network/:4:1","tags":["linux","计算机网络"],"title":"Linux常用命令--网络篇","uri":"/2024-03-03/network/"},{"categories":["linux"],"content":"使用 ethtool​ 查询带宽 ➜ ~ ethtool eth0 Settings for eth0: Supported ports: [ ] Supported link modes: Not reported Supported pause frame use: No Supports auto-negotiation: No Supported FEC modes: Not reported Advertised link modes: Not reported Advertised pause frame use: No Advertised auto-negotiation: No Advertised FEC modes: Not reported Speed: 10000Mb/s Duplex: Full Port: Other PHYAD: 0 Transceiver: internal Auto-negotiation: off Cannot get wake-on-lan settings: Operation not permitted Current message level: 0x000000f7 (247) drv probe link ifdown ifup rx_err tx_err Link detected: yes ➜ ~ 可以看Speed​字段，该网卡为万兆网卡 ","date":"2024-03-03","objectID":"/2024-03-03/network/:4:2","tags":["linux","计算机网络"],"title":"Linux常用命令--网络篇","uri":"/2024-03-03/network/"},{"categories":["linux"],"content":"查看连通性与延时 使用 ping​ 命令 ➜ ~ ping baidu.com -c 5 PING baidu.com (110.242.68.66) 56(84) bytes of data. 64 bytes from 110.242.68.66 (110.242.68.66): icmp_seq=1 ttl=46 time=40.7 ms 64 bytes from 110.242.68.66 (110.242.68.66): icmp_seq=2 ttl=46 time=46.8 ms 64 bytes from 110.242.68.66 (110.242.68.66): icmp_seq=3 ttl=46 time=48.5 ms 64 bytes from 110.242.68.66 (110.242.68.66): icmp_seq=4 ttl=46 time=45.8 ms 64 bytes from 110.242.68.66 (110.242.68.66): icmp_seq=5 ttl=46 time=50.6 ms --- baidu.com ping statistics --- 5 packets transmitted, 5 received, 0% packet loss, time 4067ms rtt min/avg/max/mdev = 40.674/46.477/50.616/3.328 ms ➜ ~ 显示的内容主要包含 icmp_seq​（ICMP 序列号）、TTL​（生存时间，或者跳数）以及 time​ （往返延时），而且最后会汇总本次测试的情况，如果网络没有丢包，packet loss​ 的百分比就是 0。 不过，需要注意的是，ping​ 不通服务器并不代表 HTTP 请求也不通，因为有的服务器的防火墙是会禁用 ICMP 协议的。 ","date":"2024-03-03","objectID":"/2024-03-03/network/:5:0","tags":["linux","计算机网络"],"title":"Linux常用命令--网络篇","uri":"/2024-03-03/network/"},{"categories":["linux"],"content":"防火墙设置 要在 Linux 上禁用一个 IP 或者某个 TCP 端口，你可以使用防火墙软件，如 iptables​ 或者 firewalld​。 ","date":"2024-03-03","objectID":"/2024-03-03/network/:6:0","tags":["linux","计算机网络"],"title":"Linux常用命令--网络篇","uri":"/2024-03-03/network/"},{"categories":["linux"],"content":"使用 iptables： 禁用一个 IP： sudo iptables -A INPUT -s 目标IP -j DROP 这个命令将来自目标 IP 的所有入站流量直接丢弃，从而禁止了该 IP 的访问。 禁用某个 TCP 端口： sudo iptables -A INPUT -p tcp --dport 端口号 -j DROP 这个命令将来自指定 TCP 端口的所有入站流量直接丢弃，从而禁止了该端口的访问。 ","date":"2024-03-03","objectID":"/2024-03-03/network/:6:1","tags":["linux","计算机网络"],"title":"Linux常用命令--网络篇","uri":"/2024-03-03/network/"},{"categories":["linux"],"content":"使用 firewalld： 禁用一个 IP： sudo firewall-cmd --permanent --add-rich-rule='rule family=\"ipv4\" source address=\"目标IP\" drop' sudo firewall-cmd --reload 这个命令将来自目标 IP 的所有流量直接丢弃，从而禁止了该 IP 的访问。 禁用某个 TCP 端口： sudo firewall-cmd --permanent --add-port=端口号/tcp sudo firewall-cmd --reload 这个命令将来自指定 TCP 端口的所有流量直接丢弃，从而禁止了该端口的访问。 ","date":"2024-03-03","objectID":"/2024-03-03/network/:6:2","tags":["linux","计算机网络"],"title":"Linux常用命令--网络篇","uri":"/2024-03-03/network/"},{"categories":["linux"],"content":"介绍Linux常用系统状况相关的命令 ","date":"2024-03-03","objectID":"/2024-03-03/sysinfo/:0:0","tags":["linux"],"title":"Linux常用命令--系统篇","uri":"/2024-03-03/sysinfo/"},{"categories":["linux"],"content":"top​：Linux的任务管理器 ​-d delay​：设置更新频率，即指定刷新间隔的秒数。 例如：top -d 5​ 每隔 5 秒刷新一次。 ​-n iterations​：设置更新次数，即指定 top​ 命令将更新的次数后退出。 例如：top -n 3​ 更新 3 次后退出。 ​-b​：以批处理模式运行 top​，适用于输出到文件或管道中。 例如：top -b -n 1 \u003e top_output.txt​ 将输出一次 top​ 结果到文件中。 ​-u username​：只显示指定用户名的进程。 例如：top -u root​ 只显示 root​ 用户的进程。 ​-p pid[,pid...]​：只显示指定进程 ID 的进程。 例如：top -p 1234,5678​ 只显示进程 ID 为 1234​ 和 5678​ 的进程。 ​-o field1,field2,...​：设置默认排序字段，用逗号分隔。 例如：top -o %CPU​ 按 CPU 使用率排序。 ​-s​：累计模式，显示所有的重要信息并累计此后的信息。 例如：top -s​ 显示累计信息。 ​-h​：显示帮助信息，列出 top​ 命令的所有选项。 例如：top -h​ 显示帮助信息。 打开后，输入M：按使用内存排序 打开后，输入P：按使用CPU​排序 打开后，输入Q：退出 ","date":"2024-03-03","objectID":"/2024-03-03/sysinfo/:1:0","tags":["linux"],"title":"Linux常用命令--系统篇","uri":"/2024-03-03/sysinfo/"},{"categories":["linux"],"content":"htop​：top的升级版 ​-d seconds​：设置刷新频率，即指定更新间隔的秒数。 ​-C​：启用彩色输出，以区分不同的进程状态和资源使用情况。 ​-u username​：只显示指定用户名的进程。 ​-p pid[,pid...]​：只显示指定进程 ID 的进程。 ​-s​：安静模式，关闭实时更新，只显示当前快照的信息。 ​-t​：启用树状结构显示进程，显示进程及其子进程的关系。 ​-m​：显示内存信息。 ​-M​：按内存使用量进行排序。 ​-n​：启用数字输出模式，关闭彩色输出。 ​-H​：显示线程信息。 ​-i​：显示空闲进程。 ​-F​：强制使用 ASCII 字符输出。 ​-h​：显示帮助信息，列出 htop​ 命令的所有选项。 ","date":"2024-03-03","objectID":"/2024-03-03/sysinfo/:2:0","tags":["linux"],"title":"Linux常用命令--系统篇","uri":"/2024-03-03/sysinfo/"},{"categories":["linux"],"content":"ps​：查看进程信息 ​ -e： 显示所有进程。这包括与当前终端无关的进程。 ​ -f： 显示全格式输出。以完整的格式显示进程信息，包括进程的 UID、PID、PPID、C、STIME、TTY、TIME 等。 ​ -u username： 仅显示指定用户的进程。用于过滤出特定用户的进程信息。 ​ -p pid[,pid...] ​ ： 仅显示指定 PID 的进程。可以指定一个或多个 PID，用逗号分隔。 ​ -aux： 显示所有进程的详细信息。此参数结合了 -a​（显示所有用户的进程）、-u​（显示用户相关的详细信息）和 -x​（显示没有控制终端的进程）。 按 CPU 使用率排序： ps aux --sort=-%cpu 这将按照 CPU 使用率降序排序，即最高 CPU 使用率的进程排在前面。 按内存使用率排序： ps aux --sort=-%mem 这将按照内存使用率降序排序，即最高内存使用率的进程排在前面。 按进程 ID 排序： ps aux --sort=-pid 这将按照进程 ID 降序排序，即最大的进程 ID 的进程排在前面。 按启动时间排序： ps aux --sort=start_time 这将按照启动时间升序排序，即最早启动的进程排在前面。 按进程名排序： ps aux --sort=comm 这将按照进程名的字母顺序排序。 按命令行参数排序： ps aux --sort=cmd 这将按照进程的完整命令行参数进行排序。 其中STAT状态位常见的状态字符有: D：无法中断的休眠状态（通常 IO 的进程）； R：正在运行可中在队列中可过行的； S：处于休眠状态； T：停止或被追踪； W：进入内存交换 （从内核2.6开始无效）； X：死掉的进程 （基本很少见）； Z：僵尸进程； \u003c：优先级高的进程 N：优先级较低的进程 L：有些页被锁进内存； s：进程的领导者（在它之下有子进程）； l：多线程，克隆线程（使用 CLONE_THREAD, 类似 NPTL pthreads）； +：位于后台的进程组； ​ -ww： 不截断输出。在输出中不限制宽度，这样可以显示完整的命令行。 ​ -o format： 自定义输出格式。可以指定要显示的字段，如 pid,user,%cpu,%mem,command​。 ​ -N： 显示不匹配指定条件的进程。例如，ps -N java​ 将显示不包含 java​ 进程的所有进程。 ​ -L： 显示线程信息。显示线程相关的信息。 ​ -C command： 根据指定命令名过滤进程。例如，ps -C java​ 将显示所有名为 java​ 的进程。 ​ -k pid： 显示指定 PID 的进程以及其子进程。通常与 -L​ 参数一起使用，用于显示指定进程的所有线程。 ​ -h： 显示帮助信息。列出 ps​ 命令的所有选项。 ","date":"2024-03-03","objectID":"/2024-03-03/sysinfo/:3:0","tags":["linux"],"title":"Linux常用命令--系统篇","uri":"/2024-03-03/sysinfo/"},{"categories":["linux"],"content":"df​：查看磁盘使用信息 ​ -h： 以人类可读的格式显示磁盘空间信息，将字节、块等单位转换为 KB、MB、GB 等更易读的单位。 ​ -T： 显示文件系统的类型。 ​ -t type： 仅显示指定类型的文件系统，可以使用逗号分隔多个类型。 ​ -x type： 排除指定类型的文件系统。 ​ -i： 显示 inode 使用情况。 ​ --output： 自定义输出格式，可以指定要显示的字段。 ​ --total： 显示所有列的总和。 ​ -hT： 结合使用 -h​ 和 -T​ 参数，以人类可读的格式显示文件系统类型。 ​ --help： 显示帮助信息，列出 df​ 命令的所有选项。 ","date":"2024-03-03","objectID":"/2024-03-03/sysinfo/:4:0","tags":["linux"],"title":"Linux常用命令--系统篇","uri":"/2024-03-03/sysinfo/"},{"categories":["linux"],"content":"du​：查看目录占用磁盘信息 ​-h​：以人类可读的格式显示磁盘使用情况。 ​-s​：显示每个指定文件夹的总磁盘使用情况，而不显示其子文件夹的使用情况。 ​-a​：显示每个文件和目录的磁盘使用情况。 ​-c​：显示总磁盘使用情况，即所有文件和目录的总和。 ​-h --max-depth=N​：限制显示的目录层级，只显示指定深度的目录。 ​--exclude=PATTERN​：排除符合指定模式的文件或目录。 ​--max-depth=0​：只显示指定目录的总磁盘使用情况，不显示子目录的使用情况。 ​-b​：以字节为单位显示磁盘使用情况。 ​--help​：显示帮助信息，列出 du​ 命令的所有选项。 ","date":"2024-03-03","objectID":"/2024-03-03/sysinfo/:5:0","tags":["linux"],"title":"Linux常用命令--系统篇","uri":"/2024-03-03/sysinfo/"},{"categories":["linux"],"content":"free​：查看内存使用情况 ​-h​：以人类可读的格式显示内存使用情况，将字节、块等单位转换为 KB、MB、GB 等更易读的单位。 ​-b​：以字节为单位显示内存使用情况。 ​-m​：以 MB 为单位显示内存使用情况。 ​-g​：以 GB 为单位显示内存使用情况。 ​-t​：显示总内存使用情况，包括物理内存和交换空间。 ​-s INTERVAL​：连续显示内存使用情况，每隔指定的时间间隔刷新一次。 ​--help​：显示帮助信息，列出 free​ 命令的所有选项。 ","date":"2024-03-03","objectID":"/2024-03-03/sysinfo/:6:0","tags":["linux"],"title":"Linux常用命令--系统篇","uri":"/2024-03-03/sysinfo/"},{"categories":["linux"],"content":"netstat​：查看网络连接 ​-a​：显示所有连接和监听端口。 ​-t​：显示 TCP 协议的连接信息。 ​-u​：显示 UDP 协议的连接信息。 ​-n​：以数字格式显示 IP 地址和端口号，而不进行域名解析。 ​-p​：显示建立连接或监听的进程的 PID 和进程名称。 ​-l​：仅显示监听状态的连接。 ​-r​：显示路由表信息。 ​-s​：显示统计信息，包括各种协议的统计数据。 ​-c​：持续显示网络状态信息，类似于 top​ 命令的实时更新。 ​--help​：显示帮助信息，列出 netstat​ 命令的所有选项。 ","date":"2024-03-03","objectID":"/2024-03-03/sysinfo/:7:0","tags":["linux"],"title":"Linux常用命令--系统篇","uri":"/2024-03-03/sysinfo/"},{"categories":["linux"],"content":"uptime​：查看系统运行时间与负载情况 ➜ ~ uptime 13:44:01 up 8:22, 0 users, load average: 0.12, 0.05, 0.01 ","date":"2024-03-03","objectID":"/2024-03-03/sysinfo/:8:0","tags":["linux"],"title":"Linux常用命令--系统篇","uri":"/2024-03-03/sysinfo/"},{"categories":["linux"],"content":"ifconfig​：显示网络接口配置信息 ​ifconfig​ 命令用于配置和显示网络接口的信息。以下是一些常用的 ifconfig​ 命令参数： 无参数： 显示所有网络接口的信息。 ifconfig interface： 仅显示指定网络接口的信息。 ifconfig eth0 ​ -a： 显示所有网络接口的信息，包括未激活的接口。 ifconfig -a ​ up： 激活指定的网络接口。 ifconfig eth0 up ​ ​down： 禁用指定的网络接口。 ifconfig eth0 down ​netmask MASK： 设置指定网络接口的子网掩码。 ifconfig eth0 netmask 255.255.255.0 ​ promisc： 将指定网络接口设置为混杂模式，用于监听所有网络流量。 ifconfig eth0 promisc ​ -s： 显示摘要信息，列出每个网络接口的统计数据。 ifconfig -s ​ -v： 显示详细信息，包括版本信息。 ifconfig -v ​ -help或--help： 显示帮助信息，列出 ifconfig​ 命令的所有选项。 ifconfig --help ","date":"2024-03-03","objectID":"/2024-03-03/sysinfo/:9:0","tags":["linux"],"title":"Linux常用命令--系统篇","uri":"/2024-03-03/sysinfo/"},{"categories":["docker"],"content":"介绍容器相关的虚拟网络，如 veth、bridge、路由表、iptables ","date":"2024-03-02","objectID":"/2024-03-02/mydocker-6/:0:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第六章 容器虚拟网络","uri":"/2024-03-02/mydocker-6/"},{"categories":["docker"],"content":"1. Linux 虚拟网络设备 ","date":"2024-03-02","objectID":"/2024-03-02/mydocker-6/:1:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第六章 容器虚拟网络","uri":"/2024-03-02/mydocker-6/"},{"categories":["docker"],"content":"Linux Veth veth-pair 顾名思义，veth-pair 就是一对的虚拟设备接口，和 tap/tun 设备不同的是，它都是成对出现的。一端连着协议栈，一端彼此相连着。 一般用于跨 namespace 通信。 Linux 中默认不同 net namespace 设备无法通信。 网络命名空间 为了支持网络协议栈的多个实例，Linux 在网络栈中引入了网络命名空间。这些独立的协议栈被隔离到不同的命名空间中。 处理不同网络命令空间中的通信 ​ ​ Demo 本次演示中，先创建一个网络命名空间，然后创建一个 veth 设备对，将设备对分别切换到不同的命名空间中，实现不同命名空间的互相通信。 准备一个 net namespace root@pjm2001:~# ip netns add netns1 root@pjm2001:~# ip netns list netns1 root@pjm2001:~# 创建两个 Veth 设备对(ip link add \u003cveth name\u003e type veth peer name \u003cpeer\u003e​) root@pjm2001:~# ip link add veth0 type veth peer name veth1 root@pjm2001:~# ip link show 1: lo: \u003cLOOPBACK,UP,LOWER_UP\u003e mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 2: eth0: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000 link/ether 00:15:5d:c4:21:04 brd ff:ff:ff:ff:ff:ff 3: veth1@veth0: \u003cBROADCAST,MULTICAST,M-DOWN\u003e mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether aa:ed:e3:6e:27:4b brd ff:ff:ff:ff:ff:ff 4: veth0@veth1: \u003cBROADCAST,MULTICAST,M-DOWN\u003e mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether fe:2a:a9:3a:08:af brd ff:ff:ff:ff:ff:ff root@pjm2001:~# 此时两个 veth 都在默认 net namespace 中，为了测试，先将其中一个切换到 netns1 root@pjm2001:~# ip link set veth1 netns netns1 root@pjm2001:~# ip link show 1: lo: \u003cLOOPBACK,UP,LOWER_UP\u003e mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 2: eth0: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000 link/ether 00:15:5d:c4:21:04 brd ff:ff:ff:ff:ff:ff 4: veth0@if3: \u003cBROADCAST,MULTICAST\u003e mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether fe:2a:a9:3a:08:af brd ff:ff:ff:ff:ff:ff link-netns netns1 root@pjm2001:~# ip netns exec netns1 ip link show 1: lo: \u003cLOOPBACK\u003e mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 3: veth1@if4: \u003cBROADCAST,MULTICAST\u003e mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether aa:ed:e3:6e:27:4b brd ff:ff:ff:ff:ff:ff link-netnsid 0 root@pjm2001:~# 至此，两个不同的命名空间各自有一个 Veth，不过还不能通信，因为我们还没给它们分配 IP root@pjm2001:~# ip netns exec netns1 ip addr add 10.1.1.1/24 dev veth1 root@pjm2001:~# ip addr add 10.1.1.2/24 dev veth0 root@pjm2001:~# 再启动它们 root@pjm2001:~# ip netns exec netns1 ip link set dev veth1 up root@pjm2001:~# ip link set dev veth0 up root@pjm2001:~# 现在两个网络命名空间可以互相通信了 root@pjm2001:~# ping 10.1.1.1 PING 10.1.1.1 (10.1.1.1) 56(84) bytes of data. 64 bytes from 10.1.1.1: icmp_seq=1 ttl=64 time=0.166 ms 64 bytes from 10.1.1.1: icmp_seq=2 ttl=64 time=0.053 ms 64 bytes from 10.1.1.1: icmp_seq=3 ttl=64 time=0.051 ms ^C --- 10.1.1.1 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 2077ms rtt min/avg/max/mdev = 0.051/0.090/0.166/0.053 ms root@pjm2001:~# 至此，Veth 设备对的基本原理和用法演示结束。 Docker 内部，Veth 设备对也是连通容器与宿主机的主要网络设备。 查看对端设备 由于 Veth 设备对被移动到另一个命名空间后在当前命名空间中就看不到了。 那么该如何知道这个 Veth 设备的另一端在哪儿呢？ 可以使用 ethtool 工具来查看： root@pjm2001:~# ip netns exec netns1 ethtool -S veth1 NIC statistics: peer_ifindex: 4 rx_queue_0_xdp_packets: 0 rx_queue_0_xdp_bytes: 0 rx_queue_0_drops: 0 rx_queue_0_xdp_redirect: 0 rx_queue_0_xdp_drops: 0 rx_queue_0_xdp_tx: 0 rx_queue_0_xdp_tx_errors: 0 tx_queue_0_xdp_xmit: 0 tx_queue_0_xdp_xmit_errors: 0 root@pjm2001:~# peer_ifindex 就是另一端的接口设备的序列号，这里是 4。 然后在到默认命名空间取看 序列化 4 代表的是什么设备： root@pjm2001:~# ip link | grep ^4 4: veth0@if3: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000 root@pjm2001:~# 可以看到 序列号 4 的设备就是 veth0，它的另一端就是 netns1 中的 veth1，它们互为 peer。 ","date":"2024-03-02","objectID":"/2024-03-02/mydocker-6/:1:1","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第六章 容器虚拟网络","uri":"/2024-03-02/mydocker-6/"},{"categories":["docker"],"content":"Linux Bridge Bridge 虚拟设备是用来桥接的网络设备，它相当于现实世界中的交换机，可以连接不同的网络设备，当请求到达 Bridge 设备时，可以通过报文中的 Mac 地址进行广播或转发。 例如，我们可以创建一个 Bridge 设备来连接 Namespace 中的网络设备和宿主机上的网络。 root@pjm2001:~# ip netns add ns1 root@pjm2001:~# ip link add veth0 type veth peer name veth1 root@pjm2001:~# ip link set veth1 netns ns1 root@pjm2001:~# ip link 1: lo: \u003cLOOPBACK,UP,LOWER_UP\u003e mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 2: eth0: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000 link/ether 00:15:5d:c4:21:04 brd ff:ff:ff:ff:ff:ff 7: veth0@if6: \u003cBROADCAST,MULTICAST\u003e mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether 1e:f3:a4:95:47:79 brd ff:ff:ff:ff:ff:ff link-netns ns1 root@pjm2001:~# brctl addbr br0 root@pjm2001:~# brctl addif br0 eth0 root@pjm2001:~# brctl addif br0 veth0 root@pjm2001:~# brctl show br0 bridge name bridge id STP enabled interfaces br0 8000.00155dc42104 no eth0 veth0 root@pjm2001:~# linux bridge 实践 ​ ​ ","date":"2024-03-02","objectID":"/2024-03-02/mydocker-6/:1:2","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第六章 容器虚拟网络","uri":"/2024-03-02/mydocker-6/"},{"categories":["docker"],"content":"2. Linux 路由表 路由表是 Linux 内核的一个模块，通过定义路由表来决定在某个网络 Namespace 中包的流向，从而定义请求会到哪个网络设备上。 ​ ​ 继续以上面的例子演示 # 启动宿主机上的虚拟网络设备， root@pjm2001:~# ip link set veth0 up root@pjm2001:~# ip link set br0 up # 给ns1中的虚拟网络设备设置IP并启动它 root@pjm2001:~# ip netns exec ns1 ip addr add 172.18.0.2/24 dev veth1 root@pjm2001:~# ip netns exec ns1 ip link set dev veth1 up root@pjm2001:~# ip netns exec ns1 ip link show veth1 6: veth1@if7: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000 link/ether 16:94:1d:b5:77:bf brd ff:ff:ff:ff:ff:ff link-netnsid 0 # 分别设置ns1网络空间的路由和宿主机上的路由 # default代表0.0.0.0/0,即在Net Namespace中的所有流量都经过veth1的网络设备流出 root@pjm2001:~# ip netns exec ns1 route add default dev veth1 # 在宿主机上将172.18.0.0/24网段的请求路由到br0网桥 root@pjm2001:~# route add -net 172.18.0.0/24 dev br0 root@pjm2001:~# 通过设置路由，对 IP 地址的请求就能正确被路由到对应的网络设备上，从而实现通信，如下： # 查看宿主机的IP地址 root@pjm2001:~# ip addr show eth0 2: eth0: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc mq master br0 state UP group default qlen 1000 link/ether 00:15:5d:c4:21:04 brd ff:ff:ff:ff:ff:ff inet 172.23.52.96/20 brd 172.23.63.255 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::215:5dff:fec4:2104/64 scope link valid_lft forever preferred_lft forever # 从Namespace中访问宿主机的地址 root@pjm2001:~# ip netns exec ns1 ping -c 1 172.23.52.96 PING 172.23.52.96 (172.23.52.96) 56(84) bytes of data. 64 bytes from 172.23.52.96: icmp_seq=1 ttl=64 time=0.053 ms --- 172.23.52.96 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 0.053/0.053/0.053/0.000 ms root@pjm2001:~# # 从宿主机访问Namespace中的网络地址 root@pjm2001:~# ip netns exec ns1 ip addr show veth1 6: veth1@if7: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 16:94:1d:b5:77:bf brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.18.0.2/24 scope global veth1 valid_lft forever preferred_lft forever inet6 fe80::1494:1dff:feb5:77bf/64 scope link valid_lft forever preferred_lft forever root@pjm2001:~# ping -c 1 172.18.0.2 PING 172.18.0.2 (172.18.0.2) 56(84) bytes of data. 64 bytes from 172.18.0.2: icmp_seq=1 ttl=64 time=0.050 ms --- 172.18.0.2 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 0.050/0.050/0.050/0.000 ms root@pjm2001:~# 到此就实现了通过网桥连接不同 Namespace 网络了。 ","date":"2024-03-02","objectID":"/2024-03-02/mydocker-6/:2:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第六章 容器虚拟网络","uri":"/2024-03-02/mydocker-6/"},{"categories":["docker"],"content":"3. Linux iptables iptables 是对 Linux 内核的 netfilter 模块进行操作和展示的工具，用来管理包的流动和转送。iptables 定义了一套链式处理的结构，在网络包传输的各个阶段可以使用不同的策略对包进行加工、传送或丢弃。 在容器虚拟化的技术中，经常会用到两种策略 MASQUERADE 和 DNAT，用于容器和宿主机外部的网络通信。 ","date":"2024-03-02","objectID":"/2024-03-02/mydocker-6/:3:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第六章 容器虚拟网络","uri":"/2024-03-02/mydocker-6/"},{"categories":["docker"],"content":"MASQUERADE iptables 中的 MASQUERADE 策略可以将请求包中的源地址转换成一个网络设备的地址。 比如上述例子中的那个 Namespace 中网络设备的地址是 172.18.0.2, 这个地址虽然在宿主机上可以路由到 br0 网桥，但是到达宿主机外部之后，是不知道如何路由到这个 IP 地址的，所以如果要请求外部地址的话，需要先通过 MASQUERADE 策略将这个 IP 转换成宿主机出口网卡的 IP。 # 打开IP转发 root@pjm2001:~# sysctl -w net.ipv4.conf.all.forwarding=1 net.ipv4.conf.all.forwarding = 1 # 对Namespace中发出的包添加网络地址转换 root@pjm2001:~# iptables -t nat -A POSTROUTING -s 172.18.0.0/24 -o eth0 -j MAS QUERADE root@pjm2001:~# 在 Namespace 中请求宿主机外部地址时，将 Namespace 中的源地址转换成宿主机的地址作为源地址，就可以在 Namespace 中访问宿主机外的网络了。 ","date":"2024-03-02","objectID":"/2024-03-02/mydocker-6/:3:1","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第六章 容器虚拟网络","uri":"/2024-03-02/mydocker-6/"},{"categories":["docker"],"content":"DNAT iptables 中的 DNAT 策略也是做网络地址的转换，不过它是要更换目标地址，经常用于将内部网络地址的端口映射到外部去。 比如，上面那个例子中的 Namespace 如果需要提供服务给宿主机之外的应用去请求要怎么办呢? 外部应用没办法直接路由到 172.18.0.2 这个地址，这时候就可以用到 DNAT 策略。 # 将宿主机上80端口的请求转发到Namespace里的IP上 root@pjm2001:~# iptables -t nat -A PREROUTING -p tcp -m tcp --dport 80 -j DNAT --to-destination 172.18.0.2:80 root@pjm2001:~# 这样就可以把宿主机上 80 端口的 TCP 请求转发到 Namespace 中的地址 172.18.0.2:80,从而实现外部的应用调用。 ‍ ","date":"2024-03-02","objectID":"/2024-03-02/mydocker-6/:3:2","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第六章 容器虚拟网络","uri":"/2024-03-02/mydocker-6/"},{"categories":["docker"],"content":"4. 结尾 做完上述实验之后，记得恢复网络设置。 root@pjm2001:~# ip link delete veth0 root@pjm2001:~# ip link delete br0 root@pjm2001:~# ping github.com PING github.com (20.205.243.166) 56(84) bytes of data. 64 bytes from 20.205.243.166 (20.205.243.166): icmp_seq=1 ttl=100 time=236 ms 64 bytes from 20.205.243.166 (20.205.243.166): icmp_seq=2 ttl=100 time=233 ms ^C --- github.com ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 1266ms rtt min/avg/max/mdev = 233.168/234.758/236.349/1.590 ms root@pjm2001:~# ip netns delete ns1 ","date":"2024-03-02","objectID":"/2024-03-02/mydocker-6/:4:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第六章 容器虚拟网络","uri":"/2024-03-02/mydocker-6/"},{"categories":["blog"],"content":"纪念我本科的算法竞赛生涯 ","date":"2024-02-29","objectID":"/2024-02-29/acm/:0:0","tags":["ACM","blog","生活"],"title":"我那一路坎坷的ACM算法竞赛生涯","uri":"/2024-02-29/acm/"},{"categories":["blog"],"content":"初识算法竞赛 进入大学前的暑假，在 MOOC 上跟着浙江大学的翁恺老师学习了 C 语言。学完之后离开学还有些日子，还去尝试了浙江大学陈越姥姥的数据结构课（但由于当时非常的菜，没怎么听明白）。 一次偶然的机会，在网上刷到了关于计算机学生建议参加的竞赛，于是，算法竞赛走进了我的生活。 ","date":"2024-02-29","objectID":"/2024-02-29/acm/:1:0","tags":["ACM","blog","生活"],"title":"我那一路坎坷的ACM算法竞赛生涯","uri":"/2024-02-29/acm/"},{"categories":["blog"],"content":"我的大一 ","date":"2024-02-29","objectID":"/2024-02-29/acm/:2:0","tags":["ACM","blog","生活"],"title":"我那一路坎坷的ACM算法竞赛生涯","uri":"/2024-02-29/acm/"},{"categories":["blog"],"content":"我被我校 ACM 协会拒绝了 入学后，协会的招新信息没有通知到我所在的学院（经管学院）。百团大战那天，我很茫然的发现，ACM 协会并没有来，原来已经招过新了，不再补招，于是，我被 “拒绝” 了。 ","date":"2024-02-29","objectID":"/2024-02-29/acm/:2:1","tags":["ACM","blog","生活"],"title":"我那一路坎坷的ACM算法竞赛生涯","uri":"/2024-02-29/acm/"},{"categories":["blog"],"content":"我的第一场校赛 那是 2020 年的 CCCC 校赛选拔赛，只能做一些模拟题，水平是非常非常的有限，并且暑假后我并没有写过多少代码，好在暑假的代码量支撑我拿到了大一新生中的三等奖，同时获得了小礼品，一盏台灯。 但是呢，最终由于水平有限，未能入选。 ​ ​ ","date":"2024-02-29","objectID":"/2024-02-29/acm/:2:2","tags":["ACM","blog","生活"],"title":"我那一路坎坷的ACM算法竞赛生涯","uri":"/2024-02-29/acm/"},{"categories":["blog"],"content":"关于转专业 比赛后，我便专心投入到转专业的事情中，好在专业课没有拉跨，并且数学成绩优异，虽然面试的时候出现了一点小插曲（同时也导致现在也不喜欢当时面试我的老师），最后还是轻轻松松的转入了现在的专业，计算机科学与技术。并且报了校选修课课——算法优化，开始正式的踏上算法竞赛之路。 我开始跟着紫书（刘汝佳的《算法竞赛入门经典》）开始一步步学习算法，发现此书对我来说还是有点难度颇高了，但是其中的模拟题，对于当时的我来说，是真的使我的编码能力得到了很大的提高。 同时，也会偶尔参加 codeforces 的比赛，体验过掉分的痛苦，也体验过比赛时成功 AC 一题的惊喜。 期间和浙大宁波理工学院的朋友聊过是选择算法竞赛 or 数学建模，最后还是选择了算法竞赛，感谢胡向东同学的鼓励！ 在写这段内容时（2022.4.18），惊喜发现，在算法竞赛这条路上，我已经走了快一年了。 ​ ​ ","date":"2024-02-29","objectID":"/2024-02-29/acm/:2:3","tags":["ACM","blog","生活"],"title":"我那一路坎坷的ACM算法竞赛生涯","uri":"/2024-02-29/acm/"},{"categories":["blog"],"content":"我的第二场校赛 时间来到了 2021 年的 CCCC 校内选拔赛，经过前段时间的训练，能力上也有所增长，通过了选拔，并作为三队成员，参加了我的第一场真正的算法竞赛。 ","date":"2024-02-29","objectID":"/2024-02-29/acm/:2:4","tags":["ACM","blog","生活"],"title":"我那一路坎坷的ACM算法竞赛生涯","uri":"/2024-02-29/acm/"},{"categories":["blog"],"content":"2021CCCC 那天我们大一的学生，得去主校区参加比赛。早起坐上校车后，心里一直在幻想比赛的场景和主校区的风景。三个小时的比赛很快就过去了，最后成绩一般般，但是让我由衷的体会到了算法竞赛的魅力与快乐，更坚定的选择了算法竞赛这条道路。 ​ ​ ","date":"2024-02-29","objectID":"/2024-02-29/acm/:2:5","tags":["ACM","blog","生活"],"title":"我那一路坎坷的ACM算法竞赛生涯","uri":"/2024-02-29/acm/"},{"categories":["blog"],"content":"入选 ACM 集训队 虽然是入选了，但是校赛打的是极其的糟糕，最后凭借着经常的训练记录侥幸入选。 在暑假参加了杭电的中国大学生超级联赛和牛客网举办的暑期多校训练联盟，也报了 Acwing 的算法课，算法能力在这个暑假得到了巨大的提高。 ","date":"2024-02-29","objectID":"/2024-02-29/acm/:2:6","tags":["ACM","blog","生活"],"title":"我那一路坎坷的ACM算法竞赛生涯","uri":"/2024-02-29/acm/"},{"categories":["blog"],"content":"我的大二 ","date":"2024-02-29","objectID":"/2024-02-29/acm/:3:0","tags":["ACM","blog","生活"],"title":"我那一路坎坷的ACM算法竞赛生涯","uri":"/2024-02-29/acm/"},{"categories":["blog"],"content":"2021 ICPC 上海站 上海站于 2021 年 11 月 27-28 日举行，作为我人生中第一场 ICPC，紧张之余留有一丝期待，但是最终上海站过于神仙打架以及自身实力实在是过于薄弱，取得了一个一般般的成绩。 ​ ​ 我的第一场 ICPC 以打铁为结局。 赛时剪影 ​ ​ ​ ​ ​ ​​ ","date":"2024-02-29","objectID":"/2024-02-29/acm/:3:1","tags":["ACM","blog","生活"],"title":"我那一路坎坷的ACM算法竞赛生涯","uri":"/2024-02-29/acm/"},{"categories":["blog"],"content":"第十三届蓝桥杯 校赛 校赛本着随便进的心态，并没有很认真的去打，一个小时内就把除了最后一题的所有题目都做完了，最后实在想不出最后一题该如何下手，便提前离场。最后获得了校二等奖，殊不知，真正的厄运开始了。 ​ ​ 省赛 蓝桥杯省赛于 2022 年 4 月 9 日举行，此次蓝桥杯的题目质量明显提高，虽然有多道是原题，但是能感觉到蓝桥杯正在往高难度的方向去发展，而不是以往的“暴力杯”。最后由于进制大题实在谜语以及可能出现的其他错误，仅获得浙江省蓝桥杯 C++B 组二等奖，无缘国赛。 ","date":"2024-02-29","objectID":"/2024-02-29/acm/:3:2","tags":["ACM","blog","生活"],"title":"我那一路坎坷的ACM算法竞赛生涯","uri":"/2024-02-29/acm/"},{"categories":["blog"],"content":"浙江省第十九届大学生程序设计竞赛 浙江省赛于 2022 年 4 月 16 日举行，这场实话实说，运气占了很大一部分。我队过题速度快且罚时少，并且对于马拉车板子，在比赛时临场学会，一次通过。 本来省赛能摘一枚铜牌就知足了，实在没有料到，最后拿到了一块宝贵的银牌 🥈，并且拿了全校第一，全省本科组第 52 名的成绩。 ​ ​ ​ ​ ​ ","date":"2024-02-29","objectID":"/2024-02-29/acm/:3:3","tags":["ACM","blog","生活"],"title":"我那一路坎坷的ACM算法竞赛生涯","uri":"/2024-02-29/acm/"},{"categories":["blog"],"content":"2021 ICPC 昆明站 昆明站于 2022 年 4 月 17 日举行。谁又能想到省赛的第二天就是昆明站呢？对于昆明站，我队表现极差，虽说开局很快过掉了签到题，但是由于选题失误，浪费大量时间，错失了拿牌机会。 知耻而后勇吧 🙏 ​ ​ ","date":"2024-02-29","objectID":"/2024-02-29/acm/:3:4","tags":["ACM","blog","生活"],"title":"我那一路坎坷的ACM算法竞赛生涯","uri":"/2024-02-29/acm/"},{"categories":["blog"],"content":"第七届中国高校计算机大赛-团体程序设计天梯赛 天梯赛于 2022 年 4 月 23 日举行。本届天梯赛的题目质量也非常好，虽说比赛时一度想摆烂不打了，但是最后还是挺住了压力，拿到了人生的第一个算法竞赛国奖。所在团队的队友也十分给力，一起拿下了省二和国二。 ​ ​ ​​ ​​ ","date":"2024-02-29","objectID":"/2024-02-29/acm/:3:5","tags":["ACM","blog","生活"],"title":"我那一路坎坷的ACM算法竞赛生涯","uri":"/2024-02-29/acm/"},{"categories":["blog"],"content":"2022RoboCom 机器人开发者大赛 拿到了省二和国三！ ​​ ​​ ​ ","date":"2024-02-29","objectID":"/2024-02-29/acm/:3:6","tags":["ACM","blog","生活"],"title":"我那一路坎坷的ACM算法竞赛生涯","uri":"/2024-02-29/acm/"},{"categories":["blog"],"content":"总结大二 大二这一年，我实现了算法竞赛奖牌从零的突破。唯一不足的是并没有获得 金牌/一等奖/🥇 ，希望我的大三能够坚持下去，再接再厉。 ","date":"2024-02-29","objectID":"/2024-02-29/acm/:3:7","tags":["ACM","blog","生活"],"title":"我那一路坎坷的ACM算法竞赛生涯","uri":"/2024-02-29/acm/"},{"categories":["blog"],"content":"我的大三 ","date":"2024-02-29","objectID":"/2024-02-29/acm/:4:0","tags":["ACM","blog","生活"],"title":"我那一路坎坷的ACM算法竞赛生涯","uri":"/2024-02-29/acm/"},{"categories":["blog"],"content":"2022 ICPC 南京站 由于队伍调整，和一个当时在字节实习的学长一起组了队，打铁。当时校内出现了疫情，但是还是撑到了比赛开始。 ​ ​ ","date":"2024-02-29","objectID":"/2024-02-29/acm/:4:1","tags":["ACM","blog","生活"],"title":"我那一路坎坷的ACM算法竞赛生涯","uri":"/2024-02-29/acm/"},{"categories":["blog"],"content":"2022 ICPC 香港站 疫情放开，在学校打，太菜了还是 ​ ​ ","date":"2024-02-29","objectID":"/2024-02-29/acm/:4:2","tags":["ACM","blog","生活"],"title":"我那一路坎坷的ACM算法竞赛生涯","uri":"/2024-02-29/acm/"},{"categories":["blog"],"content":"浙江省第二十届大学生程序设计竞赛 ​ 第一次线下赛，在杭州师范大学，机房很大，但是电脑不是很好。自己是真的尽力了，唉，最遗憾的一局！ 开心的是见到了 east 和翁恺老师！！！追星成功 一些想分享的图片 ​ ​ ​ ​ ​​​​ ","date":"2024-02-29","objectID":"/2024-02-29/acm/:4:3","tags":["ACM","blog","生活"],"title":"我那一路坎坷的ACM算法竞赛生涯","uri":"/2024-02-29/acm/"},{"categories":["blog"],"content":"第八届中国高校计算机大赛-团体程序设计天梯赛 拿到了个人国三 🥉，和队友通力拿下国家金奖！🏅️ ​ ​ ​​ ","date":"2024-02-29","objectID":"/2024-02-29/acm/:4:4","tags":["ACM","blog","生活"],"title":"我那一路坎坷的ACM算法竞赛生涯","uri":"/2024-02-29/acm/"},{"categories":["blog"],"content":"第十四届蓝桥杯 浙江省一 🏅️，国二 🥈 ​ ​ ","date":"2024-02-29","objectID":"/2024-02-29/acm/:4:5","tags":["ACM","blog","生活"],"title":"我那一路坎坷的ACM算法竞赛生涯","uri":"/2024-02-29/acm/"},{"categories":["blog"],"content":"2023RAICOM 打了省二 🥈，晋级国赛。但是想不明白国赛为什么要在周五举办，由于上班，没有参加。 ","date":"2024-02-29","objectID":"/2024-02-29/acm/:4:6","tags":["ACM","blog","生活"],"title":"我那一路坎坷的ACM算法竞赛生涯","uri":"/2024-02-29/acm/"},{"categories":["blog"],"content":"总结 大三一年，ICPC 全铁，浙江省赛打铁，天梯赛金银铜，蓝桥杯饮马国二，RAICOM 由于个人事务没有参加国赛。 共计 🏅️x2，🥈x3，🥉x1。 ","date":"2024-02-29","objectID":"/2024-02-29/acm/:4:7","tags":["ACM","blog","生活"],"title":"我那一路坎坷的ACM算法竞赛生涯","uri":"/2024-02-29/acm/"},{"categories":["blog"],"content":"我的大四 ","date":"2024-02-29","objectID":"/2024-02-29/acm/:5:0","tags":["ACM","blog","生活"],"title":"我那一路坎坷的ACM算法竞赛生涯","uri":"/2024-02-29/acm/"},{"categories":["blog"],"content":"2023 ICPC 合肥站（退役） 前情提要：打这场时作者已经上了六个月的班，基本上训练是荒废了。 第一次线下 ICPC，去了合肥中科大 3 天（旅游的很开心 ​ ​ Day 1 周五直接在七牛请假，坐了下午的高铁直奔合肥，入住中科大旁的汉庭酒店之后就在合肥逛了逛，在合肥大街上狂蹬共享单车，时速可能超过了 25km/h，严重违反新国标 🤣 去了罍街、总理故居、包公园、逍遥津和一个不知道名字的步行街。最后在商场里，狂飙卡丁车（狠狠的套了小学生的圈！！！） ​ Day 2 这天是热身赛，上午在中科大徒步越野，下午电脑前疯狂热身。 刚好之前集训队有学长考研考到了中科大，热身赛结束之后，我们便联系了学长，一起吃了铜锅羊肉，晚上继续在中科大越野徒步。刚好中科大发的校园卡里面钱用不光，就请学长吃了一顿中科大烧烤 hhhh 中科大真的很大，也很有名校的氛围，少年班、第一教学楼、孺子牛、郭沫若像、红专路，那少年的梦，在此刻又触动了内心深处。 ​ Day 3 比赛日。 不出意外的我们打的很烂，而且由于太菜，评测机的 bug，整场下来非常的不顺利。喜提铁牌。 比赛完之后，释然的似了，笑了。对于过往的比赛，一切都如云烟散去，就像如今的经济环境一样，大学生毕业找不到工作一般。一千万的应届大学生，在这场经济下行的危机中，逐渐丧失了原来的梦。 当然，也没有辜负最后在中科大的时光，我与队友逛了中科大没有去过的角落，校史馆，校门口。 当日晚，于合肥南站败逃回杭（雀魂，启动！ ​ 一些想展示的照片 ​ ​ ​​ ​​ ​ ​ ​ ​​​ ","date":"2024-02-29","objectID":"/2024-02-29/acm/:5:1","tags":["ACM","blog","生活"],"title":"我那一路坎坷的ACM算法竞赛生涯","uri":"/2024-02-29/acm/"},{"categories":["blog"],"content":"2024 天梯赛 天梯赛在 2024.4.20 举行。是我本科阶段的最后一场算法竞赛。 这次有所突破，打了 226 分，拿了个人国二，以及团队省二国二。 ","date":"2024-02-29","objectID":"/2024-02-29/acm/:5:2","tags":["ACM","blog","生活"],"title":"我那一路坎坷的ACM算法竞赛生涯","uri":"/2024-02-29/acm/"},{"categories":["blog"],"content":"结束 至此，我的算法竞赛生涯就结束了。 从大一错过了 ACM 协会的招新，到成为了集训队主力，最后于中科大退役。 算法竞赛带给我的不仅仅是代码逻辑上能力的提升，还有集训队同仁之间的友谊，这是无比珍贵的。 方行，方毓乔，袁辰洋，杨之川…… 在我算法竞赛的路上有同仁一起刷题训练的时光，是我本科生活富有色彩的一笔。 有你，幸会。 ","date":"2024-02-29","objectID":"/2024-02-29/acm/:6:0","tags":["ACM","blog","生活"],"title":"我那一路坎坷的ACM算法竞赛生涯","uri":"/2024-02-29/acm/"},{"categories":["git"],"content":"同步目录下 git 项目到 github，实现自动化创建仓库，自动化上传 ","date":"2024-02-29","objectID":"/2024-02-29/sync_git_porject/:0:0","tags":["shell","git"],"title":"使用shell脚本同步git项目至github","uri":"/2024-02-29/sync_git_porject/"},{"categories":["git"],"content":"0. 预先准备 Github Token 打开GitHub Token New页面，勾选repo​ 选项，如下图所示 ​ ​ 拉至页面最下面，生成 Token，最后复制该 Token，保存好 ​ ​ 切换分支 把需要同步的 git 项目迁移到同一个文件夹内，并且把这些项目的 git 分支使用git checkout [branch]​ 命令切换到开发的主分支上，并且保证暂存区无修改内容。 ","date":"2024-02-29","objectID":"/2024-02-29/sync_git_porject/:1:0","tags":["shell","git"],"title":"使用shell脚本同步git项目至github","uri":"/2024-02-29/sync_git_porject/"},{"categories":["git"],"content":"1. 代码 在需要同步的目录下，新建一个 shell 文件，名为sync_git_project.sh​，代码内容如下： #!/bin/bash user='' # 填入github用户名 github_token='' # 填入上一步生成的token # 遍历文件夹下的目录 for file in * do file_path=`pwd` dir_name=\"$file_path/$file\" # 判断是否为目录 if test -d $dir_name; then # 是否为git项目 if test -d \"$dir_name/.git\"; then echo $file cd $file git stash git pull # 创建远程私有github仓库 # API：https://docs.github.com/zh/rest/repos/repos?apiVersion=2022-11-28#create-a-repository-for-the-authenticated-user if ! git remote -v | grep git@github.com:$user/$file.git; then curl -L -s \\ -X POST \\ -H \"Accept: application/vnd.github+json\" \\ -H \"Authorization: Bearer $github_token\" \\ -H \"X-GitHub-Api-Version: 2022-11-28\" \\ https://api.github.com/user/repos \\ -d \"{\\\"name\\\":\\\"$file\\\",\\\"private\\\":true}\" \\ --compressed # 添加remote git remote set-url --add origin git@github.com:$user/$file.git fi # 上传 git push git stash pop echo \"$file upload complete\\n\" cd .. fi fi done ","date":"2024-02-29","objectID":"/2024-02-29/sync_git_porject/:2:0","tags":["shell","git"],"title":"使用shell脚本同步git项目至github","uri":"/2024-02-29/sync_git_porject/"},{"categories":["git"],"content":"2. 运行 在终端执行下面的命令，即可同步项目至 github bash sync_git_project.sh 等待一段时间后，可以发现目录内的 git 项目已全部同步至 github，并且如果之前没有该 repo，也自动创建了。 ","date":"2024-02-29","objectID":"/2024-02-29/sync_git_porject/:3:0","tags":["shell","git"],"title":"使用shell脚本同步git项目至github","uri":"/2024-02-29/sync_git_porject/"},{"categories":["docker"],"content":"使用 Go 实现容器的进阶操作 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-5/:0:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第五章 构建容器进阶","uri":"/2024-02-26/mydocker-5/"},{"categories":["docker"],"content":"实现容器后台运行 在 Docker 早期版本，所有的容器 init 进程都是从 docker daemon 这个进程 fork 出来的，这也就会导致一个众所周知的问题，如果 docker daemon 挂掉，那么所有的容器都会宕掉，这给升级 docker daemon 带来很大的风险。 后来，Docker 使用了 containerd， 也就是现在的 runC，便可以实现即使 daemon 挂掉，容器依然健在的功能了，其结构如下图所示。 ​ ​ 我们并不想去实现一个 daemon,因为这和容器的关联不是特别大，而且，查看 Docker 的运行引擎 runC 可以发现，runC 也提供一.种 detach 功能，可以保证在 runC 退出的情况下容器依然可以运行。因此，我们将会使用 detach 功能去实现创建完成容器后，mydocker 就会退出,但是容器依然继续运行的功能。 容器，在操作系统看来，其实就是一个进程。当前运行命令的 mydocker 是主进程，容器是被当前 mydocker 进程 fork 出来的子进程。子进程的结束和父进程的运行是一个异步的过程，即父进程永远不知道子进程到底什么时候结束。如果创建子进程的父进程退出，那么这个子进程就成了没人管的孩子，俗称孤儿进程。为了避免孤儿进程退出时无法释放所占用的资源而僵死，进程号为 1 的 init 进程就会接受这些孤儿进程。 这就是父进程退出而容器进程依然运行的原理。虽然容器刚开始是由当前运行的 mydocker 进程创建的，但是当 mydocker 进程退出后，容器进程就会被进程号为 1 的 init 进程接管，这时容器进程还是运行着的，这样就实现了 mydocker 退出、容器不宕掉的功能。 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-5/:1:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第五章 构建容器进阶","uri":"/2024-02-26/mydocker-5/"},{"categories":["docker"],"content":"实现查看存在的容器 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-5/:2:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第五章 构建容器进阶","uri":"/2024-02-26/mydocker-5/"},{"categories":["docker"],"content":"记录容器的 info ​ ​ ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-5/:2:1","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第五章 构建容器进阶","uri":"/2024-02-26/mydocker-5/"},{"categories":["docker"],"content":"ps 命令执行流程 ​ ​ ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-5/:2:2","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第五章 构建容器进阶","uri":"/2024-02-26/mydocker-5/"},{"categories":["docker"],"content":"实现查看容器的日志 一般来说，对于容器中运行的进程，使日志达到标准输出是一个非常好的实现方案，因此需要将容器中的标准输出保存下来，以便需要的时候访问。 我们就以此作为思路来实现 mydocker logs 命令。 我们会将容器进程的标准输出挂载到/var/run/mydocker/容器名/container.log\"​ 文件中，这样就可以在调用 mydocker logs 的时候去读取这个文件，并将进程内的标准输出打印出来。 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-5/:3:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第五章 构建容器进阶","uri":"/2024-02-26/mydocker-5/"},{"categories":["docker"],"content":"实现进入容器 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-5/:4:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第五章 构建容器进阶","uri":"/2024-02-26/mydocker-5/"},{"categories":["docker"],"content":"setns 加入对应的 Namespace 很简单，Linux 提供了 setns 系统调用给我们使用。 setns 是一个系统调用，可以根据提供的 PID 再次进入到指定的 Namespace 中。它需要先打开/proc/[pid/ns/​ 文件夹下对应的文件，然后使当前进程进入到指定的 Namespace 中。 但是用 Go 来实现则存在一个致命问题：setns 调用需要单线程上下文，而 GoRuntime 是多线程的。 准确的说是 MountNamespace。 为了解决该问题，我们只能在 Go Runtime 启动之前，执行 setns 调用。 要实现这种提前调用，可以利用 cgo 的 constructor 技巧，该技巧能够在 Go Runtime 启动之前，执行一个任意的 C 函数。 runC 中的 nsenter 也是借助 cgo 实现的。 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-5/:4:1","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第五章 构建容器进阶","uri":"/2024-02-26/mydocker-5/"},{"categories":["docker"],"content":"Cgo Cgo 是一个很炫酷的功能，允许 Go 程序去调用 C 的函数与标准库。你只需要以一种特殊的方式在 Go 的源代码里写出需要调用的 C 的代码，Cgo 就可以把你的 C 源码文件和 Go 文件整合成一个包。 下面举一个最简单的例子，在这个例子中有两个函数一 Random 和 Seed,在 它们里面调用了 C 的 random 和 srandom 函数。 package nsenter /* #include \u003cerrno.h\u003e #include \u003csched.h\u003e #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cstring.h\u003e #include \u003cfcntl.h\u003e __attribute__((constructor)) void enter_namespace(void) { // 这里的代码会在Go运行时启动前执行，它会在单线程的C上下文中运行 char *mydocker_pid; mydocker_pid = getenv(\"mydocker_pid\"); if (mydocker_pid) { // fprintf(stdout, \"got mydocker_pid=%s\\n\", mydocker_pid); } else { // fprintf(stdout, \"missing mydocker_pid env skip nsenter\"); // 如果没有指定PID就不需要继续执行，直接退出 return; } char *mydocker_cmd; mydocker_cmd = getenv(\"mydocker_cmd\"); if (mydocker_cmd) { // fprintf(stdout, \"got mydocker_cmd=%s\\n\", mydocker_cmd); } else { // fprintf(stdout, \"missing mydocker_cmd env skip nsenter\"); // 如果没有指定命令也是直接退出 return; } int i; char nspath[1024]; // 需要进入的5种namespace char *namespaces[] = { \"ipc\", \"uts\", \"net\", \"pid\", \"mnt\" }; for (i=0; i\u003c5; i++) { // 拼接对应路径，类似于/proc/pid/ns/ipc这样 sprintf(nspath, \"/proc/%s/ns/%s\", mydocker_pid, namespaces[i]); int fd = open(nspath, O_RDONLY); // 执行setns系统调用，进入对应namespace if (setns(fd, 0) == -1) { //fprintf(stderr, \"setns on %s namespace failed: %s\\n\", namespaces[i], strerror(errno)); } else { //fprintf(stdout, \"setns on %s namespace succeeded\\n\", namespaces[i]); } close(fd); } // 在进入的Namespace中执行指定命令，然后退出 int res = system(mydocker_cmd); exit(0); return; } */ import \"C\" 这段代码导入了一个叫 C 的包，但是你会发现在 Go 标准库里面并没有这个包，那是因为这根本就不是一个真正的包，而只是 Cgo 创建的一个特殊命名空间，用来与 C 的命名空间交流。 可以看到，这段程序还是很怪异的，和普通的 Go 代码是不一样的。这里主要使用了构造函数，然后导入了 C 模块，一旦这个包被引用，它就会在所有 Go 运行的环境启动之前执行，这样就避免了 Go 多线程导致的无法进入 mnt Namespace 的问题。这段程序执行完毕后，Go 程序才会执行。 但是这会带来一个问题，就是只要这个包被导入，它就会在所有 Go 代码前执行，那么即使那些不需要使用 exec 这段代码的地方也会运行这段程序。 举例来说，使用 mydocker run 来创建容器，但是这段 C 代码依然会执行，这就会影响前面已经完成的功能。因此，在这段 C 代码前面一开始的位置就添加了环境变量检测，没有对应的环境变量时，就直接退出。对于不使用 exec 功能的 Go 代码，只要不设置对应的环境变量，这段 C 代码就不会运行，这样就不会影响原来的逻辑。 注意：只有在你的 Go 应用程序中注册、导入了这个包，才会调用这个构造函数。 就像这样： import ( _ \"mydocker/nsenter\" ) 使用 cgo 我们无法直接获取传递给程序的参数，可用的做法是，通过 go exec 创建一个自身运行进程，然后通过传递环境变量的方式，传递给 cgo 参数值。 体现在 runc 中就是 runc create → runc init​ ，runc 中有很多细节，他通过环境变量传递 netlink fd，然后进行通信。 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-5/:4:2","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第五章 构建容器进阶","uri":"/2024-02-26/mydocker-5/"},{"categories":["docker"],"content":"实现停止容器 主要就是查找到它的主进程 PID,然后发送 SIGTERM 信号，等待进程结束就好。 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-5/:5:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第五章 构建容器进阶","uri":"/2024-02-26/mydocker-5/"},{"categories":["docker"],"content":"实现删除容器 主要是文件操作，因为容器对应的进程已经被停止，所以只需要将对应记录文件信息的目录删除即可。 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-5/:6:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第五章 构建容器进阶","uri":"/2024-02-26/mydocker-5/"},{"categories":["docker"],"content":"实现根据容器构造镜像 之前容器都是用的 /root/merged 目录作为自己的 rootfs，当启动多个容器时可写层会互相影响。 所以，本节要实现如下两个目的。 1）为每个容器分配单独的隔离文件系统。 2）修改 mydocker commit 命令，实现对不同容器进行打包镜像的功能。 3）修改 mydocker rm 命令，删除容器时顺带删除文件系统 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-5/:7:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第五章 构建容器进阶","uri":"/2024-02-26/mydocker-5/"},{"categories":["docker"],"content":"实现隔离文件系统 改动点： 1）runCommand 命令中添加 imageName 作为第一个参数输入 相关方法都要增加相关参数 containerInfo 增加对应字段 2）rootfs 相关目录定义成变量，不在固定写死。 3）文件系统相关操作抽取出来，单独放到 volume.go 文件中 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-5/:7:1","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第五章 构建容器进阶","uri":"/2024-02-26/mydocker-5/"},{"categories":["docker"],"content":"实现指定环境变量运行 exec 命令其实是 mydocker 发起 的另外一个进程，这个进程的父进程其实是宿主机的，并不是容器内的。因为在 Cgo 里面使用了 setns 系统调用，才使得这个进程进入到了容器内的命名空间，但是由于环境变量是继承自父进程的，因此这个 exec 进程的环境变量其实是继承自宿主机的，所以在 exec 进程内看到的环境变量其实是宿主机的环境变量。 但是，只要是容器内 PID 为 1 的进程，创建出来的进程都会继承它的环境变量。下面修改 exec 命令来直接使用 env 命令查看容器内环境变量的功能。 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-5/:8:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第五章 构建容器进阶","uri":"/2024-02-26/mydocker-5/"},{"categories":["docker"],"content":"小结 本章实现了容器操作的基本功能。 首先实现了容器的后台运行，然后将容器的状态在文件系统上做了存储。 通过这些存储信息，又可以实现列出当前容器信息的功能。 并且， 基于后台运行的容器，我们可以去手动停止容器，并清除掉容器的存储信息。 最后修改了上一章镜像的存储结构，使得多个容器可以并存，且存储的内容互不干扰。 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-5/:9:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第五章 构建容器进阶","uri":"/2024-02-26/mydocker-5/"},{"categories":["docker"],"content":"使用 Go 实现简易 Docker Images ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-4/:0:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第四章 构造镜像","uri":"/2024-02-26/mydocker-4/"},{"categories":["docker"],"content":"使用 busybox 创建容器 准备 rootfs：将运行中的 busybox 容器导出并解压后作为 rootfs 挂载 rootfs：使用pivotRoot​ 系统调用，将前面准备好的目录作为容器的 rootfs 使用 在切换 rootfs 之后，容器就实现了和宿主机的文件系统隔离。 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-4/:1:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第四章 构造镜像","uri":"/2024-02-26/mydocker-4/"},{"categories":["docker"],"content":"实现原理 使用 ​pivot_root系统调用来切换整个系统的 rootfs，配合上 /root/busybox​ 来实现一个类似镜像的功能。 ​其中pivot_root​ 是一个系统调用，主要功能是去改变当前的 root 文件系统。 原型如下： #include \u003cunistd.h\u003e int pivot_root(const char *new_root, const char *put_old); ​new_root​：新的根文件系统的路径。 ​put_old​：将原根文件系统移到的目录。 使用 pivot_root​ 系统调用后，原先的根文件系统会被移到 put_old​ 指定的目录，而新的根文件系统会变为 new_root​ 指定的目录。这样，当前进程就可以在新的根文件系统中执行操作。 注意：new_root 和 put_old 不能同时存在当前 root 的同一个文件系统中。 pivotroot 和 chroot 有什么区别？ pivot_root 是把整个系统切换到一个新的 root 目录，会移除对之前 root 文件系统的依赖，这样你就能够 umount 原先的 root 文件系统。 而 chroot 是针对某个进程，系统的其他部分依旧运行于老的 root 目录中。 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-4/:1:1","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第四章 构造镜像","uri":"/2024-02-26/mydocker-4/"},{"categories":["docker"],"content":"基于 overlayfs 实现写操作隔离 https://www.lixueduan.com/posts/docker/09-ufs-overlayfs/ overlayfs 一般分为 lower、upper、merged 和 work 4 个目录。 lower 只读层，该层数据不会被修改 upper 可读写层，所有修改都发生在这一层，即使是修改的 lower 中的数据。 merged 视图层，可以看到 lower、upper 中的所有内容 work 则是 overlayfs 内部使用 使用我们的镜像目录(busybox 目录) 作为 lower 目录，这样可以保证镜像内容被修改。 merged 目录由于可以看到全部内容，因此作为容器 rootfs 目录，即 pivotRoot 会切换到 merged 目录。 upper 目录则是用于保存容器中的修改，因为 overlayfs 中所有修改都会发生在这里。 overlayfs 引入具体流程如下： 1）自动解压 busybox.tar 到 busybox 作为 lower 目录，类似 docker 镜像层 2）容器启动前准备好 lower、upper、work、merged 目录并 mount 到 merged 目录 3）容器启动后使用 pivotRoot 将 rootfs 切换到 merged 目录 后续容器中的修改由于 overlayfs 的特性，都会发生在 upper 目录中，而不会影响到 lower 目录 4）容器停止后 umount 并移除 upper、work、merged 目录 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-4/:2:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第四章 构造镜像","uri":"/2024-02-26/mydocker-4/"},{"categories":["docker"],"content":"实现 volume 数据卷挂载(持久化数据) ​bind mount​ 是一种将一个目录或者文件系统挂载到另一个目录的技术。它允许你在文件系统层级中的不同位置共享相同的内容，而无需复制文件。 ​mount -o bind /host/directory/ /container/directory/​ 这样容器中往该目录里写的数据最终会共享到宿主机上，从而实现持久化。 首先要理解 linux 中的 bind mount 功能。 ​bind mount​ 是一种将一个目录或者文件系统挂载到另一个目录的技术。它允许你在文件系统层级中的不同位置共享相同的内容，而无需复制文件。 其次，则是要理解宿主机目录和容器目录之间的关联关系。 以 -v /root/volume:/tmp​ 参数为例： 1）按照语法，-v /root/volume:/tmp​ 就是将宿主机/root/volume​ 挂载到容器中的 /tmp​ 目录。 2）由于前面使用了 pivotRoot 将 /root/merged​ 目录作为容器的 rootfs，因此，容器中的根目录实际上就是宿主机上的 /root/merged​ 目录 3）那么容器中的 /tmp​ 目录就是宿主机上的 /root/merged/tmp​ 目录。 4）因此，我们只需要将宿主机/root/volume​ 目录挂载到宿主机的 /root/merged/tmp​ 目录即可实现 volume 挂载。 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-4/:3:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第四章 构造镜像","uri":"/2024-02-26/mydocker-4/"},{"categories":["docker"],"content":"实现 commit 打包容器为镜像 由于之前使用 pivotRoot + overlayfs 技术 将 /root/merged​ 目录作为容器的 rootfs，因此容器中的所有改动都发生在该目录下。 这里我们的 **mydocker commit**​ 命令只需要把该目录保存下来即可，因此简单实现为 使用 tar 命令将​ **/root/merged**​ 目录打成 tar 包 ​ ​ ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-4/:4:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第四章 构造镜像","uri":"/2024-02-26/mydocker-4/"},{"categories":["docker"],"content":"推荐阅读: https://www.lixueduan.com/posts/docker/mydocker/04-change-rootfs-by-pivot-root https://www.lixueduan.com/posts/docker/mydocker/05-isolate-operate-by-overlayfs https://www.lixueduan.com/posts/docker/mydocker/06-volume-by-bind-mount https://www.lixueduan.com/posts/docker/mydocker/07-mydocker-commit ‍ ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-4/:5:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第四章 构造镜像","uri":"/2024-02-26/mydocker-4/"},{"categories":["docker"],"content":"通过使用 Go 实现简易 Docker Conatiner 开发中使用到的第三方包： go get github.com/urfave/cli go get github.com/sirupsen/logrus ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-3/:0:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第三章 构造容器","uri":"/2024-02-26/mydocker-3/"},{"categories":["docker"],"content":"Linux proc 文件系统 ​/proc ​ 文件系统由内核提供，包含系统运行时的信息，只存在与内存中。 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-3/:1:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第三章 构造容器","uri":"/2024-02-26/mydocker-3/"},{"categories":["docker"],"content":"实现 run 命令 ​syscall.Exec ​ 是最为重要的一句黑魔法，正是这个系统调用实现了完成初始化动作并将用户进程运行起来的操作。 首先，使用 Docker 创建起来一个容器之后，会发现容器内的第一个程序，也就是 PID 为 1 的那个进程，是指定的前台进程。但是，我们知道容器创建之后，执行的第一个进程并不是用户的进程，而是 init 初始化的进程。 这时候，如果通过 ps 命令查看就会发现，容器内第一个进程变成了自己的 init,这和预想的是不一样的。 有没有什么办法把自己的进程变成 PID 为 1 的进程呢？ 这里 execve 系统调用就是用来做这件事情的。 syscall.Exec 这个方法，其实最终调用了 Kernel 的 int execve(const char *filename, char *const argv[], char *const envp[]); ​ 这个系统函数。它的作用是执行当前 filename 对应的程序,它会覆盖当前进程的镜像、数据和堆栈等信息，包括 PID，这些都会被将要运行的进程覆盖掉。 也就是说，调用这个方法，将用户指定的进程运行起来，把最初的 init 进程给替换掉，这样当进入到容器内部的时候，就会发现容器内的第一个程序就是我们指定的进程了。 这其实也是目前 Docker 使用的容器引擎 runC 的实现方式之一。 ➜ my-docker git:(ch3) ✗ go build . ➜ my-docker git:(ch3) ✗ ls README.md container docs go.mod go.sum main.go main_command.go mydocker run.go test ➜ my-docker git:(ch3) ✗ sudo ./mydocker run -it /bin/sh [sudo] password for pjm: {\"level\":\"info\",\"msg\":\"[initCommand] init comeon\",\"time\":\"2024-02-16T22:11:03+08:00\"} {\"level\":\"info\",\"msg\":\"[initCommand] init command /bin/sh\",\"time\":\"2024-02-16T22:11:03+08:00\"} {\"level\":\"info\",\"msg\":\"command /bin/sh\",\"time\":\"2024-02-16T22:11:03+08:00\"} # ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 22:11 pts/6 00:00:00 /bin/sh root 6 1 0 22:11 pts/6 00:00:00 ps -ef # ls README.md container docs go.mod go.sum main.go main_command.go mydocker run.go test 由于没有 chroot ，所以目前的系统文件系统是继承自父进程的。 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-3/:2:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第三章 构造容器","uri":"/2024-02-26/mydocker-3/"},{"categories":["docker"],"content":"小结 /proc/self/exe：调用自身 init 命令，初始化容器环境 ​/proc/self/exe​ 是 Linux 系统中的一个符号链接，它指向当前进程的可执行文件。 这个路径是一个虚拟路径，实际上并不对应于文件系统中的一个文件，而是通过 /proc 文件系统提供的一种方式来访问进程相关的信息。 具体而言，/proc/self 是一个指向当前进程自身的符号链接，而 exe 则是一个特殊的文件，通过这个文件可以访问当前进程的可执行文件。 因此，/proc/self/exe 实际上是当前进程可执行文件的路径。 也就是说在 mydocker run 命令中执行的 /proc/self/exe init 实际上最终执行的是 mydocker init，即 run 命令会调用 init 命令来初始化容器环境。 tty：实现交互 当用户指定 -it 参数时，就将 cmd 的输入和输出连接到终端，以便我们可以与命令进行交互，并看到命令的输出。 Namespace 隔离：通过在 fork 时指定对应 Cloneflags 来实现创建新 Namespace fork 新进程时，通过指定 Cloneflags 会创建对应的 Namespace 以实现隔离，这里包括 UTS（主机名）、PID（进程 ID）、挂载点、网络、IPC 等方面的隔离。 proc 隔离：通过重新 mount /proc 文件系统来实现进程信息隔离 /proc 文件系统是一个虚拟的文件系统，提供了对内核和运行中进程的信息的访问。通过挂载 /proc，系统中的许多信息和控制接口可以通过文件的形式在这个目录下找到。 例如，你可以通过 /proc 查看系统的一些信息，如进程列表、内存使用情况、CPU 信息等。 例如: ➜ ~ ls /proc 1 36011 83329 bus diskstats ioports kpagecount mounts stat version 144 4 83330 cgroups dma irq kpageflags mtrr swaps vmallocinfo 145 54 83331 cmdline driver kallsyms loadavg net sys vmstat 160 55 94546 config.gz execdomains kcore locks pagetypeinfo sysvipc zoneinfo 161 56 94547 consoles filesystems key-users mdstat partitions thread-self 35427 76282 94548 cpuinfo fs keys meminfo schedstat timer_list 35428 76283 acpi crypto interrupts kmsg misc self tty 35429 76284 buddyinfo devices iomem kpagecgroup modules softirqs uptime ➜ ~ 而在容器环境中，为了和宿主机的 /proc 环境隔离，因此在 mydocker init​ 命令中我们会重新挂载 /proc 文件系统，即： defaultMountFlags := syscall.MS_NOEXEC | syscall.MS_NOSUID | syscall.MS_NODEV _ = syscall.Mount(\"proc\", \"/proc\", \"proc\", uintptr(defaultMountFlags), \"\") 对应的 mount 命令为: mount -t proc proc /proc​ 而当前进程在 fork 时指定了 syscall.CLONE_NEWPID​ 等等标记，因此是在新的 Namespace 中的，那就意味着看不到宿主机上的进程信息，那么重新挂载后的 /proc 文件系统自然也就只有当前 Namespace 下的进程信息。 这也就是为什么在容器中执行 ps 命令只能看到容器中的进程信息 execve 系统调用：使用指定进程覆盖 init 进程 execve 系统调用用于取代当前进程的映像（即，当前进程的可执行文件），并用一个新的程序来替代。 原型如下： int execve(const char *filename, char *const argv[], char *const envp[); ​filename​ 参数指定了要执行的新程序的文件路径。 ​argv​ 参数是一个字符串数组，包含了新程序的命令行参数。数组的第一个元素通常是新程序的名称，随后的元素是命令行参数。 ​envp​ 参数是一个字符串数组，包含了新程序执行时使用的环境变量。 execve 的工作方式是加载指定的程序文件，并将它替代当前进程的内存映像。因此，执行 execve 后，原进程的代码、数据等内容都会被新程序的内容替代。 即：它的作用是执行当前 filename 对应的程序,它会覆盖当前进程的镜像、数据和堆栈等信息，包括 PID，这些都会被将要运行的进程覆盖掉。 在 Go 中的调用方式为 syscall.Exe​。 通过该系统调用，可以使用用户指定的命令启动新进程来覆盖 mydocker 进程作为容器环境中的 PID 1 进程。 即：在 init 命令中解析拿到用户指定的命令并通过 syscall.Exe​ 使用该命令创建新进程来覆盖 mydocker 进程。 这也就是为什么我们执行 mydocker run -it /bin/sh​ 后 sh 会成为 PID 1 进程。 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-3/:2:1","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第三章 构造容器","uri":"/2024-02-26/mydocker-3/"},{"categories":["docker"],"content":"运行流程 ​ ​ 1）流程开始，用户手动执行 mydocker run 命令 2）urfave/cli 工具解析传递过来的参数 3）解析完成后发现第一个参数是 run，于是执行 run 命令，调用 runCommand 方法，该方法中继续调用 NewParentProcess 函数构建一个 cmd 对象 4）NewParentProcess 将构建好的 cmd 对象返回给 runCommand 方法 5）runCommand 方法中调用 cmd.exec 执行上一步构建好的 cmd 对象 6）容器启动后，根据 cmd 中传递的参数，/proc/self/exe init 实则最终会执行 mydocker init 命令，初始化容器环境 7）init 命令内部实现就是通过 mount 命令挂载 proc 文件系统 8）容器创建完成，整个流程结束 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-3/:2:2","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第三章 构造容器","uri":"/2024-02-26/mydocker-3/"},{"categories":["docker"],"content":"优化: 使用匿名管道传递参数 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-3/:3:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第三章 构造容器","uri":"/2024-02-26/mydocker-3/"},{"categories":["docker"],"content":"存在的问题 如果用户输入参数特别长，或者里面有一些特殊字符时该方案就会失效。 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-3/:3:1","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第三章 构造容器","uri":"/2024-02-26/mydocker-3/"},{"categories":["docker"],"content":"什么是匿名管道 匿名管道是一种特殊的文件描述符，用于在父进程和子进程之间创建通信通道。 有以下特点： 管道有一个固定大小的缓冲区，一般是 4KB。 这种通道是单向的，即数据只能在一个方向上流动。 当管道被写满时，写进程就会被阻塞，直到有读进程把管道的内容读出来。 同样地，当读进程从管道内拿数据的时候，如果这时管道的内容是空的，那么读进程同样会被阻塞，一直等到有写进程向管道内写数据。 因此，匿名管道在进程间通信中很有用，可以使一个进程的输出成为另一个进程的输入，从而实现进程之间的数据传递。 为什么选择匿名管道？ 我们这个场景正好也是父进程和子进程之间传递数据，而且也是单向的，只会从父进程传递给子进程，因此正好使用匿名管道来实现。 返回的两个 FD 一个代表管道的读端，另一个代表写端。 我们只需要把 readPipe FD 告知子进程，writePipe FD 告知父进程即可完成通讯。父进程将参数写入到 writePipe 后，子进程即可从 readPipe 中读取到。 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-3/:3:2","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第三章 构造容器","uri":"/2024-02-26/mydocker-3/"},{"categories":["docker"],"content":"具体实现 整个实现分为两个部分： FD 传递 首先在父进程里创建一个匿名管道,父进程就可以拿到 writepipe 的 fd. 现在需要将 readpipe fd 告知子进程,将 readPipe 作为 ExtraFiles，这样 cmd 执行时就会外带着这个文件句柄去创建子进程。 数据读写 父进程写数据 由于父进程天然就能拿到 writePipe FD，因此只需要在合适的时候将数据写入管道即可。 何为合适的时候？ 虽然匿名管道自带 4K 缓冲，但是如果写满之后就会阻塞，因此最好是等子进程启动后，再往里面写，尽量避免意外情况。 因此，合适的时候就是指子进程启动之后。 如果未启动子进程就往管道中写，写完了再启动子进程，大部分情况下也可以，但是如果 cmd 大于 4k 就会导致永久阻塞。 因为子进程未启动，管道中的数据永远不会被读取，因此会一直阻塞。 对应到代码中，也就是 parent.Start()​ 之后，等子进程启动后就通过 writePipe FD 将命令写入到管道中。 子进程读数据 子进程这边就麻烦一点，包含以下两步： 1）获取 readPipe FD 2）读取数据 子进程启动后，首先要找到前面通过ExtraFiles​ 传递过来的 readPipe FD，然后才是数据读取， 子进程 fork 出来后，执行到readUserCommand​ 函数就会开始读取参数，此时如果父进程还没有开始发送参数，根据管道的特性，子进程会阻塞在这里，一直到父进程发送数据过来后子进程才继续执行下去。 ​ ​ 父进程创建匿名管道，得到 readPiep FD 和 writePipe FD； 父进程中构造 cmd 对象时通过ExtraFiles​ 将 readPiep FD 传递给子进程 父进程启动子进程后将命令通过 writePipe FD 写入子进程 子进程中根据 index 拿到对应的 readPipe FD 子进程中 readPipe FD 中读取命令并执行 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-3/:3:3","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第三章 构造容器","uri":"/2024-02-26/mydocker-3/"},{"categories":["docker"],"content":"增加容器资源限制 mydocker run 命令增加对应 flag 实现统一 CgroupsManager 实现各个 Subsystem 容器创建、停止时调用对应方法配置 cgroup ​ ​ ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-3/:4:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第三章 构造容器","uri":"/2024-02-26/mydocker-3/"},{"categories":["docker"],"content":"遇到的问题 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-3/:5:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第三章 构造容器","uri":"/2024-02-26/mydocker-3/"},{"categories":["docker"],"content":"fork/exec /proc/self/exe: no such file or directory​ 第二次运行 mydocker 时会报错: ➜ my-docker git:(ch3) sudo ./mydocker run -it /bin/ls [sudo] password for pjm: {\"level\":\"info\",\"msg\":\"[initCommand] init comeon\",\"time\":\"2024-02-16T22:24:59+08:00\"} {\"level\":\"info\",\"msg\":\"[initCommand] init command /bin/ls\",\"time\":\"2024-02-16T22:24:59+08:00\"} {\"level\":\"info\",\"msg\":\"command /bin/ls\",\"time\":\"2024-02-16T22:24:59+08:00\"} README.md container docs go.mod go.sum main.go main_command.go mydocker run.go test ➜ my-docker git:(ch3) sudo ./mydocker run -it /bin/ls [sudo] password for pjm: {\"level\":\"error\",\"msg\":\"run fail, fork/exec /proc/self/exe: no such file or directory\",\"time\":\"2024-02-16T22:25:06+08:00\"} ➜ my-docker git:(ch3) 这个是因为代码中会将容器进程的 proc 信息挂载为 proc 文件系统，具体代码如下： defaultMountFlags := syscall.MS_NOEXEC | syscall.MS_NOSUID | syscall.MS_NODEV _ = syscall.Mount(\"proc\", \"/proc\", \"proc\", uintptr(defaultMountFlags), \"\") 这部分代码会在 mydocker init 中执行，也就是说实际上是在容器进程中执行的 mount，当我们的 mydocker 进程运行结束退出后，容器进程就消失了。 而在引入了 systemd 之后的 linux 中，mount namespace 是 shared by default，也就是说宿主机上的 /proc 目录也被影响了。 即：宿主机 /proc 目录的内容依旧是运行 mydocker 时的信息，而此时因为 mydocker 已经退出了，对应的进程信息自然就不存在了，所以会在执行 mydocker run 中的 /proc/self/exe​ 这个命令时出现这个错误。 解决方案 临时: 手动执行一次 mount,重新挂载/proc 目录 sudo mount -t proc proc /proc 永久: 将 mount 事件显式指定为 private 即可避免挂载事件外泄，这样就不会破坏宿主机 /proc 目录数据了。 // systemd 加入linux之后, mount namespace 就变成 shared by default, 所以你必须显示声明你要这个新的mount namespace独立。 // 即 mount proc 之前先把所有挂载点的传播类型改为 private，避免本 namespace 中的挂载事件外泄。 // 把所有挂载点的传播类型改为 private，避免本 namespace 中的挂载事件外泄。 _ = syscall.Mount(\"\", \"/\", \"\", syscall.MS_PRIVATE|syscall.MS_REC, \"\") // 如果不先做 private mount，会导致挂载事件外泄，后续再执行 mydocker 命令时 /proc 文件系统异常 // 可以执行 mount -t proc proc /proc 命令重新挂载来解决 defaultMountFlags := syscall.MS_NOEXEC | syscall.MS_NOSUID | syscall.MS_NODEV _ = syscall.Mount(\"proc\", \"/proc\", \"proc\", uintptr(defaultMountFlags), \"\") ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-3/:5:1","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第三章 构造容器","uri":"/2024-02-26/mydocker-3/"},{"categories":["docker"],"content":"推荐阅读： https://www.lixueduan.com/posts/docker/mydocker/01-mydocker-run/ https://www.lixueduan.com/posts/docker/mydocker/02-passing-param-by-pipe/ https://www.lixueduan.com/posts/docker/mydocker/03-resource-limit-by-cgroups/ ‍ ‍ ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-3/:6:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第三章 构造容器","uri":"/2024-02-26/mydocker-3/"},{"categories":["docker"],"content":"介绍 Docker 核心所用到的 Linux API ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-2/:0:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第二章 基础技术","uri":"/2024-02-26/mydocker-2/"},{"categories":["docker"],"content":"Linux Namespace 可以隔离一系列系统资源，例如 PID、UID、Network。 chroot 隔离文件: chroot 的用法 作用：改变进程的根目录，使它不能访问该目录之外的其他文件。即切换进程的 rootfs 常用命令 chroot 常见管理 namespace 的 API clone()：传递特定的 flag(CLONE_NEW*)标志给 clone()，则会根据每个标志创建对应新的 namespace 并且将子进程添加为其的成员。 setns()：允许一个进程加入一个已存在的 namespace 中。 unshare()：移出某个 Namespace，允许进程取消其执行的上下文，可以利用此系统调用让当前进程移动到一个新的 namespace 中。（unshare –pid: Unshare the pid namespace） execv()：在子进程中运行一个新的程序 当前 Linux 一共实现了 6 种不同类型的 Namespace Namespace 类型 系统调用参数 Mount Namespace CLONE_NEWNS UTS Namespace CLONE_NEWUTS IPC Namespace CLONE_NEWIPC PID Namespace CLONE_NEWPID Network Namespace CLONE_NEWNET User Namespace CLONE_NEWUSER ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-2/:1:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第二章 基础技术","uri":"/2024-02-26/mydocker-2/"},{"categories":["docker"],"content":"UTS Namespace 用来隔离 hostname 和 domain name。在 UTS Namespace 里，每个 Namespace 允许有自己的 hostname。 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-2/:1:1","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第二章 基础技术","uri":"/2024-02-26/mydocker-2/"},{"categories":["docker"],"content":"IPC Namespace 隔离进程间通信资源，即隔离 System V IPC 和 POSIX message queues。使用ipcs -q验证。 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-2/:1:2","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第二章 基础技术","uri":"/2024-02-26/mydocker-2/"},{"categories":["docker"],"content":"PID Namespace 用来隔离进程 ID，echo $$显示当前 pid 为 1，但是不能用 ps 或 top 命令，因为这些命令使用/proc 里的内容。 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-2/:1:3","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第二章 基础技术","uri":"/2024-02-26/mydocker-2/"},{"categories":["docker"],"content":"Mount Namespace 用于隔离各个进程看到的挂载点视图，不同 namespace 的进程中，看到的文件层次是不一样的。在 Mount Namespace 中，调用mount()和umount()仅仅会影响当前 namespace 内的文件系统，对全局的文件系统不会造成影响。 mount 和 umount 是 Linux 系统中用于挂载和卸载文件系统的命令。 mount 命令 mount 命令用于将文件系统挂载到指定的挂载点上，其基本语法为： mount [options] \u003cdevice\u003e \u003cmountpoint\u003e 其中： \u003cdevice\u003e：表示要挂载的设备或文件系统的路径，可以是硬盘分区、软件 RAID 设备、CD-ROM 等。 \u003cmountpoint\u003e：表示挂载的目标路径，也就是文件系统挂载的位置。 mount 命令的主要作用包括： 将文件系统挂载到指定的挂载点上，使得文件系统中的内容可以被访问。 可以通过不同的选项对挂载的行为进行配置，比如读写权限、文件系统类型等。 umount 命令 umount 命令用于卸载已经挂载的文件系统，其基本语法为： umount \u003cmountpoint\u003e 其中： \u003cmountpoint\u003e：表示已经挂载的文件系统的挂载点。 umount 命令的主要作用是将指定挂载点上的文件系统卸载，使得该挂载点上的内容不再可见，并释放相关资源。 使用示例 挂载一个设备到指定挂载点： mount /dev/sdb1 /mnt 这会将 /dev/sdb1​ 分区挂载到 /mnt​ 目录上。 使用选项挂载一个文件系统： mount -t ext4 /dev/sdc1 /mnt 这会将 /dev/sdc1​ 分区以 ext4 文件系统类型挂载到 /mnt​ 目录上。 卸载一个已挂载的文件系统： umount /mnt 这会将 /mnt​ 目录上的文件系统卸载。 这条命令 mount -t proc proc /proc​ 的作用是将虚拟文件系统 proc 挂载到系统中的 /proc​ 目录上。 具体而言，这个命令完成了以下几个作用： ​-t proc​ 指定了挂载的文件系统类型为 proc，即虚拟文件系统 proc。proc 文件系统是一个特殊的文件系统，它不存储在磁盘上，而是在内存中由内核动态创建的，用于提供进程信息和内核信息等。 ​proc​ 是要挂载的文件系统的源，通常在 Linux 中，虚拟文件系统 proc 不需要一个实际的设备来挂载，因此通常直接写 proc​。 ​/proc​ 是挂载点，也就是挂载操作的目标路径。在 Linux 系统中，/proc​ 目录用于向用户和用户空间程序提供关于系统内核和进程的信息。挂载 proc 文件系统到 /proc​ 目录后，可以通过 /proc​ 目录来访问和获取系统内核和进程的各种信息。 因此，这条命令的作用是将 Linux 内核提供的 proc 文件系统挂载到系统中的 /proc​ 目录，以便用户和程序可以通过 /proc​ 目录来查看和获取关于系统内核和进程的信息。 这些命令对于管理 Linux 系统中的文件系统非常重要，能够方便地实现文件系统的挂载和卸载操作。 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-2/:1:4","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第二章 基础技术","uri":"/2024-02-26/mydocker-2/"},{"categories":["docker"],"content":"User Namespace 主要用来隔离用户的用户组 ID，非 root 用户可以在自己创建的 User Namespace 里拥有 root 权限。使用id命令进行验证。 ​ ​ ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-2/:1:5","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第二章 基础技术","uri":"/2024-02-26/mydocker-2/"},{"categories":["docker"],"content":"Network Namespace 用来隔离网络设备、IP 地址端口。使 Namespace 拥有独立的网络设备。运行ifconfig​ 没有任何网络设备。 ​ ​ ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-2/:1:6","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第二章 基础技术","uri":"/2024-02-26/mydocker-2/"},{"categories":["docker"],"content":"Linux Cgroups Ubuntu 安装 cgroup：sudo apt install cgroup-tools 全称 Control Group，对子系统提供精细化的控制能力，例如 cpu、内存、io、网络。 基于 cgroup virtual filesystem，这个系统文件一般挂载在 /sys/fs/cgroup 目录下。 通过将 pid 加入到对应cgroup.procs​，即可对进程所拥有的资源进行限制。 ​ ​ cgroup 提供cpu.cfs_quota_us和cpu.cfs_period_us两个参数限制 CPU 占用的上限。 cpu.cfs_quota_us: 运行周期，单位为微秒，默认 100,000us，即 100ms。 cpu.cfs_quota_us: 运行周期内这个 cgroup 组所有进程可运行的时间总量，单位为微秒，默认值为-1，即不设置上限。 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-2/:2:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第二章 基础技术","uri":"/2024-02-26/mydocker-2/"},{"categories":["docker"],"content":"cgroup 的三个组件： Subsystem（子系统） ： 子系统是 cgroups 的核心组件之一，用于控制和管理特定类型的资源。每个子系统负责监控和限制一种或多种资源，如 CPU、内存、磁盘 I/O、网络带宽等。不同的子系统对应不同的资源类型，例如，cpu 子系统用于限制 CPU 使用量，memory 子系统用于限制内存使用量，blkio 子系统用于限制磁盘 I/O 等。通过配置 cgroups 中的子系统，可以为进程组分配和限制资源的使用。 Hierarchy（层级） ： 层级是 cgroups 中的一个概念，用于组织和管理 cgroups。一个 cgroups 层级可以包含多个 cgroups 组，并且可以为每个 cgroups 组分配一定数量的资源。每个 cgroups 层级由一个或多个子系统组成，这些子系统共同为 cgroups 中的进程组提供资源控制。层级可以以树状结构组织，每个层级都有一个顶层的根节点。 Control Interface（控制接口） ： 控制接口是用户用于管理 cgroups 的接口，它允许用户创建、修改、删除 cgroups，并设置相应的资源限制和参数。通过控制接口，用户可以在运行时动态地管理 cgroups，实现对进程组资源的有效控制和管理。控制接口通常通过文件系统暴露，用户可以通过文件系统操作来管理 cgroups。常见的控制接口包括在 /sys/fs/cgroup 或 /sys/fs/cgroup/\u003csubsystem\u003e 下的文件和目录。 三者之间的关系 系统创建新的 hierarchy，系统中所有的进程都会加入这个 hierarchy 的 cgroup 根节点，这个根节点由 hierarchy 默认创建。 一个 subsystem 只能附加在一个 hierarchy 上 一个 hierarchy 可以附加多个 subsystem 一个进程可以作为多个 cgroup 成员，但是这些 cgroup 必须在不同的 hierarchy 中 一个进程 fork 出子进程时，子进程与父进程在同一个 cgroup 里，也可以迁移到其他 cgroup 中 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-2/:2:1","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第二章 基础技术","uri":"/2024-02-26/mydocker-2/"},{"categories":["docker"],"content":"Kernel 接口 创建并挂载一个 hierarchy（cgroup 树） mkdir cgroups-test sudo mount -t cgroups -o none,name=cgroups-test cgroups-test ./cgroups-test ​ ​ 在根节点上扩展出两个子 cgroup cd cgroups-test sudo mkdir cgroups-1 sudo mkdir cgroups-2 ​ ​ 在 cgroup 中添加和移动进程 echo $$ cat /proc/$$/cgroups sudo sh -c \"echo $$ \u003e cgroup-1/tasks\" cat /proc/$$/cgroups 执行这段命令可以发现进程 76284 被加到了 cgroup-test:/cgroup-1 中 ​ ​ 通过 subsystem 限制 cgroup 的资源 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-2/:2:2","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第二章 基础技术","uri":"/2024-02-26/mydocker-2/"},{"categories":["docker"],"content":"Docker 如何使用 Cgroups？ docker 为每个容器创建 cgroup，并通过 cgroup 去配置资源限制和资源监控 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-2/:2:3","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第二章 基础技术","uri":"/2024-02-26/mydocker-2/"},{"categories":["docker"],"content":"Union File System Union File System，简称 UnionFS，是把其他文件系统联合到一个联合挂载点的文件系统服务。unionfs 用到了一个重要的资源管理技术，叫写时复制。 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-2/:3:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第二章 基础技术","uri":"/2024-02-26/mydocker-2/"},{"categories":["docker"],"content":"AUFS AUFS 重写了早期的 UnionFS1.x，改进了可靠性与性能。 image Layer 与 AUFS Image Layer（镜像层） ： Docker 镜像是由多个层组成的，每个镜像层都是一个只读的文件系统快照，包含了一组文件和目录。每个镜像层都有一个唯一的标识符，通常是基于其内容的哈希值。镜像层之间通过父子关系连接，使得 Docker 可以有效地共享和重用相同的文件系统层。当创建一个新的镜像时，Docker 会根据 Dockerfile 中的指令（比如 RUN、COPY、ADD 等）创建新的层，并在其上叠加已有的层，形成一个新的镜像。 image layer 与 AUFS 是如何通过共享文件和文件夹实现镜像存储的？ Image Layer（镜像层）和 AUFS（Another Union File System）通过共享文件和文件夹的方式来实现镜像存储和管理的。 在 Docker 中，当创建一个新的镜像时，Docker 会根据 Dockerfile 中的指令逐步构建镜像，并生成一系列的镜像层。每个镜像层都包含了一组文件和目录的快照。这些文件和目录可以是通过 RUN​、COPY​、ADD​ 等指令添加到镜像中的。 AUFS 提供了一种联合挂载的技术，允许将多个只读的镜像层和一个可写的容器层组合在一起，形成一个完整的容器文件系统。AUFS 将这些不同的层叠加在一起，形成一个逻辑的文件系统视图。对于容器内的操作，AUFS 会根据层的优先级和可写性，选择相应的层来执行读取和写入操作。 在 AUFS 中，镜像层之间通过共享文件和文件夹来实现存储的。具体来说，AUFS 使用了一种称为写时复制（copy-on-write）的技术。当容器需要修改一个文件或目录时，AUFS 不会直接修改原始的文件或目录，而是创建一个副本并将修改写入副本中。这样做的好处是，多个容器可以共享相同的只读镜像层，而不会相互影响，从而节省存储空间和提高效率。 container layer 与 AUFS Container Layer（容器层） ： 容器层是 Docker 容器的可写文件系统层，用于存储容器运行时产生的文件和目录，以及容器内部的变化。当您在容器中创建、修改或删除文件时，这些更改都会记录在容器层中。容器层使得 Docker 可以实现容器的状态隔离和持久化，即使容器被删除，容器层中的数据也可以被保留下来。 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-2/:3:1","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第二章 基础技术","uri":"/2024-02-26/mydocker-2/"},{"categories":["docker"],"content":"关于环境配置、docker 简介以及 Go 相关的使用 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-1/:0:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第一章 容器与开发语言","uri":"/2024-02-26/mydocker-1/"},{"categories":["docker"],"content":"环境配置： 操作系统：Ubuntu 20.04.3 LTS 内核版本：5.15.133.1-microsoft-standard-WSL2 Go version：go1.22.0 linux/amd64 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-1/:1:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第一章 容器与开发语言","uri":"/2024-02-26/mydocker-1/"},{"categories":["docker"],"content":"Docker 特点：轻量级（共享内核）、开放、安全（将不同的应用隔离起来） 与虚拟机比较：都有资源隔离与分配的能力，由于共享操作系统的内核，所以容器更加便携与高效 优点：加速开发效率，利用容器合作开发，使开发人员不用担心配置环境的问题。 WSL 环境 docker 使用：WSL 上的 Docker 容器入门 | Microsoft Learn ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-1/:2:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第一章 容器与开发语言","uri":"/2024-02-26/mydocker-1/"},{"categories":["docker"],"content":"GO golang 安装：Download and install - The Go Programming Language WSL 环境使用 Goland 开发：使用 WSL 环境在 Goland 中开发 Go 项目 - 掘金 ","date":"2024-02-26","objectID":"/2024-02-26/mydocker-1/:3:0","tags":["docker"],"title":"《自己动手写docker》阅读笔记--第一章 容器与开发语言","uri":"/2024-02-26/mydocker-1/"},{"categories":[],"content":"关于作者...","date":"2024-02-26","objectID":"/about/","tags":[],"title":"如果你想了解一些东西","uri":"/about/"},{"categories":[],"content":"关于江明说 好记性不如烂博客。 江明说代码，说生活，说万物。 涉及技术栈、组件以及工具 编辑器：Visual Studio Code 博客框架：Hugo 主题样式：LoveIt 评论系统：Giscus 图床工具：PicX Static CDN：jsDelivr ","date":"2024-02-26","objectID":"/about/:1:0","tags":[],"title":"如果你想了解一些东西","uri":"/about/"},{"categories":[],"content":"关于我 我是潘江明，始于 2001-09-05，杭州。 一个有奇怪想法、整天逼逼叨叨或沉默不语的人，一个无趣的人。 本科就读于浙江科技大学（2020.9 ~ 2024.6）工学学士，计算机科学与技术。 ACM 败犬，野生 Gopher，帝都西二旗打工人。 爱好：自驾游，编程，美女。 我的白日梦： 带上快乐与相机，和喜欢的人走遍世界的角角落落。 ","date":"2024-02-26","objectID":"/about/:2:0","tags":[],"title":"如果你想了解一些东西","uri":"/about/"}]